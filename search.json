[{"title":"2025.6.17学习日记","path":"/2025/06/17/学习日记/2025.6.17学习笔记/","content":"今日学习内容3DGS:今日工作总结在Ubuntu系统上部署了DashGaussian项目.学习DashGaussian项目的改进点.用DashGaussian训练中. 明日工作计划继续训练… 力扣每日一题:一道很有意思的数学题.正问题比较复杂,但是反过来想分割成为多少块就很简单了.https://leetcode.cn/problems/count-the-number-of-arrays-with-k-matching-adjacent-elements?envType=daily-questionenvId=2025-06-17这道题做完之后,做了灵神模运算的笔记,复习了一下快速幂.求组合数的话,先求n! 然后从后向前求1n!. Mysql学习开始学习SQL优化篇,慢sql优化. 项目学习晚上学代码随想录二叉树三四道题. 生活记录早上踢球今早七点训练一会儿.颠球,逆足,短传.右膝内侧还是有点不舒服,需要养一养.","tags":["项目","3DGS","日记","leetcode","mysql","模运算"]},{"title":"2025.6.16学习日记","path":"/2025/06/16/学习日记/2025.6.16学习笔记/","content":"今日学习内容3DGS:今日工作总结配环境.DashGaussian项目部署在Win系统有问题,所以装了一个ubuntu双系统.配置ubuntu环境,基本环境已配置完成. 明日工作计划在Ubuntu系统上部署DashGaussian项目.尝试运行一下. 力扣每日一题:维护最小值遍历的简单题. Mysql学习学完了日志篇 项目学习看了三四篇文档. 晚上学代码随想录二叉树三四道题. 生活记录晚上健身晚上健身 后侧链","tags":["项目","3DGS","日记","leetcode","mysql"]},{"title":"2025.6.14学习日记","path":"/2025/06/14/学习日记/2025.6.14学习笔记/","content":"今日学习内容今天一直在配环境……………. 3DGS:今日工作总结配置Effect3DGS环境，安装子模块时出现安装报错: 配置Effect3DGS环境时,子模块一直无法安装成功.尝试重新配置了多个conda环境来安装子模块,但重新安装其他依赖后,安装子模块diff-gaussian-rasterization仍然报错.Effect3DGS项目没有环境依赖文件,也没在github上贴出,只能先暂时搁置.看了一些其他的3DGS项目 明日工作计划准备部署DashGaussian项目:3DGS训练加速方法. 力扣每日一题:二分答案+贪心+相邻相减计数 Spring学习做了一个工厂 晚上学代码随想录生活记录","tags":["spring","3DGS","日记","leetcode","mysql"]},{"title":"2025.6.13学习日记","path":"/2025/06/13/学习日记/2025.6.13学习笔记/","content":"今日学习内容3DGS:今日工作总结在drjohnson数据集与playroom数据集跑完了原版3DGS.发现viewer中的帧率显示并不准确,存在锁帧率上限和波动的情况,调试了一个测量3DGS的FPS的脚本,可以准确测出3DGS渲染帧率.配置Effect3DGS环境，尝试运行出现一些版本依赖问题。 明日工作计划部署EfficientGS环境,用改进方法跑数据集. 力扣每日一题:二分答案+贪心+相邻相减计数 看mysql看到29条,日志篇延伸出去看多了,看到下午四点半. Spring学习晚上学代码随想录生活记录晚上健身今天主要练的背.","tags":["spring","3DGS","日记","leetcode","mysql"]},{"title":"Spring学习笔记","path":"/2025/06/12/Spring学习笔记/","content":"基础1.Spring 是什么？特性？有哪些模块？一句话概括：Spring 是一个轻量级、非入侵式的控制反转 (IoC)和面向切面 (AOP) 的框架。 2003 年，一个音乐家 Rod Johnson 决定发展一个轻量级的 Java 开发框架，Spring作为 Java 战场的龙骑兵渐渐崛起，并淘汰了EJB这个传统的重装骑兵。 到了现在，企业级开发的标配基本就是 Spring5+ Spring Boot 2 + JDK 8 Spring 有哪些特性呢？ 1. IoC 和 DI 的支持Spring 的核心就是一个大的工厂容器，可以维护所有对象的创建和依赖关系，Spring 工厂用于生成 Bean，并且管理 Bean 的生命周期，实现高内聚低耦合的设计理念。 2. AOP 编程的支持Spring 提供了面向切面编程，可以方便的实现对程序进行权限拦截、运行监控等切面功能。 3. 声明式事务的支持支持通过配置就来完成对事务的管理，而不需要通过硬编码的方式，以前重复的一些事务提交、回滚的 JDBC 代码，都可以不用自己写了。 4. 快捷测试的支持Spring 对 Junit 提供支持，可以通过注解快捷地测试 Spring 程序。 5. 快速集成功能方便集成各种优秀框架，Spring 不排斥各种优秀的开源框架，其内部提供了对各种优秀框架（如：Struts、Hibernate、MyBatis、Quartz 等）的直接支持。 6. 复杂 API 模板封装Spring 对 JavaEE 开发中非常难用的一些 API（JDBC、JavaMail、远程调用等）都提供了模板化的封装，这些封装 API 的提供使得应用难度大大降低。 简单说一下什么是AOP 和 IoC？AOP：面向切面编程，是一种编程范式，它的主要作用是将那些与核心业务逻辑无关，但是对多个对象产生影响的公共行为封装起来，如日志记录、性能统计、事务等。IoC：控制反转，是一种设计思想，它的主要作用是将对象的创建和对象之间的调用过程交给 Spring 容器来管理。 Spring源码看过吗？看过一些，主要就是针对 Spring 循环依赖、Bean 声明周期、AOP、事务、IOC 这五部分。详情看笔记,Spring源码笔记. 2.Spring 有哪些模块呢？Spring 框架是分模块存在，除了最核心的Spring Core Container是必要模块之外，其他模块都是可选，大约有 20 多个模块。 最主要的七大模块： Spring Core：Spring 核心，它是框架最基础的部分，提供 IoC 和依赖注入 DI 特性。 Spring Context：Spring 上下文容器，它是 BeanFactory 功能加强的一个子接口。 Spring Web：它提供 Web 应用开发的支持。 Spring MVC：它针对 Web 应用中 MVC 思想的实现。 Spring DAO：提供对 JDBC 抽象层，简化了 JDBC 编码，同时，编码更具有健壮性。 Spring ORM：它支持用于流行的 ORM 框架的整合，比如：Spring + Hibernate、Spring + iBatis、Spring + JDO 的整合等。 Spring AOP：即面向切面编程，它提供了与 AOP 联盟兼容的编程实现。 3.Spring 有哪些常用注解呢？Spring 提供了大量的注解来简化 Java 应用的开发和配置，主要用于 Web 开发、往容器注入 Bean、AOP、事务控制等。 Web 开发方面有哪些注解呢？①、@Controller：用于标注控制层组件。②、@RestController：是@Controller 和 @ResponseBody 的结合体，返回 JSON 数据时使用。③、@RequestMapping：用于映射请求 URL 到具体的方法上，还可以细分为：@GetMapping：只能用于处理 GET 请求@PostMapping：只能用于处理 POST 请求@DeleteMapping：只能用于处理 DELETE 请求④、@ResponseBody：直接将返回的数据放入 HTTP 响应正文中，一般用于返回 JSON 数据。⑤、@RequestBody：表示一个方法参数应该绑定到 Web 请求体。⑥、@PathVariable：用于接收路径参数，比如 @RequestMapping(“hello{name}”)，这里的 name 就是路径参数。⑦、@RequestParam：用于接收请求参数。比如 @RequestParam(name “key”) String key，这里的 key 就是请求参数。 容器类注解有哪些呢？@Component：标识一个类为 Spring 组件，使其能够被 Spring 容器自动扫描和管理。@Service：标识一个业务逻辑组件（服务层）。比如 @Service(“userService”)，这里的 userService 就是 Bean 的名称。@Repository：标识一个数据访问组件（持久层）。@Autowired：按类型自动注入依赖。@Configuration：用于定义配置类，可替换 XML 配置文件。@Value：用于将 Spring Boot 中 application.properties 配置的属性值赋值给变量。 AOP 方面有哪些注解呢？@Aspect 用于声明一个切面，可以配合其他注解一起使用，比如：@After：在方法执行之后执行。@Before：在方法执行之前执行。@Around：方法前后均执行。@PointCut：定义切点，指定需要拦截的方法。事务注解有哪些？主要就是 @Transactional，用于声明一个方法需要事务支持。 4.Spring 中应用了哪些设计模式呢？Spring 框架中用了蛮多设计模式的： ①、比如说工厂模式用于 BeanFactory 和 ApplicationContext，实现 Bean 的创建和管理。 ApplicationContext context = new ClassPathXmlApplicationContext(applicationContext.xml);MyBean myBean = context.getBean(MyBean.class); ②、比如说单例模式，这样可以保证 Bean 的唯一性，减少系统开销。 ApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);MyService myService1 = context.getBean(MyService.class);MyService myService2 = context.getBean(MyService.class);// This will print true because both references point to the same instanceSystem.out.println(myService1 == myService2); ③、比如说 AOP 使用了代理模式来实现横切关注点（如事务管理、日志记录、权限控制等）。 @Transactionalpublic void myTransactionalMethod() // 方法实现 Spring如何实现单例模式？Spring 通过 IOC 容器(控制反转)实现单例模式，具体步骤是： 单例 Bean 在容器初始化时创建并使用 DefaultSingletonBeanRegistry 提供的 singletonObjects进行缓存。 // 单例缓存private final MapString, Object singletonObjects = new ConcurrentHashMap();public Object getSingleton(String beanName) return this.singletonObjects.get(beanName);protected void addSingleton(String beanName, Object singletonObject) this.singletonObjects.put(beanName, singletonObject); 在请求 Bean 时，Spring 会先从缓存中获取。 39.Spring 容器、Web 容器之间的区别？（补充）Spring 容器是 Spring 框架的核心部分，负责管理应用程序中的对象生命周期和依赖注入。Web 容器（也称 Servlet 容器），是用于运行 Java Web 应用程序的服务器环境，支持 Servlet、JSP 等 Web 组件。常见的 Web 容器包括 Apache Tomcat、Jetty等。Spring MVC 是 Spring 框架的一部分，专门用于处理 Web 请求，基于 MVC（Model-View-Controller）设计模式。 IoC5.说一说什么是 IoC、DI？所谓的IoC，就是由容器来控制对象的生命周期和对象之间的关系。控制对象生命周期的不再是引用它的对象，而是容器，这就叫控制反转（Inversion of Control）。 没有 IoC 之前： 我需要一个女朋友，刚好大街上突然看到了一个小姐姐，人很好看，于是我就自己主动上去搭讪，要她的微信号，找机会聊天关心她，然后约她出来吃饭，打听她的爱好，三观。。。 有了 IoC 之后： 我需要一个女朋友，于是我就去找婚介所，告诉婚介所，我需要一个长的像赵露思的，会打 Dota2 的，于是婚介所在它的人才库里开始找，找不到它就直接说没有，找到它就直接介绍给我。 婚介所就相当于一个 IoC 容器，我就是一个对象，我需要的女朋友就是另一个对象，我不用关心女朋友是怎么来的，我只需要告诉婚介所我需要什么样的女朋友，婚介所就帮我去找。 Spring 倡导的开发方式就是这样，所有类的创建和销毁都通过 Spring 容器来，不再是开发者去 new，去 null，这样就实现了对象的解耦。 于是，对于某个对象来说，以前是它控制它依赖的对象，现在是所有对象都被 Spring 控制。 说说什么是DI?IOC 是一种思想，DI 是实现 IOC 的具体方式，比如说利用注入机制（如构造器注入、Setter 注入）将依赖传递给目标对象。 2004 年，Martin Fowler 在他的文章《控制反转容器依赖注入模式》首次提出了 DI（依赖注入，Dependency Injection） 这个名词。 打个比方，你现在想吃韭菜馅的饺子，这时候就有人用针管往你吃的饺子里注入韭菜鸡蛋馅。就好像 A 类需要 B 类，以前是 A 类自己 new 一个 B 类，现在是有人把 B 类注入到 A 类里。 为什么要使用 IoC 呢？在平时的 Java 开发中，如果我们要实现某一个功能，可能至少需要两个以上的对象来协助完成，在没有 Spring 之前，每个对象在需要它的合作对象时，需要自己 new 一个，比如说 A 要使用 B，A 就对 B 产生了依赖，也就是 A 和 B 之间存在了一种耦合关系。 有了 Spring 之后，就不一样了，创建 B 的工作交给了 Spring 来完成，Spring 创建好了 B 对象后就放到容器中，A 告诉 Spring 我需要 B，Spring 就从容器中取出 B 交给 A 来使用。 至于 B 是怎么来的，A 就不再关心了，Spring 容器想通过 newnew 创建 B 还是 new 创建 B，无所谓。 这就是 IoC 的好处，它降低了对象之间的耦合度，使得程序更加灵活，更加易于维护。 6.能简单说一下 Spring IoC 的实现机制吗？Spring 的 IoC 本质就是一个大工厂，我们想想一个工厂是怎么运行的呢？ 生产产品：一个工厂最核心的功能就是生产产品。在 Spring 里，不用 Bean 自己来实例化，而是交给 Spring，应该怎么实现呢？——答案毫无疑问，反射。那么这个厂子的生产管理是怎么做的？你应该也知道——工厂模式。 库存产品：工厂一般都是有库房的，用来库存产品，毕竟生产的产品不能立马就拉走。Spring 我们都知道是一个容器，这个容器里存的就是对象，不能每次来取对象，都得现场来反射创建对象，得把创建出的对象存起来。 订单处理：还有最重要的一点，工厂根据什么来提供产品呢？订单。这些订单可能五花八门，有线上签签的、有到工厂签的、还有工厂销售上门签的……最后经过处理，指导工厂的出货。在 Spring 里，也有这样的订单，它就是我们 bean 的定义和依赖关系，可以是 xml 形式，也可以是我们最熟悉的注解形式。 我们简单地实现一个 mini 版的 Spring IoC： 7.说说 BeanFactory 和 ApplicantContext?可以这么比喻，BeanFactory 是 Spring 的“心脏”，而 ApplicantContext 是 Spring 的完整“身躯”。 BeanFactory 主要负责配置、创建和管理 bean，为 Spring 提供了基本的依赖注入（DI）支持。ApplicationContext 是 BeanFactory 的子接口，在 BeanFactory 的基础上添加了企业级的功能支持。 详细说说 BeanFactoryBeanFactory 位于整个 Spring IoC 容器的顶端，ApplicationContext 算是 BeanFactory 的子接口。 它最主要的方法就是 getBean()，这个方法负责从容器中返回特定名称或者类型的 Bean 实例。 来看一个 XMLBeanFactory（已过时） 获取 bean 的例子： class HelloWorldApp public static void main(String[] args) BeanFactory factory = new XmlBeanFactory (new ClassPathResource(beans.xml)); HelloWorld obj = (HelloWorld) factory.getBean(itwanger); obj.getMessage(); 请详细说说 ApplicationContextApplicationContext 继承了 HierachicalBeanFactory 和 ListableBeanFactory 接口，算是 BeanFactory 的自动挡版本，是 Spring 应用的默认方式。 ApplicationContext 会在启动时预先创建和配置所有的单例 bean，并支持如 JDBC、ORM 框架的集成，内置面向切面编程（AOP）的支持，可以配置声明式事务管理等。 这是 ApplicationContext 的使用例子： class MainApp public static void main(String[] args) // 使用 AppConfig 配置类初始化 ApplicationContext ApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class); // 从 ApplicationContext 获取 messageService 的 bean MessageService service = context.getBean(MessageService.class); // 使用 bean service.printMessage(); 通过 AnnotationConfigApplicationContext 类，我们可以使用 Java 配置类来初始化 ApplicationContext，这样就可以使用 Java 代码来配置 Spring 容器。 @Configuration@ComponentScan(basePackages = com.github.paicoding.forum.test.javabetter.spring1) // 替换为你的包名public class AppConfig 8.你知道 Spring 容器启动阶段会干什么吗？","tags":["基础","spring"]},{"title":"2025.6.12学习日记","path":"/2025/06/12/学习日记/2025.6.12学习笔记/","content":"今日学习内容3DGS:今日工作总结今天对开源数据集train,truck,drjohnson进行训练和测试.结果主要用于之后跑不同改进版本3DGS的参考。结果在飞书文档中在训练drjohnson数据集过程中,训练速度明显变慢.分析原因：可能是drjohnson数据集中，图像分辨率相比train和truck数据集更高,点云数量更大，并且在train.py训练过程中，高斯球克隆更加激进，导致显存交换更加频繁，IO时间变长或者缓存碎片化，导致训练时间成倍增加。 明日工作计划继续将drjohnson数据集与playroom数据集进行训练和测试作为参考.部署EfficientGS方法进行测试,该方法主要针对室外大场景,对原版3DGS进行性能优化. 力扣每日一题:循环数组简单题. 上午看mysql看到24题. 下午看项目看了一篇Servlet的文章. Spring学习写了四条,开个头. 晚上学代码随想录继续二叉树. 做了一道数组模拟环形链表找入口的题,挺有意思的. https://leetcode.cn/problems/find-the-duplicate-number 生活记录晚上健身今天主要练的背.","tags":["spring","3DGS","日记","leetcode","mysql"]},{"title":"3DGS-Ubuntu环境.md","path":"/2025/06/11/3DGS/3DGS-Ubuntu环境/","content":"环境:Ubuntu20.04和Win11双系统CUDA11.8Anacoda3 安装clash for linux 快捷命令 clashtun on off anaconda:source conda activate 虚拟环境名","tags":["3DGS","公司"]},{"title":"3DGS学习笔记","path":"/2025/06/11/3DGS/3DGS学习笔记/","content":"环境配置https://www.youtube.com/watch?v=UXtuigy_wYc youtube复现视频https://github.com/graphdeco-inria/gaussian-splatting 3DGS的github源码地址https://dl.acm.org/doi/10.1145/3592433 论文地址https://arxiv.org/abs/2308.04079 下载依赖和环境视频老哥的github地址https://github.com/jonstephens85/gaussian-splatting-Windows 下载git(跳过)测试是否下载git –version 下载anaconda(跳过)下载CUDA :nvcc –version测试版本nvidia-smi确定电脑最高支持的CUDA版本 ,我的最高支持12.8 准备下载CUDA 11.8版本安装vs2019官方下载地址：https://visualstudio.microsoft.com/zh-hans/vs/older-downloads/ 下载colmap准备编译打开anaconda prompt D: 切换D盘D:\\user\\desktop\\workplace\\3DGS\\userdesktopworkplace3DGS 要将 Anaconda 创建的虚拟环境设置在 D 盘，可以按照以下步骤操作： 修改 Anaconda 配置首先，需要修改 Anaconda 的配置，使其将环境创建在指定路径。在 Anaconda Prompt 中执行以下命令：conda config –add envs_dirs D:\\Anaconda\\envs（如果需要，将 D:\\Anaconda\\envs 替换为你想要的路径） 确保路径存在确保你指定的路径已经存在。如果不存在，请手动创建该文件夹。 创建虚拟环境现在你就可以创建虚拟环境，新的环境将被创建在 D 盘的指定路径下：conda create –name env_name python3.x 检查环境位置可以使用以下命令查看虚拟环境的位置：conda info –envs经过以上步骤后，你的虚拟环境将会在 D 盘创建。conda create -n gaussian_splatting python3.7conda activate gaussian_splattingconda install -c conda-forge vs2019_win-64pip install torch1.13.1+cu117 torchvision0.14.1+cu117 torchaudio0.13.1 –extra-index-url https://download.pytorch.org/whl/cu117pip install submodulesdiff-gaussian-rasterizationpip install submodulessimple-knnpip install submodulesfused-ssim 训练3dgs的运行训练下述所有命令都是在终端里运行的，运行时保持是从gaussian-splatting目录下开始输入的。省流版本:conda activate gaussian_splattingd:cd D:\\sys\\Desktop\\Workplace\\3DGS新的路径训练:python train.py -s data_train -m data_train/output (参数为输出地址)python render.py -m data_train/output把train文件夹的method复制到test文件夹python metrics.py -m data_train/output 1.视频截取帧这里可以用自己手机拍摄的一段视频，一两分钟即可，可以参考一下作者的训练时间，作者用自己的笔记本（4060 8G），大概训练了两个小时左右，跑完了所有的迭代。 在gaussian-splatting目录下新建一个data文件夹，将你拍摄的视频移动到该data文件夹下，并将你的视频改名为input，后缀.mp4不用改。然后在data文件夹里再建一个与视频同名的文件夹，名字也是input。然后就可以输入命令啦（终端里从gaussian-splattingdata目录下开始输入） cd data ffmpeg -i input.mp4 -vf setpts=0.2*PTS input\\input_%04d.jpg #推荐运行这个指令 ffmpeg -i input.mp4 -vf setpts=0.2*PTS,fps=1 input\\input_%04d.jpg #如果需要调整抽帧频率可以参考这个指令。选择一个运行即可 这里简单的说一下各个参数的含义。setpts0.2*PTS 将视频播放速度加快到原来的 5 倍。这意味着原视频的每秒帧数增加到 5 倍。如果原始视频是 30 FPS，加速后的视频将以 150 FPS 播放。尽管视频播放速度加快了，ffmpeg fps1 会以每秒一帧的频率提取图片。 这样就可以把你的视频截取为帧并保存在input文件夹里，在input文件夹里应该可以看到许多张照片。 2.产生点云在终端gaussian-splatting目录下输入cd ..python convert.py -s data 这个就是利用安装的colmap产生点云，会花费一些时间，等待完成即可。 3.查看点云终端里输入 colmap 调出来colmap后，选择file-import model然后选择gaussian-splattingdatasparse0文件夹，选择确定，即可打开生成的点云，遇到弹窗×掉即可。可以看到生成的点云还有相机路径。 4.开始训练同样，在终端里gaussian-splatting目录下，输入 python train.py -s data -m dataoutput (参数为输出地址)python train.py -s data -m dataimages 成功开始会出现如下图所示然后耐心等待训练完成以后即可。 5.查看结果同样，在终端里gaussian-splatting目录下，输入 .\\viewers\\bin\\SIBR_gaussianViewer_app -m dataoutput 即可打开viewer窗口，可以把你的场景拖大，下面是一些快捷按键 w uio asd jkl 就是可以控制视角的变化，大家自己按一下就知道是干啥的了，这里就不一一列举对应的功能了（作者已经累了），注意切换输入法为英文输入。 至此，就全部结束啦，完结撒花！ 1 . convert.py将input数据集转换成为点云通过sfm算法将输入的图片集转换成点云,这种方式的具体流程如下: 特征提取：从输入的图像集中，对每一张图像提取特征点及其描述子，常用的特征提取算法有 SIFT、SURF、ORB 等。 全局特征匹配：在所有图像的特征点之间进行匹配，找出不同图像中表示同一物理点的特征点对。由于是全局匹配，可能会处理大量的特征点对，计算量较大。 相机位姿估计：根据匹配的特征点对，使用诸如对极几何、PnP 等算法来估计相机的相对位姿。 三角测量：利用已知的相机位姿和匹配的特征点，通过三角测量计算出三维点的坐标，从而生成点云。 全局优化：使用束调整（Bundle Adjustment）等方法对相机位姿和三维点的坐标进行全局优化，提高点云的精度。SfM 侧重于对静态图像集进行全局处理，通过全局优化来生成高精度的点云,SfM相比ORB方法 更侧重于离线的高精度三维重建. 渲染辐射场的几种方法建立了最近的数据集。革命性地合成了用多张照片或视频捕获的场景。然而，实现高视觉质量仍然需要训练和渲染成本高昂的神经网络，而最近更快的方法不可避免地要牺牲速度来换取质量。对于无界和完整的场景(而不是孤立的对象)和1080p分辨率的渲染，目前没有一种方法可以实现实时显示速率。我们介绍了三个关键要素，使我们能够在保持有竞争力的训练时间的同时实现最先进的视觉质量，并且重要的是允许在1080p分辨率下实现高质量的实时(≥30 fps)新视图合成。首先，从相机校准过程中产生的稀疏点开始，我们用3D高斯分布表示场景，该分布保留了用于场景优化的连续体辐射场的理想属性，同时避免了在空白空间中不必要的计算;其次，我们对3D高斯分布进行交错优化密度控制，特别是优化各向异性协方差以实现场景的准确表示;第三，我们开发了一种支持各向异性喷溅的快速可视性感知渲染算法，既加速了训练，又允许实时渲染。我们展示了最先进的视觉质量和实时性 3dgs流程3DGS流程：（1）通过colmap等工具从多视角图像获取SfM点云（SfM是一种三维重建算法，通过两个或多个场景图片恢复相机位姿，并重建三维坐标点），对 SfM 点云进行了初始化。 （2）点云中的每一个点代表着一个三维的高斯分布，除了点的位置（均值）外，还有协方差、不透明度、颜色（球谐函数）–3D 高斯球云。 （3）将这些椭球体沿着特定角度投影到对应位姿所在平面（Splatting）。一个椭球体投影到平面会得到一个椭圆；然后通过计算待求解像素和椭圆中心的距离，我们得到不透明度（离的近，说明越不透明）；每个椭球又代表各自的颜色，进行alpha composting来合成颜色，然后快速的对所有像素做“可微光栅化”，渲染得到图像。 （4）得到渲染图像Image后，再与gt图像比较，得到损失loss，并沿蓝色箭头反向传播，随机梯度下降；向下送入自适应密度控制中（增密或修剪），更新点云优化。 代码运行流程1.Runningpython train.py -s 示例： python train.py -s data360_extra_scenestreehill 运行完在output下得到相应的文件夹outputtreehill， 将得到的结果路径添加至SIBR_viewer.py（model_path r’D:\\gaussian-splatting\\output\\treehill’），运行即可获得可视化。 densify_and_prune操作会改变高斯数量。结合在一起，允许模型根据当前两个的训练状态动态地调整高斯的数量，从而实现更好的表示能力和计算效率。因此，在这个过程中，高斯的数量会变化，所以需要在执行后打印出当前的高斯数量。在训练的时候添加高斯数量打印： print(f”Iteration {iteration}: Number of Gaussians after densification and pruning: {gaussians.get_xyz.shape[0]}”) 2. Evaluationpython train.py -s –eval # Train with traintest splitpython render.py -m # Generate renderingspython metrics.py -m # Compute error metrics on renderings 训练模型-渲染图像-计算指标 示例：Evaluation运行，输入命令行(python train.py -s + 数据集的路径) python train.py -s data360_extra_scenestreehill –evalpython render.py -m outputtreehillpython metrics.py -m outputtreehill 2. Processing your own Scenes按照README.me进行，选择的mill19building-pixsfm进行简单测试 图像目录结构： location|---input |---image 0 |---image 1 |---...python convert.py -s location [--resize] #If not resizing, ImageMagick is not needed示例：data/mill19/building-pixsfm|---input |---image 0 |---image 1 |---... 然后运行： python convert.py -s datamill19building-pixsfm","tags":["3DGS","公司"]},{"title":"2025.6.11学习日记","path":"/2025/06/11/学习日记/2025.6.11学习笔记/","content":"今日学习内容3DGS:今日工作总结:​一. 代码运行与结构梳理​​:学习了原版3DGS的项目结构和训练流程: train.py : 训练脚本,主要负责对高斯球参数进行训练. render.py : 渲染脚本,用于将训练得到的高斯球参数渲染成图像. metrics.py : 评估脚本,对比真值图像和渲染图像,用于评估渲染结果的质量. 二.训练结果:火车数据集301张图像. train.py :ITER 7000:L1损失 : 0.06603520661592484PSNR :20.096060180664065训练时间 : 13分30秒ITER 30000:L1损失 : 0.038734884932637215PSNR : 24.450721740722656s训练时间:77分25秒 render.py : metrics.py :SSIM: 0.87444342PSNR: 25.8431702LPIPS: 0.1703709 ​​明日工作计划:​​今天对火车的数据集进行了实验,明天准备开始对其他数据集进行实验,得出一组原版3DGS的训练结果作为参考,方便对后续3DGS改进算法进行实验对比. 下午回学校开会来着晚上继续做力扣二叉树篇明日计划3dgs明天尽量让时间一直在跑代码,然后我可以学java. mysql学习力扣项目文档生活记录1. 早上足球训练早上7点,颠球短传训练.","tags":["3DGS","日记"]},{"title":"nvm更改node版本","path":"/2025/06/11/杂项笔记/nvm更改node版本/","content":"安装brew首先安装 Brew。这个就不详细说了 没有的话自己去搜一下 第一步：进行nvm 安装操作brew install nvm 执行后：== Pouring nvm-0.39.1_1.all.bottle.tar.gz== CaveatsPlease note that upstream has asked us to make explicit managingnvm via Homebrew is unsupported by them and you should check anyproblems against the standard nvm install method prior to reporting.You should create NVMs working directory if it doesnt exist: // 这里就是提示你创建一个 nvm文件 mkdir ~/.nvmAdd the following to ~/.zshrc or your desired shellconfiguration file: // 这里就是想让你进行一些配置 export NVM_DIR=$HOME/.nvm [ -s /opt/homebrew/opt/nvm/nvm.sh ] \\. /opt/homebrew/opt/nvm/nvm.sh # This loads nvm [ -s /opt/homebrew/opt/nvm/etc/bash_completion.d/nvm ] \\. /opt/homebrew/opt/nvm/etc/bash_completion.d/nvm # This loads nvm bash_completionYou can set $NVM_DIR to any location, but leaving it unchanged from/opt/homebrew/opt/nvm will destroy any nvm-installed Node installationsupon upgrade/reinstall.Type `nvm help` for further information.== Summary🍺 /opt/homebrew/Cellar/nvm/0.39.1_1: 9 files, 184KB 执行 nvm –versionnvm --version //出现问题。去进行配置 zsh: command not found: nvm 第二步：nvm配置1.vim ~/.bash_profile点击 i 进行插入操作 插入下面配置 export NVM_DIR=~/.nvmsource $(brew --prefix nvm)/nvm.sh 插入完成后 点击Esc 然后 使用 :wq. 保存并退出 执行：source ~/.bash_profile 如果出问题先不管接着往下走 2.vim ~/.zshrc点击 i 进行插入操作 插入下面配置 export NVM_DIR=~/.nvmsource $(brew --prefix nvm)/nvm.sh 插入完成后 点击Esc 然后 使用 :wq. 保存并退出 执行：source ~/.zshrc 3.vim ~/.profile点击 i 进行插入操作 插入下面配置 export NVM_DIR=~/.nvmsource $(brew --prefix nvm)/nvm.sh 插入完成后 点击Esc 然后 使用 :wq. 保存并退出 执行：source ~/.profile 最后开始进行测试执行：nvm --version 显示版本号就说明配置成功：0.39.1 通过nvm 进行node 版本控制 版本号根据自己的需求定义 nvm install 12.6.0 查看版本：node -v nvm 常用命令：以下用8.9.2版本为例nvm ls ：打印出所有的版本 install stable：安装最稳定的版本nvm install v8.9.2 ： 安装node的8.9.2的版本（删除用uninstall）nvm current ：当前使用的node版本nvm use v8.9.2 ：将node改为8.9.2版本nvm alias default 0.12.7：设置默认 node 版本为 0.12.7nvm alias default ：设置系统默认的node版本nvm alias ：给不同的版本号添加别名nvm unalias ： 删除已定义的别名nvm reinstall-packages ：在当前版本node环境下，重新全局安装指定版本号的npm包npm install -g mz-fis：安装 mz-fis 模块至全局目录，安装的路径：/Users/你的用户名/.nvm/versions/node/v0.12.7/lib/mz-fisnvm use 4：切换至 4.2.2 版本（支持模糊查询）npm install -g react-native-cli：安装 react-native-cli 模块至全局目录，安装的路径：/Users/你的用户名/.nvm/versions/node/v4.2.2/lib/react-native-cli node npm 版本对照链接: 版本对照 末尾 npm 降级执行：sudo npm install npm@6.9.0 -g 问题是不可控的 如果未能解决你的问题 就祝你顺利","tags":["nvm","node"]},{"title":"Java集合框架笔记","path":"/2025/06/10/Java集合框架笔记/","content":"框架图先贴一个Java集合框架图 可以看出,集合主要分成两大部分: Collection:主要由 List、Set、Queue 组成，List 代表有序、可复的集合，典型代表就是封装了动态数组的 ArrayList 和封装了链表的 LinkedList；Set 代表⽆序、不可复的集合，典型代表就是 HashSet 和 TreeSet；Queue 代表队列，典型代表就是双端队列ArrayDeque，以及优先级队列 PriorityQueue。 Map:代表键值对的集合，典型代表就是 HashMap。 CollectionListList 的特点是存取有序，可以存放复的元素，可以⽤下标对元素进⾏操作。 ArrayListArrayList的增删改查: // 创建⼀个集合ArrayListString list = new ArrayListString();// 添加元素list.add(王⼆);list.add(沉默);list.add(陈清扬);// 遍历集合 for 循环for (int i = 0; i list.size(); i++) String s = list.get(i); System.out.println(s);// 遍历集合 for eachfor (String s : list) stem.out.println(s);// 删除元素list.remove(1);// 遍历集合for (String s : list) System.out.println(s);// 修改元素list.set(1,王⼆狗);// 遍历集合for (String s : list) System.out.println(s);","tags":["基础","Java","集合"]},{"title":"Mysql学习笔记","path":"/2025/06/10/Mysql学习笔记/","content":"Mysql基础0.什么是MYSQLMySQL 是⼀个开源的关系型数据库，现在⾪属于 Oracle 公司。 删除创建一张表DROP TABLE 删除表CREATE TABLE 创建表创建表的时候，可以通过 PRIMARY KEY 设定主键。 CREATE TABLE users ( id INT AUTO_INCREMENT, name VARCHAR(100) NOT NULL, email VARCHAR(100), PRIMARY KEY (id)); 写一个升序降序的SQL语句可以使用ORDER BY字句对查询结果进行排序.默认情况下是升序排序.如需要降序,使用关键字DESC例子: SELECT id, name, salaryFROM employeesORDER BY salary DESC; 如若对多个字段进行排序: SELECT id, name, salaryFROM employeesORDER BY salary DESC, name ASC; 优先级从左到右,相当于先按工资降序,工资相同再按照姓名升序. MYSQL出现性能差的原因可能是 SQL 查询使⽤了全表扫描，也可能是查询语句过于复杂，如多表JOIN或嵌套⼦查询。也有可能是单表数据量过⼤。 通常情况下,增加索引就可以解决大部分的性能问题.对于热点数据,增加redis缓存,减轻对数据库的压力. 1.两张表怎么进行连接可以通过内连接inner join、外连接 outer join 、交叉连接 cross join 等方式来进行连接. 什么是内连接内连接⽤于返回两个表中有匹配关系的⾏。假设有两张表，⽤户表和订单表，想查询有订单的⽤户，就可以使⽤内连接 users INNER JOIN orders，按照⽤户 ID 关联就⾏了。 SELECT users.name, orders.order_idFROM usersINNER JOIN orders ON users.id = orders.user_id; 两表匹配的行才会输出. 什么是外连接和内连接不同，外连接不仅返回两个表中匹配的⾏，还返回没有匹配的⾏，⽤ null 来填充。外连接⼜分为左外连接 left join 和右外连接 right join。 left join 会保留左表中符合条件的所有记录，如果右表中有匹配的记录，就返回匹配的记录，否则就⽤null 填充，常⽤于某表中有，但另外⼀张表中可能没有的数据的查询场景。假设要查询所有⽤户及他们的订单，即使⽤户没有下单，就可以使⽤左连接： SELECT users.id, users.name, orders.order_idFROM usersLEFT JOIN orders ON users.id = orders.user_id; (这里面左表就是users,users所有行都会输出) 右连接就是左连接的镜像，right join 会保留右表中符合条件的所有记录，如果左表中有匹配的记录，就返回匹配的记录，否则就⽤ null 填充。 什么是交叉连接交叉连接会返回两张表的笛卡尔积，也就是将左表的每⼀⾏与右表的每⼀⾏进⾏组合，返回的⾏数是两张表⾏数的乘积。假设有 A 表和 B 表，A 表有 2 ⾏数据，B 表有 3 ⾏数据，那么交叉连接的结果就是 2 * 3 6 ⾏。笛卡尔积是数学中的⼀个概念，例如集合 A{a,b}，集合 B{0,1,2} ，那么 A x B {a,0,a,1,a,2,b,0,b,1,b,2,}。 SELECT A.id, B.idFROM ACROSS JOIN B; 2.内连接 左连接 右连接有什么区别左连接 FROM 表a join 表b 相当于 a在左 b在右MySQL 的连接主要分为内连接和外连接，外连接⼜可以分为左连接和右连接。 内连接相当于找两表的交集.左连接和右连接可以⽤来找出两个表中不同的记录，相当于两个数据集的并集。两者的区别是，左连接会保留左表中符合条件的所有记录，右连接则刚好相反。 例子:有三张表，⼀张⽂章表 article，主要存⽂章标题 title.⼀张⽂章详情表 article_detail，主要存⽂章的内容 content.⼀张⽂章评论表 comment，主要存评论 content.三个表通过⽂章 id关联。内连接:返回至少有评论的文章标题和评论内容 SELECT LEFT(a.title, 20) AS ArticleTitle, LEFT(c.content, 20) AS CommentContent //返回LEFT左数前20字符 AS为列或表起临时别名FROM article a //article起别名 aINNER JOIN comment c ON a.id = c.article_id //内连接 id相同 起别名cLIMIT 2; //只返回两条 左连接:返回所有⽂章的标题和⽂章评论，即使某些⽂章没有评论（填充为 NULL）。 SELECT LEFT(a.title, 20) AS ArticleTitle, LEFT(c.content, 20) ASCommentContentFROM article aLEFT JOIN comment c ON a.id = c.article_idLIMIT 2; 右连接:调换了位置 SELECT LEFT(a.title, 20) AS ArticleTitle, LEFT(c.content, 20) ASCommentContentFROM comment cRIGHT JOIN article a ON a.id = c.article_idLIMIT 2; 3.数据库的三大范式 - 第⼀范式:确保表的每⼀列都是不可分割的基本数据单元.⽐如说⽤户地址，应该拆分成省、市、区、详细地址等 4 个字段。相当于保持列的原子性. - 第⼆范式:要求表中的每⼀列都和主键直接相关。⽐如在订单表中，商品名称、单位、商品价格等字段应该拆分到商品表中。然后再创建一个订单商品关联表.不能出现部分依赖的情况.相当于让解决复合主键的部分依赖问题.订单明细(订单ID, 产品ID, 产品名称, 数量)↑ 复合主键是(订单ID, 产品ID)，但”产品名称”只依赖”产品ID”（部分依赖）修改为:订单明细(订单ID, 产品ID, 数量)产品(产品ID, 产品名称) - 第三范式:⾮主键列应该只依赖于主键列。⽐如说在设计订单信息表的时候，可以把客户名称、所属公司、联系⽅式等信息拆分到客户信息表中，然后在订单信息表中⽤客户编号进⾏关联。**相当于消除传递依赖.**将​​传递依赖​​的字段（A→B→C，其中A是主键）拆分到新表中。学生(学号, 姓名, 宿舍号, 宿舍费用)↑ “宿舍费用”依赖”宿舍号”，而”宿舍号”依赖”学号”（传递依赖）修改为:学生(学号, 姓名, 宿舍号)宿舍(宿舍号, 宿舍费用) 建表时需要考虑哪些问题⾸先需要考虑表是否符合数据库的三⼤范式，确保字段不可再分，消除⾮主键依赖，确保字段仅依赖于主键等。然后在选择字段类型时，应该尽量选择合适的数据类型。在字符集上，尽量选择 utf8mb4，这样不仅可以⽀持中⽂和英⽂，还可以⽀持表情符号等。当数据量较⼤时，⽐如上千万⾏数据，需要考虑分表。⽐如订单表，可以采⽤⽔平分表的⽅式来分散单表存储压⼒。 水平分表(按行拆分):水平分表是将​​同一张表中的数据按行拆分到多个结构相同的表中 按照id范围分表 按照时间范围分表 按照hash分表 按照地域分表 垂直分表(按列拆分):不同分表包含不同字段,表字段过多或冷热数据分离时使用. 4.varchar 与 char 的区别latin1 字符集，且列属性定义为 NOT NULL。 varchar 是可变⻓度的字符类型，原则上最多可以容纳 65535 个字符，但考虑字符集，以及MySQL 需要 1 到 2 个字节来表示字符串⻓度，所以实际上最⼤可以设置到 65533。char 是固定⻓度的字符类型，当定义⼀个 CHAR(10) 字段时，不管实际存储的字符⻓度是多少，都只会占⽤ 10 个字符的空间。如果插⼊的数据⼩于 10 个字符，剩余的部分会⽤空格填充。 varchar在输入过长时也会截断. 5.blob 和 text 有什么区别blob ⽤于存储⼆进制数据，⽐如图⽚、⾳频、视频、⽂件等；但实际开发中，我们都会把这些⽂件存储到 OSS 或者⽂件服务器上，然后在数据库中存储⽂件的 URL。 text ⽤于存储⽂本数据，⽐如⽂章、评论、⽇志等。 6.DATETIME 和 TIMESTAMP 有什么区别DATETIME 直接存储⽇期和时间的完整值，与时区⽆关。TIMESTAMP 存储的是 Unix 时间戳，1970-01-01 00:00:01 UTC 以来的秒数，受时区影响。 另外，DATETIME 的默认值为 null，占⽤ 8 个字节；TIMESTAMP 的默认值为当前时间——CURRENT_TIMESTAMP，占 4 个字节，实际开发中更常⽤，因为可以⾃动更新。 7. in 和 exists 的区别当使⽤ IN 时，MySQL 会⾸先执⾏⼦查询，然后将⼦查询的结果集⽤于外部查询的条件。这意味着⼦查询的结果集需要全部加载到内存中。 ⽽ EXISTS 会对外部查询的每⼀⾏，执⾏⼀次⼦查询。如果⼦查询返回任何⾏，则EXISTS条件为真。EXISTS 关注的是⼦查询是否返回⾏，⽽不是返回的具体值。 -- IN 的临时表可能成为性能瓶颈SELECT * FROM usersWHERE id IN (SELECT user_id FROM orders WHERE amount 100);//查询所有下过单笔订单金额超过100的用户（完整信息）-- EXISTS 可以利⽤关联索引SELECT * FROM users uWHERE EXISTS (SELECT 1 FROM orders oWHERE o.user_id = u.id AND o.amount 100); IN 适⽤于⼦查询结果集较⼩的情况。如果⼦查询返回⼤量数据,IN的查询效率会下降,因为他会把整个结果存到内存当中. ⽽ EXISTS 适⽤于⼦查询结果集可能很⼤的情况。由于 EXISTS 只需要判断⼦查询是否返回⾏，⽽不需要加载整个结果集，因此在某些情况下性能更好，特别是当⼦查询可以使⽤索引时。 NULL值IN的返回结果中如果有NULL值,可能会出现意料外的情况:比如WHERE column IN ((subquery))，如果subquery为NULL,这个条件永远不会为真,除非column也为NULL. EXISTS如果有NULL值的话,因为EXISTS只关心是否有⾏,所以不会出现NULL值的影响. 8.记录货币⽤什么类型⽐较好?如果是电商、交易、账单等涉及货币的场景，建议使⽤ DECIMAL 类型，因为 DECIMAL 类型是精确数值类型，不会出现浮点数计算误差。 如果是银⾏,涉及到⽀付的场景，建议使⽤ BIGINT 类型。可以将货币⾦额乘以⼀个固定因⼦，⽐如 100，表示以“分”为单位，然后存储为 BIGINT 。这种⽅式既避免了浮点数问题，同时也提供了不错的性能。但在展示的时候需要除以相应的因⼦。 为什么不推荐使⽤ FLOAT 或 DOUBLE？因为 FLOAT 和 DOUBLE 都是浮点数类型，会存在精度问题。在许多编程语⾔中， 0.1 + 0.2 的结果会是类似 0.30000000000000004 的值，⽽不是预期的 0.3 。 9.如何存储emoji?因为 emoji是 4 个字节的 UTF-8 字符，⽽ MySQL 的 utf8 字符集只⽀持最多 3 个字节的 UTF-8 字符，所以在 MySQL 中存储 emoji 时，需要使⽤ utf8mb4 字符集。 MySQL 8.0 已经默认⽀持 utf8mb4 字符集，可以通过 SHOW VARIABLES WHERE Variable_name LIKE character\\_set\\_% OR Variable_name LIKE collation%; 查看。 10.drop、delete 与 truncate 的区别？ DROP 是物理删除，⽤来删除整张表，包括表结构，且不能回滚。 DELETE ⽀持⾏级删除，可以带 WHERE 条件，可以回滚。 TRUNCATE ⽤于清空表中的所有数据，但会保留表结构，不能回滚。 11.UNION 与 UNION ALL 的区别？UNION 会⾃动去除合并后结果集中的重复⾏。UNION ALL 不会去重，会将所有结果集合并起来。 12.count(1)、count(*) 与 count(列名) 的区别？在InnoDB引擎里面,count(1)和count(*)没有任何区别,都用来统计所有行,包括NULL.如果有索引,那么count(1)和count(*)都会走索引,而count(列名)会走主键索引. COUNT(列名) 只统计列名不为 NULL 的⾏数。 13.SQL 查询语句的执⾏顺序了解吗？了解,先执行FROM确定主表,，再执⾏JOIN连接，然后 WHERE 进⾏过滤，接着 GROUP BY 进⾏分组，HAVING 过滤聚合结果，SELECT 选择最终列，ORDER BY 排序，最后 LIMIT 限制返回⾏数。 WHERE 先执⾏是为了减少数据量，HAVING 只能过滤聚合数据，ORDER BY 必须在SELECT 之后排序最终结果，LIMIT 最后执⾏以减少数据传输。 这个执⾏顺序与编写 SQL 语句的顺序不同，这也是为什么有时候在 SELECT ⼦句中定义的别名不能在 WHERE ⼦句中使⽤得原因，因为 WHERE 是在 SELECT 之前执⾏的。 LIMIT 为什么在最后执⾏？因为 LIMIT 是在最终结果集上执⾏的，如果在 WHERE 之前执⾏ LIMIT，那么就会先返回所有⾏，然后再进⾏ LIMIT 限制，这样会增加数据传输的开销。 ORDER BY 为什么在 SELECT 之后执⾏？因为排序需要基于最终返回的列，如果 ORDER BY 早于 SELECT 执⾏，计算 类的聚合函数就会出问题。比如说如果要按照所选的平均值排序,order by先执行,还没有计算平均值. 14.介绍⼀下 MySQL 的常⽤命令MySQL 的常⽤命令主要包括数据库操作命令、表操作命令、⾏数据 CRUD 命令、索引和约束的创建修改命令、⽤户和权限管理的命令、事务控制的命令等。 -- 数据库操作CREATE DATABASE db_name; -- 创建数据库DROP DATABASE db_name; -- 删除数据库SHOW DATABASES; -- 查看所有数据库USE db_name; -- 切换数据库-- 表操作CREATE TABLE table_name ( -- 创建表 id INT PRIMARY KEY AUTO_INCREMENT, name VARCHAR(50) NOT NULL);DROP TABLE table_name; -- 删除表ALTER TABLE table_name ADD COLUMN col_name INT; -- 添加列ALTER TABLE table_name DROP COLUMN col_name; -- 删除列SHOW TABLES; -- 查看所有表DESC table_name; -- 查看表结构-- 数据CRUDINSERT INTO table_name VALUES (1, test); -- 插入数据SELECT * FROM table_name; -- 查询数据UPDATE table_name SET name=new WHERE id=1;-- 更新数据DELETE FROM table_name WHERE id=1; -- 删除数据-- 索引和约束CREATE INDEX idx_name ON table_name(col); -- 创建索引ALTER TABLE table_name ADD PRIMARY KEY(id); -- 添加主键ALTER TABLE table_name ADD UNIQUE(col_name); -- 添加唯一约束ALTER TABLE table_name ADD FOREIGN KEY(col) REFERENCES other_table(col); -- 外键-- 用户权限CREATE USER user@host IDENTIFIED BY pwd; -- 创建用户GRANT ALL ON db_name.* TO user@host; -- 授权REVOKE ALL ON db_name.* FROM user@host; -- 撤销权限DROP USER user@host; -- 删除用户-- 事务控制START TRANSACTION; -- 开始事务COMMIT; -- 提交事务ROLLBACK; -- 回滚事务SET autocommit=0; -- 关闭自动提交 说说数据库操作命令?CREATE DATABASE database_name; ⽤于创建数据库;USE database_name;⽤于显示所有数据库;DROP DATABASE database_name;⽤于删除数据库;SHOW DATABASES; 换数据库。 说说表操作命令？CREATE TABLE table_name (列名1 数据类型1, 列名2 数据类型2,...); 用于创建表；DROP TABLE table_name; 用于删除表；SHOW TABLES; 用于显示所有表；DESCRIBE table_name; 用于查看表结构；ALTER TABLE table_name ADD column_name datatype; 用于修改表。 说说行数据的 CRUD 命令？INSERT INTO table_name (column1, column2, ...) VALUES (value1, value2, ...); 用于插入数据；SELECT column_names FROM table_name WHERE condition; 用于查询数据；UPDATE table_name SET column1 = value1, column2 = value2 WHERE condition; 用于更新数据；DELETE FROM table_name WHERE condition; 用于删除数据。 说说索引和约束的创建修改命令？CREATE INDEX index_name ON table_name (column_name); 用于创建索引；ALTER TABLE table_name ADD PRIMARY KEY (column_name); 用于添加主键；ALTER TABLE table_name ADD CONSTRAINT fk_name FOREIGN KEY (column_name) REFERENCES parent_table (parent_column_name); 用于添加外键。 说说用户和权限管理的命令？CREATE USER username@host IDENTIFIED BY password; 用于创建用户；GRANT ALL PRIVILEGES ON database_name.table_name TO username@host; 用于授予权限；REVOKE ALL PRIVILEGES ON database_name.table_name FROM username@host; 用于撤销权限；DROP USER username@host; 用于删除用户。 说说事务控制的命令？START TRANSACTION; 用于开始事务；COMMIT; 用于提交事务；ROLLBACK; 用于回滚事务。 15.MySQL bin 目录下的可执行文件了解吗MySQL 的 bin 目录下有很多可执行文件，主要用于管理 MySQL 服务器、数据库、表、数据等。比如说：mysql：用于连接 MySQL 服务器mysqldump：用于数据库备份，对数据备份、迁移或恢复时非常有用mysqladmin：用来执行一些管理操作，比如说创建数据库、删除数据库、查看 MySQL 服务器的状态等。mysqlcheck：用于检查、修复、分析和优化数据库表，对数据库的维护和性能优化非常有用。mysqlimport：用于从文本文件中导入数据到数据库表中，适合批量数据导入。mysqlshow：用于显示 MySQL 数据库服务器中的数据库、表、列等信息。mysqlbinlog：用于查看 MySQL 二进制日志文件的内容，可以用于恢复数据、查看数据变更等。 16.MySQL 第 3-10 条记录怎么查？可以使用 limit 语句，结合偏移量和行数来实现。 SELECT * FROM table_name LIMIT 2, 8; limit 语句用于限制查询结果的数量，偏移量表示从哪条记录开始，行数表示返回的记录数量。2：偏移量，表示跳过前两条记录，从第三条记录开始。8：行数，表示从偏移量开始，返回 8 条记录。偏移量是从 0 开始的，即第一条记录的偏移量是 0；如果想从第 3 条记录开始，偏移量就应该是 2。 17.用过哪些 MySQL 函数？用过挺多的，比如说处理字符串的函数：CONCAT(): 用于连接两个或多个字符串。LENGTH(): 用于返回字符串的长度。SUBSTRING(): 从字符串中提取子字符串。REPLACE(): 替换字符串中的某部分。TRIM(): 去除字符串两侧的空格或其他指定字符。 处理数字的函数：ABS(): 返回一个数的绝对值。ROUND(): 四舍五入到指定的小数位数。MOD(): 返回除法操作的余数。 日期和时间处理函数：NOW(): 返回当前的日期和时间。CURDATE(): 返回当前的日期。 汇总函数：SUM(): 计算数值列的总和。AVG(): 计算数值列的平均值。COUNT(): 计算某列的行数。 逻辑函数：IF(): 如果条件为真，则返回一个值；否则返回另一个值。CASE: 根据一系列条件返回值。 18.说说 SQL 的隐式数据类型转换？当一个整数和一个浮点数相加时，整数会被转换为浮点数。SELECT 1 + 1.0; – 结果为 2.0当一个字符串和一个整数相加时，字符串会被转换为整数。SELECT 1 + 1; – 结果为 2隐式转换会导致意想不到的结果，最好通过显式转换来规避。SELECT CAST(1 AS SIGNED INTEGER) + 1; – 结果为 2 19. 说说 SQL 的语法树解析？SQL 语法树解析是将 SQL 查询语句转换成抽象语法树 —— AST 的过程，是数据库引擎处理查询的第一步，也是防止 SQL 注入的重要手段。通常分为 3 个阶段。 第一个阶段，词法分析：拆解 SQL 语句，识别关键字、表名、列名等。 —start—比如说：SELECT id, name FROM users WHERE age 18;将会被拆解为：[SELECT] [id] [,] [name] [FROM] [users] [WHERE] [age] [] [18] [;]—end— 第二个阶段，语法分析：检查 SQL 是否符合语法规则，并构建抽象语法树。 —start—比如说上面的语句会被构建成如下的语法树： SELECT / \\ Columns FROM / \\ | id name users | WHERE | age 18或者这样表示：SELECT ├── COLUMNS: id, name ├── FROM: users ├── WHERE │ ├── CONDITION: age 18—end— 第三个阶段，语义分析：检查表、列是否存在，进行权限验证等。 —start—比如说执行：SELECT id, name FROM users WHERE age ‘eighteen’;会报错：ERROR: Column ‘age’ is INT, but ‘eighteen’ is STRING.—end— 数据库架构20.说说 MySQL 的基础架构？MySQL 采用分层架构，主要包括连接层、服务层、和存储引擎层。①、连接层主要负责客户端连接的管理，包括验证用户身份、权限校验、连接管理等。可以通过数据库连接池来提升连接的处理效率。②、服务层是 MySQL 的核心，主要负责查询解析、优化、执行等操作。在这一层，SQL 语句会经过解析、优化器优化，然后转发到存储引擎执行，并返回结果。这一层包含查询解析器、优化器、执行计划生成器、日志模块等。③、存储引擎层负责数据的实际存储和提取。MySQL 支持多种存储引擎，如 InnoDB、MyISAM、Memory 等。binlog写入在哪一层？binlog 在服务层，负责记录 SQL 语句的变化。它记录了所有对数据库进行更改的操作，用于数据恢复、主从复制等。 21.一条查询语句SELECT是如何执行的？当我们执行一条 SELECT 语句时，MySQL 并不会直接去磁盘读取数据，而是经过 6 个步骤来解析、优化、执行，然后再返回结果。第一步，客户端发送 SQL 查询语句到 MySQL 服务器。 第二步，MySQL 服务器的连接器开始处理这个请求，跟客户端建立连接、获取权限、管理连接。 第三步，解析器对 SQL 语句进行解析，检查语句是否符合 SQL 语法规则，确保数据库、表和列都是存在的，并处理 SQL 语句中的名称解析和权限验证。 第四步，优化器负责确定 SQL 语句的执行计划，这包括选择使用哪些索引，以及决定表之间的连接顺序等。 第五步，执行器会调用存储引擎的 API来进行数据的读写。 第六步，存储引擎负责查询数据，并将执行结果返回给客户端。客户端接收到查询结果，完成这次查询请求。 22.一条更新语句UPDATE是如何执行的？undo log 回滚日志: 用于事务的回滚操作.redo log 重做日志: 用于实现事务的持久性,保持数据一致性.总的来说，一条 UPDATE 语句的执行过程包括读取数据页、加锁解锁、事务提交、日志记录等多个步骤。拿 update test set a=1 where id=2 举例来说：在事务开始前，MySQL 需要记录undo log，用于事务回滚。 操作 id 旧值 新值 update 2 N 1 除了记录 undo log，存储引擎还会将更新操作写入 redo log，状态标记为 prepare，并确保 redo log 持久化到磁盘。这一步可以保证即使系统崩溃，数据也能通过 redo log 恢复到一致状态。 写完redo log 后，MySQL 会获取行锁，将 a 的值修改为 1，标记为脏页，此时数据仍然在内存的 buffer pool 中，不会立即写入磁盘。后台线程会在适当的时候将脏页刷盘，以提高性能。 最后提交事务，redo log 中的记录被标记为 committed，行锁释放。 如果 MySQL 开启了 binlog，还会将更新操作记录到 binlog 中，主要用于主从复制。 以及数据恢复，可以结合 redo log 进行点对点的恢复。binlog 的写入通常发生在事务提交时，与 redo log 共同构成“两阶段提交”，确保两者的一致性。 注意，redo log 的写入有两个阶段的提交，一是 binlog 写入之前prepare 状态的写入，二是binlog写入之后 commit 状态的写入。 23.说说 MySQL 的段区页行MySQL 是以表的形式存储数据的，而表空间的结构则由段、区、页、行组成。 ①、段：表空间由多个段组成，常见的段有数据段、索引段、回滚段等。创建索引时会创建两个段，数据段和索引段，数据段用来存储叶子节点中的数据；索引段用来存储非叶子节点的数据。回滚段包含了事务执行过程中用于数据回滚的旧数据。 ②、区：段由一个或多个区组成，区是一组连续的页，通常包含 64 个连续的页，也就是 1M 的数据。使用区而非单独的页进行数据分配可以优化磁盘操作，减少磁盘寻道时间，特别是在大量数据进行读写时。 ③、页：页是 InnoDB 存储数据的基本单元，标准大小为 16 KB，索引树上的一个节点就是一个页。也就意味着数据库每次读写都是以 16 KB 为单位的，一次最少从磁盘中读取 16KB 的数据到内存，一次最少写入 16KB 的数据到磁盘。 ④、行：InnoDB 采用行存储方式，意味着数据按照行进行组织和管理，行数据可能有多个格式，比如说 COMPACT、REDUNDANT、DYNAMIC 等。MySQL 8.0 默认的行格式是 DYNAMIC，由COMPACT 演变而来，意味着这些数据如果超过了页内联存储的限制，则会被存储在溢出页中。可以通过 show table status like ‘%article%’ 查看行格式。 了解 MySQL的数据行、行溢出机制吗？InnoDB从磁盘中读取数据的最小单位是数据页。 一 行有哪些格式Mysql的数据行有两种格式:Compact格式和Redundant格式。Compact是一种紧凑的行格式，设计的初衷就是为了让一个数据页中可以存放更多的数据行。 你品一品，让一个数据页中可以存放更多的数据行是一个多么激动人心的事，MySQL以数据页为单位从磁盘中读数据，如果能做到让一个数据页中有更多的行，那岂不是使用的空间变少了，且整体的效率直线飙升？ 官网介绍：Compact能比Redundant格式节约20%的存储。 Compact从MySQL5.0引入，MySQL5.1之后，行格式默认设置成 Compact 。所以本文描述的也是Compact格式。 二、紧凑的行格式长啥样？表中有的列允许为null，有的列是变长的varchar类型。那Compact行格式是如何组织描述这些信息的呢？如下图： 每部分包含的数据可能要比我上面标注的1、2、3还要多。 为了给大家更直观的感受和理解我只是挑了一部分展示给大家看。 三、MySQL单行能存多大体量的数据？在MySQL的设定中，单行数据最大能存储65535byte的数据（注意是byte，而不是字符）MySQL不允许创建一个长度为65535byte的列，因为数据页中每一行中都有我们上图提到的隐藏列。所以将varchar的长度降低到65532byte即可成功创建该表. 所以如果你将charset换成utf8这种编码格式，那varchar(N)中的N其实指的N个字符，而不是N个byte。假如encodeutf8时三个byte表示一个字符。那么65535 3 21845个字符。 四、Compact格式是如何做到紧凑的？MySQL每次进行随机的IO读默认情况下，数据页的大小为16KB。数据页中存储着数行。那就意味着一个数据页中能存储越多的数据行，MySQL整体的进行的IO次数就越少？性能就越快？Compact格式的实现思路是：当列的类型为VARCHAR、 VARBINARY、 BLOB、TEXT时，该列超过768byte的数据放到其他数据页中去。如下图：MySQL这样做，有效的防止了单个varchar列或者Text列太大导致单个数据页中存放的行记录过少而让IO飙升的窘境且占内存的。 五、什么是行溢出？如果数据页默认大小为16KB，换算成byte： 16*1024 16384 byte那你有没有发现，单页能存储的16384byte和单行最大能存储的 65535byte 差了好几倍呢 也就是说，假如你要存储的数据行很大超过了65532byte那么你是写入不进去的。假如你要存储的单行数据小于65535byte但是大于16384byte，这时你可以成功insert，但是一个数据页又存储不了你插入的数据。这时肯定会行溢出！ 其实在MySQL的设定中，发生行溢出并不是达到16384byte边缘才会发生。对于varchar、text等类型的行。当这种列存储的长度达到几百byte时就会发生行溢。 六、行 如何溢出？还是看这张图：在MySQL设定中，当varchar列长度达到768byte后，会将该列的前768byte当作当作prefix存放在行中，多出来的数据溢出存放到溢出页中，然后通过一个偏移量指针将两者关联起来，这就是行溢出机制。 七、思考一个问题不知道你有没有想过这样一个问题：首先你肯定知道，MySQL使用的是B+Tree的聚簇索引，在这棵B+Tree中非叶子节点是只存索引不存数据，叶子节点中存储着真实的数据。同时叶子结点指向数据页。那当单行存不下的时候，为啥不存储在两个数据页中呢？就像下图这样～。单个节点存储下，我用多个节点存总行吧！说不定这样我的B+Tee还能变大长高（这其实是错误的想法）这个错误的描述对应的脑图如下： 那MySQL不这样做的原因如下：MySQL想让一个数据页中能存放更多的数据行，至少也得要存放两行数据。否则就失去了B+Tree的意义。B+Tree也退化成一个低效的链表。你可以品一下这句蓝色的话，他说的每个数据页至少要存放两行数据的意思不是说 数据页不能只存一行。你确确实实可以只往里面写一行数据，然后去吃个饭，干点别的。一直让这个数据页中只有一行数据。 这句话的意思是，当你往这个数据页中写入一行数据时，即使它很大将达到了数据页的极限，但是通过行溢出机制。依然能保证你的下一条数据还能写入到这个数据页中。 存储引擎24.MySQL 有哪些常见存储引擎？MySQL 支持多种存储引擎，常见的有 MyISAM、InnoDB、MEMORY 等。—这部分是帮助理解 start，面试中可不背—我来做一个表格对比：—这部分是帮助理解 end，面试中可不背—除此之外，我还了解到：①、MySQL 5.5 之前，默认存储引擎是 MyISAM，5.5 之后是 InnoDB。②、InnoDB 支持的哈希索引是自适应的，不能人为干预。③、InnoDB 从 MySQL 5.6 开始，支持全文索引。④、InnoDB 的最小表空间略小于 10M，最大表空间取决于页面大小。如何切换 MySQL 的数据引擎？可以通过 alter table 语句来切换 MySQL 的数据引擎。ALTER TABLE your_table_name ENGINE=InnoDB;不过不建议，应该提前设计好到底用哪一种存储引擎。 25.存储引擎应该怎么选择？大多数情况下，使用默认的 InnoDB 就可以了，InnoDB 可以提供事务、行级锁、外键、B+ 树索引等能力。MyISAM 适合读多写少的场景。MEMORY 适合临时表，数据量不大的情况。因为数据都存放在内存，所以速度非常快。 26.InnoDB 和 MyISAM 主要有什么区别？InnoDB 和 MyISAM 的最大区别在于事务支持和锁机制。InnoDB 支持事务、行级锁，适合大多数业务系统；而 MyISAM 不支持事务，用的是表锁，查询快但写入性能差，适合读多写少的场景。 另外，从存储结构上来说，MyISAM 用三种格式的文件来存储，.frm 文件存储表的定义；.MYD 存储数据；.MYI 存储索引；而 InnoDB 用两种格式的文件来存储，.frm 文件存储表的定义；.ibd 存储数据和索引。 从索引类型上来说，MyISAM 为非聚簇索引，索引和数据分开存储，索引保存的是数据文件的指针。 InnoDB 为聚簇索引，索引和数据不分开。 更细微的层面上来讲，MyISAM 不支持外键，可以没有主键，表的具体行数存储在表的属性中，查询时可以直接返回；InnoDB 支持外键，必须有主键，具体行数需要扫描整个表才能返回，有索引的情况下会扫描索引。 InnoDB的内存结构了解吗？InnoDB 的内存区域主要有两块，buffer pool 和 log buffer。 buffer pool 用于缓存数据页和索引页，提升读写性能；log buffer 用于缓存 redo log，提升写入性能。InnoDB引擎框架图如下: 数据页的结构了解过吗InnoDB 的数据页由 7 部分组成，其中文件头、页头和文件尾的大小是固定的，分别为 38、56 和 8 个字节，用来标记该页的一些信息。行记录、空闲空间和页目录的大小是动态的，为实际的行记录存储空间。 真实的记录会按照指定的行格式存储到 User Records 中。 每个数据页的 File Header 都有一个上一页和下一页的编号，所有的数据页会形成一个双向链表。 在 InnoDB 中，默认的页大小是 16KB。可以通过 show variables like innodb_page_size; 查看。 27. InnoDB 的 Buffer Pool了解吗？Buffer Pool 是 InnoDB 存储引擎中的一个内存缓冲区，它会将经常使用的数据页、索引页加载进内存，读的时候先查询 Buffer Pool，如果命中就不用访问磁盘了。 如果没有命中，就从磁盘读取，并加载到 Buffer Pool，此时可能会触发页淘汰，将不常用的页移出 Buffer Pool。 写操作时不会直接写入磁盘，而是先修改内存中的页，此时页被标记为脏页，后台线程会定期将脏页刷新到磁盘。 Buffer Pool 可以显著减少磁盘的读写次数，从而提升 MySQL 的读写性能。 Buffer Pool 的默认大小是多少？本机上 InnoDB 的 Buffer Pool 默认大小是 128MB。 SHOW VARIABLES LIKE innodb_buffer_pool_size; 另外，在具有 1GB-4GB RAM 的系统上，默认值为系统 RAM 的 25%；在具有超过 4GB RAM 的系统上，默认值为系统 RAM 的 50%，但不超过 4GB。 InnoDB 对 LRU 算法的优化了解吗？LRU (least resently used)：近期最少使用 LFU (least freqently used)：频数最少使用 了解，InnoDB 对 LRU 算法进行了改良，最近访问的数据并不直接放到 LRU 链表的头部，而是放在一个叫 midpoiont 的位置。默认情况下，midpoint 位于 LRU 列表的 58 处。 比如 Buffer Pool 有 100 页，新页插入的位置大概是在第 80 页；当页数据被频繁访问后，再将其移动到 young 区，这样做的好处是热点页能长时间保留在内存中，不容易被挤出去。 —-这部分是帮助理解 start，面试中可不背—- 可以通过 innodb_old_blocks_pct 参数来调整 Buffer Pool 中 old 和 young 区的比例；通过 innodb_old_blocks_time 参数来调整页在 young 区的停留时间。 默认情况下，LRU 链表中 old 区占 37%；同一页再次访问提升的最小时间间隔是 1000 毫秒。也就是说，如果某页在 1 秒内被多次访问，只会计算一次，不会立刻升级为热点页，防止短时间批量访问导致缓存污染。 —-这部分是帮助理解 end，面试中可不背—- 日志28.MySQL 日志文件有哪些？有 6 大类，其中错误日志用于问题诊断，慢查询日志用于 SQL 性能分析，general log 用于记录所有的 SQL 语句，binlog 用于主从复制和数据恢复，redo log 用于保证事务持久性，undo log 用于事务回滚和 MVCC。 —-这部分是帮助理解 start，面试中可不背—- ①、错误日志（Error Log）：记录 MySQL 服务器启动、运行或停止时出现的问题。②、慢查询日志（Slow Query Log）：记录执行时间超过 long_query_time 值的所有 SQL 语句。这个时间值是可配置的，默认情况下，慢查询日志功能是关闭的。③、一般查询日志（General Query Log）：记录 MySQL 服务器的启动关闭信息，客户端的连接信息，以及更新、查询的 SQL 语句等。④、二进制日志（Binary Log）：记录所有修改数据库状态的 SQL 语句，以及每个语句的执行时间，如 INSERT、UPDATE、DELETE 等，但不包括 SELECT 和 SHOW 这类的操作。⑤、重做日志（Redo Log）：记录对于 InnoDB 表的每个写操作，不是 SQL 级别的，而是物理级别的，主要用于崩溃恢复。⑥、回滚日志（Undo Log，或者叫事务日志）：记录数据被修改前的值，用于事务的回滚。 —-这部分是帮助理解 end，面试中可不背—- 请重点说说 binlog？binlog 是一种物理日志，会在磁盘上记录数据库的所有修改操作。如果误删了数据，就可以使用 binlog 进行回退到误删之前的状态。 # 步骤1：恢复全量备份mysql -u root -p full_backup.sql# 步骤2：应用Binlog到指定时间点mysqlbinlog --start-datetime=2025-03-13 14:00:00 --stop-datetime=2025-03-13 15:00:00 binlog.000001 | mysql -u root -p 如果要搭建主从复制，就可以让从库定时读取主库的 binlog。MySQL 提供了三种格式的 binlog：Statement、Row 和 Mixed，分别对应 SQL 语句级别、行级别和混合级别，默认为行级别。从后缀名上来看，binlog 文件分为两类：以 .index 结尾的索引文件，以 .00000* 结尾的二进制日志文件。binlog 默认是没有启用的。 生产环境中是一定要启用的，可以通过在 my.cnf 文件中配置 log_bin 参数，以启用 binlog。 log_bin = mysql-bin #开启binlog#mysql-bin.*日志文件最大字节（单位：字节）#设置最大100MBmax_binlog_size=104857600#设置了只保留7天BINLOG（单位：天）expire_logs_days = 7#binlog日志只记录指定库的更新#binlog-do-db=db_name#binlog日志不记录指定库的更新#binlog-ignore-db=db_name#写缓冲多少次，刷一次磁盘，默认0sync_binlog=0 binlog 的配置参数都了解哪些？log_bin = mysql-bin 用于启用 binlog，这样就可以在 MySQL 的数据目录中找到 db-bin.000001、db-bin.000002 等日志文件。max_binlog_size=104857600 用于设置每个 binlog 文件的大小，不建议设置太大，网络传送起来比较麻烦。当 binlog 文件达到 max_binlog_size 时，MySQL 会关闭当前文件并创建一个新的 binlog 文件。expire_logs_days = 7 用于设置 binlog 文件的自动过期时间为 7 天。过期的 binlog 文件会被自动删除。防止长时间累积的 binlog 文件占用过多存储空间，所以这个配置很重要。binlog-do-db=db_name，指定哪些数据库表的更新应该被记录。binlog-ignore-db=db_name，指定忽略哪些数据库表的更新。sync_binlog=0，设置每多少次 binlog 写操作会触发一次磁盘同步操作。默认值为 0，表示 MySQL 不会主动触发同步操作，而是依赖操作系统的磁盘缓存策略。即当执行写操作时，数据会先写入缓存，当缓存区满了再由操作系统将数据一次性刷入磁盘。如果设置为 1，表示每次 binlog 写操作后都会同步到磁盘，虽然可以保证数据能够及时写入磁盘，但会降低性能。可以通过 show variables like %log_bin%; 查看 binlog 是否开启。 有了binlog为什么还要undolog redolog？binlog 属于 Server 层，与存储引擎无关，无法直接操作物理数据页。而 redo log 和 undo log 是 InnoDB 存储引擎实现 ACID的基石。————–ps————-ACID: **原子性(Atomicity)**：事务是一个不可分割的工作单位，事务中的操作要么全部成功，要么全部失败回滚通过undo log实现，记录事务开始前的状态，用于回滚 **一致性(Consistency)**：事务执行前后，数据库从一个一致状态转变为另一个一致状态通过其他三个特性(AID)共同保证 **隔离性(Isolation)**：多个并发事务执行时，一个事务的执行不应影响其他事务通过锁机制和MVCC(多版本并发控制)实现 **持久性(Durability)**：事务一旦提交，其结果就是永久性的通过redo log实现，即使系统崩溃也能恢复数据 ————–ps————- binlog 关注的是逻辑变更的全局记录；redo log 用于确保物理变更的持久性，确保事务最终能够刷盘成功；undo log 是逻辑逆向操作日志，记录的是旧值，方便恢复到事务开始前的状态。 另外一种回答方式。 binlog 会记录整个 SQL 或行变化；redo log 是为了恢复已提交但未刷盘的数据，undo log 是为了撤销未提交的事务。 以一次事务更新为例： # 开启事务BEGIN;# 更新数据UPDATE users SET age = age + 1 WHERE id = 1;# 提交事务COMMIT; 事务开始的时候会生成 undo log，记录更新前的数据，比如原值是 18： undo log: id=1, age=18 修改数据的时候，会将数据写入到 redo log。 比如数据页 page_id=123 上，id1 的用户被更新为 age26： redo log (prepare): page_id=123, offset=0x40, before=18, after=26 等事务提交的时候，redo log 刷盘，binlog 刷盘。 binlog 写完之后，redo log 的状态会变为 commit： redo log (commit): page_id=123, offset=0x40, before=18, after=26 binlog 如果是 Statement 格式，会记录一条 SQL 语句： UPDATE users SET age age + 1 WHERE id 1;binlog 如果是 Row 格式，会记录： 表：usersbefore: id=1, age=18after: id=1, age=26 随后，后台线程会将 redo log 中的变更异步刷新到磁盘。 详细探究一下binlog(长文警告⚠️):MySQL 的 Binlog 日志是一种二进制格式的日志，Binlog 记录所有的 DDL 和 DML 语句(除了数据查询语句SELECT、SHOW等)，以 Event 的形式记录，同时记录语句执行时间。 Binlog 的主要作用有两个：1. 数据恢复:因为 Binlog 详细记录了所有修改数据的 SQL，当某一时刻的数据误操作而导致出问题，或者数据库宕机数据丢失，那么可以根据 Binlog 来回放历史数据。2. 主从复制:想要做多机备份的业务，可以去监听当前写库的 Binlog 日志，同步写库的所有更改。 Binlog 包括两类文件：二进制日志索引文件(.index)：记录所有的二进制文件。二进制日志文件(.00000*)：记录所有 DDL 和 DML 语句事件。 Binlog 日志功能默认是开启的，线上情况下 Binlog 日志的增长速度是很快的，在 MySQL 的配置文件 my.cnf 中提供一些参数来对 Binlog 进行设置。 #设置此参数表示启用binlog功能，并制定二进制日志的存储目录log-bin=/home/mysql/binlog/#mysql-bin.*日志文件最大字节（单位：字节）#设置最大100MBmax_binlog_size=104857600#设置了只保留7天BINLOG（单位：天）expire_logs_days = 7#binlog日志只记录指定库的更新#binlog-do-db=db_name#binlog日志不记录指定库的更新#binlog-ignore-db=db_name#写缓冲多少次，刷一次磁盘，默认0sync_binlog=0 需要注意的是：max_binlog_size ：Binlog 最大和默认值是 1G，该设置并不能严格控制 Binlog 的大小，尤其是 Binlog 比较靠近最大值而又遇到一个比较大事务时，为了保证事务的完整性不可能做切换日志的动作，只能将该事务的所有 SQL 都记录进当前日志直到事务结束。所以真实文件有时候会大于 max_binlog_size 设定值。expire_logs_days ：Binlog 过期删除不是服务定时执行，是需要借助事件触发才执行，事件包括： 服务器重启 服务器被更新 日志达到了最大日志长度 max_binlog_size 日志被刷新 二进制日志由配置文件的 log-bin 选项负责启用，MySQL 服务器将在数据根目录创建两个新文件mysql-bin.000001 和 mysql-bin.index，若配置选项没有给出文件名，MySQL 将使用主机名称命名这两个文件，其中 .index 文件包含一份全体日志文件的清单。 sync_binlog：这个参数决定了 Binlog 日志的更新频率。默认 0 ，表示该操作由操作系统根据自身负载自行决定多久写一次磁盘。 sync_binlog = 1 表示每一条事务提交都会立刻写盘。sync_binlog=n 表示 n 个事务提交才会写盘。 根据 MySQL 文档，写 Binlog 的时机是：SQL transaction 执行完，但任何相关的 Locks 还未释放或事务还未最终 commit 前。这样保证了 Binlog 记录的操作时序与数据库实际的数据变更顺序一致。 检查 Binlog 文件是否已开启： mysql show variables like %log_bin%;+---------------------------------+------------------------------------+| Variable_name | Value |+---------------------------------+------------------------------------+| log_bin | ON || log_bin_basename | /usr/local/mysql/data/binlog || log_bin_index | /usr/local/mysql/data/binlog.index || log_bin_trust_function_creators | OFF || log_bin_use_v1_row_events | OFF || sql_log_bin | ON |+---------------------------------+------------------------------------+6 rows in set (0.00 sec) MySQL 会把用户对所有数据库的内容和结构的修改情况记入 mysql-bin.n 文件，而不会记录 SELECT 和没有实际更新的 UPDATE 语句。 如果你不知道现在有哪些 Binlog 文件，可以使用如下命令： show binary logs; #查看binlog列表show master status; #查看最新的binlogmysql show binary logs;+------------------+-----------+-----------+| Log_name | File_size | Encrypted |+------------------+-----------+-----------+| mysql-bin.000001 | 179 | No || mysql-bin.000002 | 156 | No |+------------------+-----------+-----------+2 rows in set (0.00 sec) Binlog 文件是二进制文件，强行打开看到的必然是乱码，MySQL 提供了命令行的方式来展示 Binlog 日志： mysqlbinlog mysql-bin.000002 | more mysqlbinlog 命令即可查看。虽然看起来凌乱其实也有迹可循。Binlog 通过事件的方式来管理日志信息，可以通过 show binlog events in 的语法来查看当前 Binlog 文件对应的详细事件信息。 mysql show binlog events in mysql-bin.000001;+------------------+-----+----------------+-----------+-------------+-----------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+------------------+-----+----------------+-----------+-------------+-----------------------------------+| mysql-bin.000001 | 4 | Format_desc | 1 | 125 | Server ver: 8.0.21, Binlog ver: 4 || mysql-bin.000001 | 125 | Previous_gtids | 1 | 156 | || mysql-bin.000001 | 156 | Stop | 1 | 179 | |+------------------+-----+----------------+-----------+-------------+-----------------------------------+3 rows in set (0.01 sec) 这是一份没有任何写入数据的 Binlog 日志文件。Binlog 的版本是V4，可以看到日志的结束时间为 Stop。出现 Stop event 有两种情况： 是 master shut down 的时候会在 Binlog 文件结尾出现 是备机在关闭的时候会写入 relay log 结尾，或者执行 RESET SLAVE 命令执行 本文出现的原因是我有手动停止过 MySQL 服务。一般来说一份正常的 Binlog 日志文件会以 Rotate event 结束。当 Binlog 文件超过指定大小，Rotate event 会写在文件最后，指向下一个 Binlog 文件。我们来看看有过数据操作的 Binlog 日志文件是什么样子的。 mysql show binlog events in mysql-bin.000002;+------------------+-----+----------------+-----------+-------------+-----------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+------------------+-----+----------------+-----------+-------------+-----------------------------------+| mysql-bin.000002 | 4 | Format_desc | 1 | 125 | Server ver: 8.0.21, Binlog ver: 4 || mysql-bin.000002 | 125 | Previous_gtids | 1 | 156 | |+------------------+-----+----------------+-----------+-------------+-----------------------------------+2 rows in set (0.00 sec) 上面是没有任何数据操作且没有被截断的 Binlog。接下来我们插入一条数据，再看看 Binlog 事件。 mysql show binlog events in mysql-bin.000002;+------------------+-----+----------------+-----------+-------------+-------------------------------------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+------------------+-----+----------------+-----------+-------------+-------------------------------------------------------------------------+| mysql-bin.000002 | 4 | Format_desc | 1 | 125 | Server ver: 8.0.21, Binlog ver: 4 || mysql-bin.000002 | 125 | Previous_gtids | 1 | 156 | || mysql-bin.000002 | 156 | Anonymous_Gtid | 1 | 235 | SET @@SESSION.GTID_NEXT= ANONYMOUS || mysql-bin.000002 | 235 | Query | 1 | 323 | BEGIN || mysql-bin.000002 | 323 | Intvar | 1 | 355 | INSERT_ID=13 || mysql-bin.000002 | 355 | Query | 1 | 494 | use `test_db`; INSERT INTO `test_db`.`test_db`(`name`) VALUES (xdfdf) || mysql-bin.000002 | 494 | Xid | 1 | 525 | COMMIT /* xid=192 */ |+------------------+-----+----------------+-----------+-------------+-------------------------------------------------------------------------+7 rows in set (0.00 sec) 这是加入一条数据之后的 Binlog 事件。 我们对 event 查询的数据行关键字段来解释一下： Pos：当前事件的开始位置，每个事件都占用固定的字节大小，结束位置(End_log_position)减去Pos，就是这个事件占用的字节数。上面的日志中我们能看到，第一个事件位置并不是从 0 开始，而是从 4。MySQL 通过文件中的前 4 个字节，来判断这是不是一个 Binlog 文件。这种方式很常见，很多格式的文件，如 pdf、doc、jpg等，都会通常前几个特定字符判断是否是合法文件。 Event_type：表示事件的类型 Server_id：表示产生这个事件的 MySQL server_id，通过设置 my.cnf 中的 server-id 选项进行配置 End_log_position：下一个事件的开始位置 Info：包含事件的具体信息 Binlog 日志格式:针对不同的使用场景，Binlog 也提供了可定制化的服务，提供了三种模式来提供不同详细程度的日志内容。 Statement 模式：基于 SQL 语句的复制(statement-based replication-SBR) Row 模式：基于行的复制(row-based replication-RBR) Mixed 模式：混合模式复制(mixed-based replication-MBR) Statement 模式保存每一条修改数据的SQL。该模式只保存一条普通的SQL语句，不涉及到执行的上下文信息。因为每台 MySQL 数据库的本地环境可能不一样，那么对于依赖到本地环境的函数或者上下文处理的逻辑 SQL 去处理的时候可能同样的语句在不同的机器上执行出来的效果不一致。比如像 sleep()函数，last_insert_id()函数，等等，这些都跟特定时间的本地环境有关。 Row 模式MySQL V5.1.5 版本开始支持Row模式的 Binlog，它与 Statement 模式的区别在于它不保存具体的 SQL 语句，而是记录具体被修改的信息。比如一条 update 语句更新10条数据，如果是 Statement 模式那就保存一条 SQL 就够，但是 Row 模式会保存每一行分别更新了什么，有10条数据。Row 模式的优缺点就很明显了。保存每一个更改的详细信息必然会带来存储空间的快速膨胀，换来的是事件操作的详细记录。所以要求越高代价越高。 Mixed 模式Mixed 模式即以上两种模式的综合体。既然上面两种模式分别走了极简和一丝不苟的极端，那是否可以区分使用场景的情况下将这两种模式综合起来呢？在 Mixed 模式中，一般的更新语句使用 Statement 模式来保存 Binlog，但是遇到一些函数操作，可能会影响数据准确性的操作则使用 Row 模式来保存。这种方式需要根据每一条具体的 SQL 语句来区分选择哪种模式。MySQL 从 V5.1.8 开始提供 Mixed 模式，V5.7.7 之前的版本默认是Statement 模式，之后默认使用Row模式， 但是在 8.0 以上版本已经默认使用 Mixed 模式了。 查询当前 Binlog 日志使用格式： mysql show global variables like %binlog_format%;+---------------------------------+---------+| Variable_name | Value |+---------------------------------+---------+| binlog_format | MIXED || default_week_format | 0 || information_schema_stats_expiry | 86400 || innodb_default_row_format | dynamic || require_row_format | OFF |+---------------------------------+---------+5 rows in set (0.01 sec) 如何通过 mysqlbinlog 命令手动恢复数据上面说过每一条 event 都有位点信息，如果我们当前的 MySQL 库被无操作或者误删除了，那么该如何通过 Binlog 来恢复到删除之前的数据状态呢？首先发现误操作之后，先停止 MySQL 服务，防止继续更新。接着通过 mysqlbinlog命令对二进制文件进行分析，查看误操作之前的位点信息在哪里。接下来肯定就是恢复数据，当前数据库的数据已经是错的，那么就从开始位置到误操作之前位点的数据肯定的都是正确的；如果误操作之后也有正常的数据进来，这一段时间的位点数据也要备份。比如说：误操作的位点开始值为 501，误操作结束的位置为705，之后到800的位点都是正确数据。那么从 0 - 500 ，706 - 800 都是有效数据，接着我们就可以进行数据恢复了。先将数据库备份并清空。接着使用 mysqlbinlog 来恢复数据：0 - 500 的数据： mysqlbinlog --start-position=0 --stop-position=500 bin-log.000003 /root/back.sql; 上面命令的作用就是将 0 -500 位点的数据恢复到自定义的 SQL 文件中。同理 706 - 800 的数据也是一样操作。之后我们执行这两个 SQL 文件就行了。 Binlog 事件类型上面我们说到了 Binlog 日志中的事件，不同的操作会对应着不同的事件类型，且不同的 Binlog 日志模式同一个操作的事件类型也不同，下面我们一起看看常见的事件类型。首先我们看看源码中的事件类型定义：源码位置：libbinlogeventsincludebinlog_event.h enum Log_event_type /** Every time you update this enum (when you add a type), you have to fix Format_description_event::Format_description_event(). */ UNKNOWN_EVENT= 0, START_EVENT_V3= 1, QUERY_EVENT= 2, STOP_EVENT= 3, ROTATE_EVENT= 4, INTVAR_EVENT= 5, LOAD_EVENT= 6, SLAVE_EVENT= 7, CREATE_FILE_EVENT= 8, APPEND_BLOCK_EVENT= 9, EXEC_LOAD_EVENT= 10, DELETE_FILE_EVENT= 11, /** NEW_LOAD_EVENT is like LOAD_EVENT except that it has a longer sql_ex, allowing multibyte TERMINATED BY etc; both types share the same class (Load_event) */ NEW_LOAD_EVENT= 12, RAND_EVENT= 13, USER_VAR_EVENT= 14, FORMAT_DESCRIPTION_EVENT= 15, XID_EVENT= 16, BEGIN_LOAD_QUERY_EVENT= 17, EXECUTE_LOAD_QUERY_EVENT= 18, TABLE_MAP_EVENT = 19, /** The PRE_GA event numbers were used for 5.1.0 to 5.1.15 and are therefore obsolete. */ PRE_GA_WRITE_ROWS_EVENT = 20, PRE_GA_UPDATE_ROWS_EVENT = 21, PRE_GA_DELETE_ROWS_EVENT = 22, /** The V1 event numbers are used from 5.1.16 until mysql-trunk-xx */ WRITE_ROWS_EVENT_V1 = 23, UPDATE_ROWS_EVENT_V1 = 24, DELETE_ROWS_EVENT_V1 = 25, /** Something out of the ordinary happened on the master */ INCIDENT_EVENT= 26, /** Heartbeat event to be send by master at its idle time to ensure masters online status to slave */ HEARTBEAT_LOG_EVENT= 27, /** In some situations, it is necessary to send over ignorable data to the slave: data that a slave can handle in case there is code for handling it, but which can be ignored if it is not recognized. */ IGNORABLE_LOG_EVENT= 28, ROWS_QUERY_LOG_EVENT= 29, /** Version 2 of the Row events */ WRITE_ROWS_EVENT = 30, UPDATE_ROWS_EVENT = 31, DELETE_ROWS_EVENT = 32, GTID_LOG_EVENT= 33, ANONYMOUS_GTID_LOG_EVENT= 34, PREVIOUS_GTIDS_LOG_EVENT= 35, TRANSACTION_CONTEXT_EVENT= 36, VIEW_CHANGE_EVENT= 37, /* Prepared XA transaction terminal event similar to Xid */ XA_PREPARE_LOG_EVENT= 38, /** Add new events here - right above this comment! Existing events (except ENUM_END_EVENT) should never change their numbers */ ENUM_END_EVENT /* end marker */; 这么多的事件类型我们就不一一介绍，挑出来一些常用的来看看。FORMAT_DESCRIPTION_EVENTFORMAT_DESCRIPTION_EVENT 是 Binlog V4 中为了取代之前版本中的 START_EVENT_V3 事件而引入的。它是 Binlog 文件中的第一个事件，而且，该事件只会在 Binlog 中出现一次。MySQL 根据 FORMAT_DESCRIPTION_EVENT 的定义来解析其它事件。它通常指定了 MySQL 的版本，Binlog 的版本，该 Binlog 文件的创建时间。 QUERY_EVENT QUERY_EVENT 类型的事件通常在以下几种情况下使用： 事务开始时，执行的 BEGIN 操作STATEMENT 格式中的 DML 操作ROW 格式中的 DDL 操作比如上文我们插入一条数据之后的 Binlog 日志： mysql show binlog events in mysql-bin.000002;+------------------+-----+----------------+-----------+-------------+-------------------------------------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+------------------+-----+----------------+-----------+-------------+-------------------------------------------------------------------------+| mysql-bin.000002 | 4 | Format_desc | 1 | 125 | Server ver: 8.0.21, Binlog ver: 4 || mysql-bin.000002 | 125 | Previous_gtids | 1 | 156 | || mysql-bin.000002 | 156 | Anonymous_Gtid | 1 | 235 | SET @@SESSION.GTID_NEXT= ANONYMOUS || mysql-bin.000002 | 235 | Query | 1 | 323 | BEGIN || mysql-bin.000002 | 323 | Intvar | 1 | 355 | INSERT_ID=13 || mysql-bin.000002 | 355 | Query | 1 | 494 | use `test_db`; INSERT INTO `test_db`.`test_db`(`name`) VALUES (xdfdf) || mysql-bin.000002 | 494 | Xid | 1 | 525 | COMMIT /* xid=192 */ |+------------------+-----+----------------+-----------+-------------+-------------------------------------------------------------------------+7 rows in set (0.00 sec) XID_EVENT在事务提交时，不管是 STATEMENT 还 是ROW 格式的 Binlog，都会在末尾添加一个 XID_EVENT 事件代表事务的结束。该事件记录了该事务的 ID，在 MySQL 进行崩溃恢复时，根据事务在 Binlog 中的提交情况来决定是否提交存储引擎中状态为 prepared 的事务。ROWS_EVENT对于 ROW 格式的 Binlog，所有的 DML 语句都是记录在 ROWS_EVENT 中。ROWS_EVENT分为三种：WRITE_ROWS_EVENTUPDATE_ROWS_EVENTDELETE_ROWS_EVENT分别对应 insert，update 和 delete 操作。对于 insert 操作，WRITE_ROWS_EVENT 包含了要插入的数据。对于 update 操作，UPDATE_ROWS_EVENT 不仅包含了修改后的数据，还包含了修改前的值。对于 delete 操作，仅仅需要指定删除的主键（在没有主键的情况下，会给定所有列）。 对比 QUERY_EVENT 事件，是以文本形式记录 DML 操作的。而对于 ROWS_EVENT 事件，并不是文本形式，所以在通过 mysqlbinlog 查看基于 ROW 格式的 Binlog 时，需要指定 -vv –base64-outputdecode-rows。 我们来测试一下，首先将日志格式改为 Rows： mysql set binlog_format=row;Query OK, 0 rows affected (0.00 sec)mysqlmysql flush logs;Query OK, 0 rows affected (0.01 sec) 然后刷新一下日志文件，重新开始一个 Binlog 日志。我们插入一条数据之后看一下日志： mysql show binlog events in binlog.000008;+---------------+-----+----------------+-----------+-------------+--------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+---------------+-----+----------------+-----------+-------------+--------------------------------------+| binlog.000008 | 4 | Format_desc | 1 | 125 | Server ver: 8.0.21, Binlog ver: 4 || binlog.000008 | 125 | Previous_gtids | 1 | 156 | || binlog.000008 | 156 | Anonymous_Gtid | 1 | 235 | SET @@SESSION.GTID_NEXT= ANONYMOUS || binlog.000008 | 235 | Query | 1 | 313 | BEGIN || binlog.000008 | 313 | Table_map | 1 | 377 | table_id: 85 (test_db.test_db) || binlog.000008 | 377 | Write_rows | 1 | 423 | table_id: 85 flags: STMT_END_F || binlog.000008 | 423 | Xid | 1 | 454 | COMMIT /* xid=44 */ |+---------------+-----+----------------+-----------+-------------+--------------------------------------+7 rows in set (0.01 sec) 说说 redo log 的工作机制？当事务启动时，MySQL 会为该事务分配一个唯一标识符。在事务执行过程中，每次对数据进行修改，MySQL 都会生成一条 Redo Log，记录修改前后的数据状态。这些 Redo Log 首先会被写入内存中的 Redo Log Buffer。当事务提交时，MySQL 再将 Redo Log Buffer 中的记录刷新到磁盘上的 Redo Log 文件中。只有当 Redo Log 成功写入磁盘，事务才算真正提交成功。当 MySQL 崩溃重启时，会先检查 Redo Log。对于已提交的事务，MySQL 会重放 Redo Log 中的记录。对于未提交的事务，MySQL 会通过 Undo Log 回滚这些修改，确保数据恢复到崩溃前的一致性状态。Redo Log 是循环使用的，当文件写满后会覆盖最早的记录。为避免覆盖未持久化的记录，MySQL 会定期执行 CheckPoint 操作，将内存中的数据页刷新到磁盘，并记录 CheckPoint 点。 重启时，MySQL 只会重放 CheckPoint 之后的 Redo Log，从而提高恢复效率。 省流版: 事务开始 记录undo log（旧数据） 修改Buffer Pool中的数据 写入redo log（prepare状态） 写入binlog 提交事务（redo log标记为commit） 后台异步刷脏页到磁盘 redo log 文件的大小是固定的吗？redo log 文件是固定大小的，通常配置为一组文件，使用环形方式写入，旧的日志会在空间需要时被覆盖。 命名方式为 ib_logfile0、iblogfile1、、、iblogfilen。默认 2 个文件，每个文件大小为 48MB。可以通过 show variables like innodb_log_file_size; 查看 redo log 文件的大小；通过 show variables like innodb_log_files_in_group; 查看 redo log 文件的数量。 说一说WAL?WAL——Write-Ahead Logging。 预写日志是 InnoDB 实现事务持久化的核心机制，它的思想是：先写日志再刷磁盘。即在修改数据页之前，先将修改记录写入 Redo Log。这样的话，即使数据页尚未写入磁盘，系统崩溃时也能通过 Redo Log 恢复数据。—-这部分是帮助理解 start，面试中可不背—-解释一下为什么需要 WAL：数据最终是要写入磁盘的，但磁盘 IO 很慢；如果每次更新都立刻把数据页刷盘，性能很差；如果还没写入磁盘就宕机，事务会丢失。WAL 的好处是更新时不直接写数据页，而是先写一份变更记录到 redo log，后台再慢慢把真正的数据页刷盘，一举多得。—-这部分是帮助理解 end，面试中可不背—- 29.binlog 和 redo log 有什么区别？binlog 由 MySQL 的 Server 层实现，与存储引擎无关；redo log 由 InnoDB 存储引擎实现。 binlog 记录的是逻辑日志，包括原始的 SQL 语句或者行数据变化，例如“将 id2 这行数据的 age 字段+1”。redo log 记录物理日志，即数据页的具体修改，例如“将 page_id123 上 offset0x40 的数据从 18 修改为 26”。binlog 是追加写入的，文件写满后会新建文件继续写入，不会覆盖历史日志，保存的是全量操作记录；redo log 是循环写入的，空间是固定的，写满后会覆盖旧的日志，仅保存未刷盘的脏页日志，已持久化的数据会被清除。另外，为保证两种日志的一致性，innodb 采用了两阶段提交策略，redo log 在事务执行过程中持续写入，并在事务提交前进入 prepare 状态；binlog 在事务提交的最后阶段写入，之后 redo log 会被标记为 commit 状态。可以通过回放 binlog 实现数据同步或者恢复到指定时间点；redo log 用来确保事务提交后即使系统宕机，数据仍然可以通过重放 redo log 恢复。 30.为什么要两阶段提交?为了保证 redo log 和 binlog 中的数据一致性，防止主从复制和事务状态不一致。 为什么 2PC 能保证 redo log 和 binlog 的强⼀致性？假如 MySQL 在预写 redo log 之后、写入 binlog 之前崩溃。那么 MySQL 重启后 InnoDB 会回滚该事务，因为 redo log 不是提交状态。并且由于 binlog 中没有写入数据，所以从库也不会有该事务的数据。 假如 MySQL 在写入 binlog 之后、redo log 提交之前崩溃。那么 MySQL 重启后 InnoDB 会提交该事务，因为 redo log 是提交状态。并且由于 binlog 中有写入数据，所以从库也会同步到该事务的数据。伪代码如下: // 事务开始begin;// try // 执行 SQL execute SQL; // 写入 redo log 并标记为 prepare write redo log prepare xid; // 写入 binlog write binlog xid sql; // 提交 redo log commit redo log xid;// catch // 回滚 redo log innodb rollback redo log xid;// 事务结束end; XID 了解吗？XID 是 binlog 中用来标识事务提交的唯一标识符。 在事务提交时，会写入一个 XID_EVENT 到 binlog，表示这个事务真正完成了。 Log_name | Pos | Event_type | Server_id | End_log_pos | Info | mysql-bin.000003 | 2005 | Gtid | 1013307 | 2070 | SET @@SESSION.GTID_NEXT= f971d5f1-d450-11ec-9e7b-5254000a56df:11 || mysql-bin.000003 | 2070 | Query | 1013307 | 2142 | BEGIN || mysql-bin.000003 | 2142 | Table_map | 1013307 | 2187 | table_id: 109 (test.t1) || mysql-bin.000003 | 2187 | Write_rows | 1013307 | 2227 | table_id: 109 flags: STMT_END_F || mysql-bin.000003 | 2227 | Xid | 1013307 | 2258 | COMMIT /* xid=121 */ 它不仅用于主从复制中事务完整性的判断，也在崩溃恢复中对 redo log 和 binlog 的一致性校验起到关键作用。 XID 可以帮助 MySQL 判断哪些 redo log 是已提交的，哪些是未提交需要回滚的，是两阶段提交机制中非常关键的一环。 31.redo log 的写入过程了解吗？InnoDB 会先将 Redo Log 写入内存中的 Redo Log Buffer，之后再以一定的频率刷入到磁盘的 Redo Log File 中。 哪些场景会触发 redo log 的刷盘动作？比如说 Redo Log Buffer 的空间不足时，事务提交时，触发 Checkpoint 时，后台线程定期刷盘时。不过，Redo Log Buffer 刷盘到 Redo Log File 还会涉及到操作系统的磁盘缓存策略，可能不会立即刷盘，而是等待一定时间后才刷盘。 innodb_flush_log_at_trx_commit 参数你了解多少？innodb_flush_log_at_trx_commit 参数是用来控制事务提交时，Redo Log 的刷盘策略，一共有三种。 0 表示事务提交时不刷盘，而是交给后台线程每隔 1 秒执行一次。这种方式性能最好，但是在 MySQL 宕机时可能会丢失一秒内的事务。 1 表示事务提交时会立即刷盘，确保事务提交后数据就持久化到磁盘。这种方式是最安全的，也是 InnoDB 的默认值。 2 表示事务提交时只把 Redo Log Buffer 写入到 Page Cache，由操作系统决定什么时候刷盘。操作系统宕机时，可能会丢失一部分数据。 一个没有提交事务的 redo log，会不会刷盘？InnoDB 有一个后台线程，每隔 1 秒会把Redo Log Buffer中的日志写入到文件系统的缓存中，然后调用刷盘操作。 因此，一个没有提交事务的 Redo Log 也可能会被刷新到磁盘中。另外，如果当 Redo Log Buffer 占用的空间即将达到 innodb_log_buffer_size 的一半时，也会触发刷盘操作。 Redo Log Buffer 是顺序写还是随机写？MySQL 在启动后会向操作系统申请一块连续的内存空间作为 Redo Log Buffer，并将其分为若干个连续的 Redo Log Block。那为了提高写入效率，Redo Log Buffer 采用了顺序写入的方式，会先往前面的 Redo Log Block 中写入，当写满后再往后面的 Block 中写入。于此同时，InnoDB 还提供了一个全局变量 buf_free，来控制后续的 redo log 记录应该写入到 block 中的哪个位置。 buf_next_to_write 了解吗？buf_next_to_write 指向 Redo Log Buffer 中下一次需要写入硬盘的起始位置。 而 buf_free 指向的是 Redo Log Buffer 中空闲区域的起始位置。 了解 MTR 吗？Mini Transaction 是 InnoDB 内部用于操作数据页的原子操作单元。 mtr_t mtr;mtr_start(mtr);// 1. 加锁// 对待访问的index加锁mtr_s_lock(rw_lock_t, mtr);mtr_x_lock(rw_lock_t, mtr);// 对待读写的page加锁mtr_memo_push(mtr, buf_block_t, MTR_MEMO_PAGE_S_FIX);mtr_memo_push(mtr, buf_block_t, MTR_MEMO_PAGE_X_FIX);// 2. 访问或修改pagebtr_cur_search_to_nth_levelbtr_cur_optimistic_insert// 3. 为修改操作生成redomlog_openmlog_write_initial_log_record_fastmlog_close// 4. 持久化redo，解锁mtr_commit(mtr); 多个事务的 Redo Log 会以 MTR 为单位交替写入到 Redo Log Buffer 中，假如事务 1 和事务 2 均有两个 MTR，一旦某个 MTR 结束，就会将其生成的若干条 Redo Log 记录顺序写入到 Redo Log Buffer 中。 也就是说，一个 MTR 会包含一组 Redo Log 记录，是 MySQL 崩溃后恢复事务的最小执行单元。 Redo Log Block 的结构了解吗？Redo Log Block 由日志头、日志体和日志尾组成，一共占用 512 个字节，其中日志头占用 12 个字节，日志尾占用 4 个字节，剩余的 496 个字节用于存储日志体。日志头包含了当前 Block 的序列号、第一条日志的序列号、类型等信息。日志尾主要存储的是 LOG_BLOCK_CHECKSUM，也就是 Block 的校验和，主要用于判断 Block 是否完整。 Redo Log Block 为什么设计成 512 字节？因为机械硬盘的物理扇区大小通常为 512 字节，Redo Log Block 也设计为同样的大小，就可以确保每次写入都是整数个扇区，减少对齐开销。 比如说操作系统的页缓存默认为 4KB，8 个 Redo Log Block 就可以组合成一个页缓存单元，从而提升 Redo Log Buffer 的写入效率。 LSN 了解吗？Log Sequence Number 是一个 8 字节的单调递增整数，用来标识事务写入 redo log 的字节总量，存在于 redo log、数据页头部和 checkpoint 中。 —-这部分是帮助理解 start，面试中可不背—-MySQL 在第一次启动时，LSN 的初始值并不为 0，而是 8704；当 MySQL 再次启动时，会继续使用上一次服务停止时的 LSN。 在计算 LSN 的增量时，不仅需要考虑 log block body 的大小，还需要考虑 log block header 和 log block tail 中部分字节数。 比如说在上图中，事务 3 的 MTR 总量为 300 字节，那么写入到 Redo Log Buffer 中的 LSN 会增长为 8704 + 300 + 12 9016。 假如事务 4 的 MTR 总量为 900 字节，那么再次写入到 Redo Log Buffer 中的 LSN 会增长为 9016 + 900 + 122 + 42 9948。 2 个 12 字节的 log block header + 2 个 4 字节的 log block tail。 —-这部分是帮助理解 end，面试中可不背—- 核心作用有三个： 第一，redo log 按照 LSN 递增顺序记录所有数据的修改操作。LSN 的递增量等于每次写入日志的字节数。 第二，InnoDB 的每个数据页头部中，都会记录该页最后一次刷新到磁盘时的 LSN。如果数据页的 LSN 小于 redo log 的 LSN，说明该页需要从日志中恢复；否则说明该页已更新。 第三，checkpoint 通过 LSN 记录已刷新到磁盘的数据页位置，减少恢复时需要处理的日志。 —-这部分是帮助理解 start，面试中可不背—- 可以通过 show engine innodb status; 查看当前的 LSN 信息。 Log sequence number：当前系统最大 LSN（已生成的日志总量）。 Log flushed up to：已写入磁盘的 redo log LSN。 Pages flushed up to：已刷新到数据页的 LSN。 Last checkpoint at：最后一次检查点的 LSN，表示已持久化的数据状态。 —-这部分是帮助理解 end，面试中可不背—- Checkpoint 了解多少？Checkpoint 是 InnoDB 为了保证事务持久性和回收 redo log 空间的一种机制。 它的作用是在合适的时机将部分脏页刷入磁盘，比如说 buffer pool 的容量不足时。并记录当前 LSN 为 Checkpoint LSN，表示这个位置之前的 redo log file 已经安全，可以被覆盖了。 MySQL 崩溃恢复时只需要从 Checkpoint 之后开始恢复 redo log 就可以了，这样可以最大程度减少恢复所花费的时间。 redo log file 的写入是循环的，其中有两个标记位置非常重要，也就是 Checkpoint 和 write pos。 write pos 是 redo log 当前写入的位置，Checkpoint 是可以被覆盖的位置。 当 write pos 追上 Checkpoint 时，表示 redo log 日志已经写满。这时候就要暂停写入并强制刷盘，释放可覆写的日志空间。 关于redo log 的调优参数了解多少？如果是高并发写入的电商系统，可以最大化写入吞吐量，容忍秒级数据丢失的风险。 innodb_flush_log_at_trx_commit = 2sync_binlog = 1000innodb_redo_log_capacity = 64Ginnodb_io_capacity = 5000innodb_lru_scan_depth = 512innodb_log_buffer_size = 256M 如果是金融交易系统，需要保证数据零丢失，接受较低的吞吐量。 innodb_flush_log_at_trx_commit = 1sync_binlog = 1innodb_redo_log_capacity = 32Ginnodb_io_capacity = 2000innodb_lru_scan_depth = 1024 核心参数一览表: 总结 对数据一致性要求高的场景，如金融交易使用innodb_flush_log_at_trx_commit1，对写入吞吐量敏感的场景，如日志采集可以使用 2 或 0，需要结合 sync_binlog 参数 sync_binlog 参数控制 binlog 的刷盘策略，可以设置为 0、1、N，0 表示依赖系统刷盘，1 表示每次事务提交都刷盘（推荐与 innodb_flush_log_at_trx_commit1 搭配），N1000 表示累计 1000 次事务后刷盘 innodb_redo_log_capacity 动态调整 Redo Log 总容量，可以根据业务负载情况调整，建议设置为 1 小时写入量的峰值（如每秒 10MB 写入则设为 36GB） innodb_io_capacity 定义 InnoDB 后台线程的每秒 IO 操作上限，直接影响脏页刷新速率；机械硬盘建议 200-500，SSD 建议 1000-2000，NVMe SSD 可设为 5000+ innodb_lru_scan_depth 控制每个缓冲池实例中 LRU 列表的扫描深度，决定每秒可刷新的脏页数量，默认值 1024 适用于多数场景，IO 密集型负载可适当降低（如 512），减少 CPU 开销。 SQL优化🌟32.什么是慢 SQL？拓展阅读: https://juejin.cn/post/7048974570228809741MySQL 中有一个叫long_query_time的参数，原则上执行时间超过该参数值的 SQL 就是慢 SQL，会被记录到慢查询日志中。 —-这部分是帮助理解 start，面试中可不背—- 可通过 show variables like ‘long_query_time’; 查看当前的 long_query_time 的参数值。—-这部分是帮助理解 end，面试中可不背—- SQL 的执行过程了解吗？SQL 的执行过程大致可以分为六个阶段：连接管理、语法解析、语义分析、查询优化、执行器调度、存储引擎读写等。Server 层负责理解和规划 SQL 怎么执行，存储引擎层负责数据的真正读写。 —-这部分是帮助理解 start，面试中可不背—- 来详细拆解一下： 客户端发送 SQL 语句给 MySQL 服务器。 如果查询缓存打开则会优先查询缓存，缓存中有对应的结果就直接返回。不过，MySQL 8.0 已经移除了查询缓存。这部分的功能正在被 Redis 等缓存中间件取代。 分析器对 SQL 语句进行语法分析，判断是否有语法错误。 搞清楚 SQL 语句要干嘛后，MySQL 会通过优化器生成执行计划。 执行器调用存储引擎的接口，执行 SQL 语句。 SQL 执行过程中，优化器通过成本计算预估出执行效率最高的方式，基本的预估维度为： IO 成本：从磁盘读取数据到内存的开销。 CPU 成本：CPU 处理内存中数据的开销。 基于这两个维度，可以得出影响 SQL 执行效率的因素有： ①、IO 成本，数据量越大，IO 成本越高。所以要尽量查询必要的字段；尽量分页查询；尽量通过索引加快查询。 ②、CPU 成本，尽量避免复杂的查询条件，如有必要，考虑对子查询结果进行过滤。 —-这部分是帮助理解 end，面试中可不背—- 如何优化慢SQL?首先，需要找到那些比较慢的 SQL，可以通过启用慢查询日志，记录那些超过指定执行时间的 SQL 查询。 也可以使用 show processlist; 命令查看当前正在执行的 SQL 语句，找出执行时间较长的 SQL。 或者在业务基建中加入对慢 SQL 的监控，常见的方案有字节码插桩、连接池扩展、ORM 框架扩展等。 然后，使用 EXPLAIN 查看慢 SQL 的执行计划，看看有没有用索引，大部分情况下，慢 SQL 的原因都是因为没有用到索引。 EXPLAIN SELECT * FROM your_table WHERE conditions;最后，根据分析结果，通过添加索引、优化查询条件、减少返回字段等方式进行优化。 慢sql日志怎么开启？编辑 MySQL 的配置文件 my.cnf，设置 slow_query_log 参数为 1。 slow_query_log = 1slow_query_log_file = /var/log/mysql/slow.loglong_query_time = 2 # 记录执行时间超过2秒的查询 然后重启 MySQL 就好了。 也可以通过 set global 命令动态设置。 SET GLOBAL slow_query_log = ON;SET GLOBAL slow_query_log_file = /var/log/mysql/slow.log;SET GLOBAL long_query_time = 2;","tags":["基础","Mysql"]},{"title":"2025.6.10学习日记","path":"/2025/06/10/学习日记/2025.6.10学习笔记/","content":"学习内容最近学习重心想转到算法相关,把随想录和题单刷一遍之后做力扣周赛,太长时间没做需要复健一下. 1. 打卡力扣每日简单的字符串计数找最大最小. 2. 看Mysql基础笔记同步在了Mysql学习笔记中. 3. 代码随想录二叉树的三种遍历和迭代遍历.今天踩了一个小坑:在实现迭代调用的统一写法时,需要在Deque中插入一个null元素作为是否遍历过的标志,但是实现Deque时用的ArrayDeque,这个实现方式不能插入null元素,需要使用LinkedList实现才可以.感觉这几个集合框架还是有必要学的深入一些的,不管是算法还是写项目都有很大帮助. 明天开始跑项目ply生活记录1. 健身今天健身房练上肢 肩 胸 核心","tags":["基础","项目","日记","leetcode"]},{"title":"JVM学习笔记","path":"/2025/06/09/JVM学习笔记/","content":"运行时数据区域 程序计数器记录正在执行的虚拟机字节码指令的地址,如果是本地方法则为空. Java虚拟机栈每个 Java ⽅法在执⾏的同时会创建⼀个栈帧⽤于存储局部变量表、操作数栈、常量池引⽤等信息。从⽅法调⽤直⾄执⾏完成的过程，对应着⼀个栈帧在 Java 虚拟机栈中⼊栈和出栈的过程。 该区域可能抛出的异常: 当线程请求的栈深度超过最⼤值，会抛出 StackOverflowError 异常； 栈进⾏动态扩展时如果⽆法申请到⾜够内存，会抛出 OutOfMemoryError 异常。 本地方法栈本地方法栈和Java虚拟机栈类似,区别在于本地方法栈为虚拟机使用到的 Native ⽅法服务. 堆所有对象都在这⾥分配内存，是垃圾收集的主要区域（”GC 堆”）。现代垃圾收集器基本都是采⽤分代收集算法，其主要的思想是针对不同类型的对象采取不同的垃圾回收算法。可以将堆分成两块： 新⽣代（Young Generation） ⽼年代（Old Generation）堆不需要连续内存，并且可以动态增加其内存，增加失败会抛出 OutOfMemoryError 异常。 ⽅法区⽤于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。和堆⼀样不需要连续的内存，并且可以动态扩展，动态扩展失败⼀样会抛出 OutOfMemoryError 异常。在 JDK 1.8 之后，原来永久代的数据被分到了堆和元空间中。元空间存储类的元信息，静态变量和常量池等放⼊堆中。 运行时常量池是⽅法区的⼀部分。Class ⽂件中的常量池（编译器⽣成的字⾯量和符号引⽤）会在类加载后被放⼊这个区域。除了在编译期⽣成的常量，还允许动态⽣成，例如 String 类的 intern()。 直接内存JDK 1.4 新引⼊了 NIO 类，它可以使⽤ Native 函数库直接分配堆外内存，然后通过 Java 堆⾥的 DirectByteBuffer对象作为这块内存的引⽤进⾏操作。这样能在⼀些场景中显著提⾼性能，因为避免了在堆内存和堆外内存来回拷⻉数据。 理解运行时的数据区 垃圾收集垃圾收集主要是针对堆和⽅法区进⾏。程序计数器、虚拟机栈和本地⽅法栈这三个区域属于线程私有的，只存在于线程的⽣命周期内，线程结束之后就会消失，因此不需要对这三个区域进⾏垃圾回收。 判断一个对象是否可被回收1. 引⽤计数算法为对象添加⼀个引⽤计数器，当对象增加⼀个引⽤时计数器加 1，引⽤失效时计数器减 1。引⽤计数为 0 的对象可被回收。 但由于对象之间循环引用的存在，引⽤计数器也会失效。 2. 可达性分析算法以 GC Roots 为起始点进⾏搜索，可达的对象都是存活的，不可达的对象可被回收。Java 虚拟机使⽤该算法来判断对象是否可被回收，GC Roots ⼀般包含以下内容： 虚拟机栈中局部变量表中引⽤的对象 本地⽅法栈中 JNI 中引⽤的对象 ⽅法区中类静态属性引⽤的对象 ⽅法区中的常量引⽤的对象 3. 方法区的回收因为⽅法区主要存放永久代对象，⽽永久代对象的回收率⽐新⽣代低很多，所以在⽅法区上进⾏回收性价⽐不⾼。主要是对常量池的回收和对类的卸载。为了避免内存溢出，在⼤量使⽤反射和动态代理的场景都需要虚拟机具备类卸载功能。类的卸载条件很多，需要满⾜以下三个条件，并且满⾜了条件也不⼀定会被卸载： 该类所有的实例都已经被回收，此时堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 Class 对象没有在任何地⽅被引⽤，也就⽆法在任何地⽅通过反射访问该类⽅法。 4. finalize()类似 C++ 的析构函数，⽤于关闭外部资源。但是⽤ try-finally 可以做得更好，并且 finalize ⽅法运⾏代价很⾼，不确定性⼤，⽆法保证各个对象的调⽤顺序，因此最好不要使⽤。 引用类型⽆论是通过引⽤计数算法判断对象的引⽤数量，还是通过可达性分析算法判断对象是否可达，判定对象是否可被回收都与引⽤有关。Java 提供了四种强度不同的引⽤类型。 1. 强引⽤被强引⽤关联的对象不会被回收。使⽤ new ⼀个新对象的⽅式来创建强引⽤。Object obj = new Object(); 2. 软引⽤被软引⽤关联的对象只有在内存不够的情况下才会被回收。使⽤ SoftReference 类来创建软引⽤。 Object obj = new Object();SoftReferenceObject sf = new SoftReferenceObject(obj);obj = null; // 使对象只被软引⽤关联 3. 弱引⽤被弱引⽤关联的对象⼀定会被回收，也就是说它只能存活到下⼀次垃圾回收发⽣之前。使⽤ WeakReference 类来创建弱引⽤。 Object obj = new Object();WeakReferenceObject wf = new WeakReferenceObject(obj);obj = null; 4. 虚引⽤⼜称为幽灵引⽤或者幻影引⽤，⼀个对象是否有虚引⽤的存在，不会对其⽣存时间造成影响，也⽆法通过虚引⽤得到⼀个对象。为⼀个对象设置虚引⽤的唯⼀⽬的是能在这个对象被回收时收到⼀个系统通知。使⽤ PhantomReference 来创建虚引⽤。 Object obj = new Object();PhantomReferenceObject pf = new PhantomReferenceObject(obj, null);obj = null; 垃圾收集算法1. 标记-清除算法最基础的收集算法，分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。不足: 效率问题，标记和清除两个过程的效率都不⾼； 空间问题，会产⽣⼤量不连续的内存碎⽚，导致⽆法给⼤对象分配内存。 2. 标记-整理算法让所有存活的对象都向⼀端移动，然后直接清理掉端边界以外的内存。 优点: 不会产⽣内存碎⽚ 不⾜: 需要移动⼤量对象，处理效率⽐较低。 3. 复制算法将内存划分为⼤⼩相等的两块，每次只使⽤其中⼀块，当这⼀块内存⽤完了就将还存活的对象复制到另⼀块上⾯，然后再把使⽤过的内存空间进⾏⼀次清理。不⾜是只使⽤了内存的⼀半。 4. 分代收集算法现在的商业虚拟机采⽤分代收集算法，它根据对象存活周期将内存划分为⼏块，不同块采⽤适当的收集算法。⼀般将堆分为新⽣代和⽼年代。 新⽣代使⽤：复制算法 ⽼年代使⽤：标记 - 清除 或者 标记 - 整理 算法 垃圾收集器以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使⽤。 单线程与多线程：单线程指的是垃圾收集器只使⽤⼀个线程，⽽多线程使⽤多个线程； 串⾏与并⾏：串⾏指的是垃圾收集器与⽤户程序交替执⾏，这意味着在执⾏垃圾收集的时候需要停顿⽤户程序；并⾏指的是垃圾收集器和⽤户程序同时执⾏。除了 CMS 和 G1 之外，其它垃圾收集器都是以串⾏的⽅式执⾏。 1. Serial 收集器串行的垃圾收集器，是最基本、历史最悠久的垃圾收集器。单CPU环境下，Serial 收集器由于没有线程交互的开销，可以获得最高的单线程收集效率。 优点: 简单、容易实现 缺点: 单线程、停顿时间⻓ 2. ParNew 收集器ParNew 收集器是 Serial 收集器的多线程版本，它是 Server 场景下默认的新⽣代收集器，除了性能原因外，主要是因为除了 Serial 收集器，只有它能与 CMS 收集器配合使⽤。 3. Parallel Scavenge 收集器与 ParNew ⼀样是多线程收集器。其它收集器⽬标是尽可能缩短垃圾收集时⽤户线程的停顿时间，⽽它的⽬标是达到⼀个可控制的吞吐量，因此它被称为“吞吐量优先”收集器。这⾥的吞吐量指 CPU ⽤于运⾏⽤户程序的时间占总时间的⽐值。 4. Serial Old 收集器是 Serial 收集器的⽼年代版本，也是给 Client 场景下的虚拟机使⽤。如果⽤在 Server 场景下，它有两⼤⽤途： 在 JDK 1.5 以及之前版本（Parallel Old 诞⽣以前）中与 Parallel Scavenge 收集器搭配使⽤。 作为 CMS 收集器的后备预案，在并发收集发⽣ Concurrent Mode Failure 时使⽤。 5. Parallel Old 收集器是 Parallel Scavenge 收集器的⽼年代版本。在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。 6. CMS 收集器CMS（Concurrent Mark Sweep），Mark Sweep 指的是标记 - 清除算法。分为以下四个流程： 初始标记：仅仅只是标记⼀下 GC Roots 能直接关联到的对象，速度很快，需要停顿。 并发标记：进⾏ GC Roots Tracing 的过程，它在整个回收过程中耗时最⻓，不需要停顿。 重新标记：为了修正并发标记期间因⽤户程序继续运作⽽导致标记产⽣变动的那⼀部分对象的标记记录，需要停顿。 并发清除：不需要停顿。 在整个过程中耗时最⻓的并发标记和并发清除过程中，收集器线程都可以与⽤户线程⼀起⼯作，不需要进⾏停顿。具有以下缺点： 吞吐量低：低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利⽤率不够⾼。 ⽆法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于⽤户线程继续运⾏⽽产⽣的垃圾，这部分垃圾只能到下⼀次 GC 时才能进⾏回收。由于浮动垃圾的存在，因此需要预留出⼀部分内存，意味着 CMS 收集不能像其它收集器那样等待⽼年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启⽤ Serial Old 来替代 CMS。 标记 - 清除算法导致的空间碎⽚，往往出现⽼年代空间剩余，但⽆法找到⾜够⼤连续空间来分配当前对象，不得不提前触发⼀次 Full GC。 7. G1 收集器G1（Garbage-First），它是⼀款⾯向服务端应⽤的垃圾收集器，在多 CPU 和⼤内存的场景下有很好的性能。堆被分为新⽣代和⽼年代，其它收集器进⾏收集的范围都是整个新⽣代或者⽼年代，⽽ G1 可以直接对新⽣代和⽼年代⼀起回收。G1 把堆划分成多个⼤⼩相等的独⽴区域（Region），新⽣代和⽼年代不再物理隔离。通过引⼊ Region 的概念，从⽽将原来的⼀整块内存空间划分成多个的⼩空间，使得每个⼩空间可以单独进⾏垃圾回收。这种划分⽅法带来了很⼤的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护⼀个优先列表，每次根据允许的收集时间，优先回收价值最⼤的 Region。每个 Region 都有⼀个 Remembered Set，⽤来记录该 Region 对象的引⽤对象所在的 Region。通过使⽤Remembered Set，在做可达性分析的时候就可以避免全堆扫描。 如果不计算维护 Remembered Set 的操作，G1 收集器的运作⼤致可划分为以下⼏个步骤： 初始标记 并发标记 最终标记：为了修正在并发标记期间因⽤户程序继续运作⽽导致标记产⽣变动的那⼀部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs ⾥⾯，最终标记阶段需要把 Remembered Set Logs的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并⾏执⾏。 筛选回收：⾸先对各个 Region 中的回收价值和成本进⾏排序，根据⽤户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与⽤户程序⼀起并发执⾏，但是因为只回收⼀部分 Region，时间是⽤户可控制的，⽽且停顿⽤户线程将⼤幅度提⾼收集效率。 具备如下特点： 空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，这意味着运⾏期间不会产⽣内存空间碎⽚。 可预测的停顿：能让使⽤者明确指定在⼀个⻓度为 M 毫秒的时间⽚段内，消耗在 GC 上的时间不得超过 N 毫秒。 内存分配与回收策略’Minor GC 和 Full GC Minor GC：回收新⽣代，因为新⽣代对象存活时间很短，因此 Minor GC 会频繁执⾏，执⾏的速度⼀般也会⽐较快。 Full GC：回收⽼年代和新⽣代，⽼年代对象存活时间⻓，因此 Full GC 很少执⾏，执⾏速度会⽐ Minor GC 慢很多。 内存分配策略 对象优先在 Eden 分配⼤多数情况下，对象在新⽣代 Eden 上分配，当 Eden 空间不够时，发起 Minor GC。 ⼤对象直接进⼊⽼年代⼤对象是指需要连续内存空间的对象，最典型的⼤对象是那种很⻓的字符串以及数组。经常出现⼤对象会提前触发垃圾收集以获取⾜够的连续空间分配给⼤对象。-XX:PretenureSizeThreshold，⼤于此值的对象直接在⽼年代分配，避免在 Eden 和 Survivor之间的⼤量内存复制。 ⻓期存活的对象进⼊⽼年代为对象定义年龄计数器，对象在 Eden 出⽣并经过 Minor GC 依然存活，将移动到 Survivor中，年龄就增加 1 岁，增加到⼀定年龄则移动到⽼年代中。-XX:MaxTenuringThreshold ⽤来定义年龄的阈值。 动态对象年龄判定虚拟机并不是永远要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升⽼年代，如果在Survivor 中相同年龄所有对象⼤⼩的总和⼤于 Survivor 空间的⼀半，则年龄⼤于或等于该年龄的对象可以直接进⼊⽼年代，⽆需等到 MaxTenuringThreshold 中要求的年龄。 空间分配担保在发⽣ Minor GC 之前，虚拟机先检查⽼年代最⼤可⽤的连续空间是否⼤于新⽣代所有对象总空间，如果条件成⽴的话，那么 Minor GC 可以确认是安全的。如果不成⽴的话虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许那么就会继续检查⽼年代最⼤可⽤的连续空间是否⼤于历次晋升到⽼年代对象的平均⼤⼩，如果⼤于，将尝试着进⾏⼀次 Minor GC；如果⼩于，或者 HandlePromotionFailure 的值不允许冒险，那么就要进⾏⼀次 Full GC。 Full GC 的触发条件对于 Minor GC，其触发条件⾮常简单，当 Eden 空间满时，就将触发⼀次 Minor GC。⽽ FullGC 则相对复杂，有以下条件： 调⽤ System.gc()只是建议虚拟机执⾏ Full GC，但是虚拟机不⼀定真正去执⾏。不建议使⽤这种⽅式，⽽是让虚拟机管理内存。 ⽼年代空间不⾜⽼年代空间不⾜的常⻅场景为前⽂所讲的⼤对象直接进⼊⽼年代、⻓期存活的对象进⼊⽼年代等。为了避免以上原因引起的 Full GC，应当尽量不要创建过⼤的对象以及数组。除此之外，可以通过 -Xmn 虚拟机参数调⼤新⽣代的⼤⼩，让对象尽量在新⽣代被回收掉，不进⼊⽼年代。还可以通过 -XX:MaxTenuringThreshold 调⼤对象进⼊⽼年代的年龄，让对象在新⽣代多存活⼀段时间。 空间分配担保失败使⽤复制算法的 Minor GC 需要⽼年代的内存空间作担保，如果担保失败会执⾏⼀次 FullGC。具体内容请参考上⾯的第 5 ⼩节。 JDK 1.7 及以前的永久代空间不⾜在 JDK 1.7 及以前，HotSpot 虚拟机中的⽅法区是⽤永久代实现的，永久代中存放的为⼀些Class 的信息、常量、静态变量等数据。当系统中要加载的类、反射的类和调⽤的⽅法较多时，永久代可能会被占满，在未配置为采⽤CMS GC 的情况下也会执⾏ Full GC。如果经过 Full GC 仍然回收不了，那么虚拟机会抛出java.lang.OutOfMemoryError。为避免以上原因引起的 Full GC，可采⽤的⽅法为增⼤永久代空间或转为使⽤ CMS GC。 Concurrent Mode Failure执⾏ CMS GC 的过程中同时有对象要放⼊⽼年代，⽽此时⽼年代空间不⾜（可能是 GC 过程中浮动垃圾过多导致暂时性的空间不⾜），便会报 Concurrent Mode Failure 错误，并触发Full GC。 类加载机制类是在运⾏期间第⼀次使⽤时动态加载的，⽽不是⼀次性加载所有类。因为如果⼀次性加载，会占⽤很多的内存。 类的生命周期 包括以下 7 个阶段： 加载（Loading） 验证（Verification） 准备（Preparation） 解析（Resolution） 初始化（Initialization） 使⽤（Using） 卸载（Unloading） 类的加载过程包含了加载、验证、准备、解析和初始化这 5 个阶段。 1. 加载加载是类加载的⼀个阶段，注意不要混淆。加载过程完成以下三件事： 通过类的完全限定名称获取定义该类的⼆进制字节流。 将该字节流表示的静态存储结构转换为⽅法区的运⾏时存储结构。 在内存中⽣成⼀个代表该类的 Class 对象，作为⽅法区中该类各种数据的访问⼊⼝。 其中⼆进制字节流可以从以下⽅式中获取： 从 ZIP 包读取，成为 JAR、EAR、WAR 格式的基础。 从⽹络中获取，最典型的应⽤是 Applet。 运⾏时计算⽣成，例如动态代理技术，在 java.lang.reflect.Proxy 使⽤ProxyGenerator.generateProxyClass 的代理类的⼆进制字节流。由其他⽂件⽣成，例如由 JSP ⽂件⽣成对应的 Class 类。 2. 验证确保 Class ⽂件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机⾃身的安全。 3. 准备类变量是被 static 修饰的变量，准备阶段为类变量分配内存并设置初始值，使⽤的是⽅法区的内存。应该注意到，实例化不是类加载的⼀个过程，类加载发⽣在所有实例化操作之前，并且类加载只进⾏⼀次，实例化可以进⾏多次。初始值⼀般为 0 值，例如下⾯的类变量 value 被初始化为 0 ⽽不是 123。public static int value = 123;如果类变量是常量，那么它将初始化为表达式所定义的值⽽不是 0。例如下⾯的常量 value 被初始化为 123 ⽽不是 0。public static final int value = 123; 4. 解析将常量池的符号引⽤替换为直接引⽤的过程。其中解析过程在某些情况下可以在初始化阶段之后再开始，这是为了⽀持 Java 的动态绑定。 5. 初始化初始化阶段才真正开始执⾏类中定义的 Java 程序代码。 初始化阶段是虚拟机执⾏类构造器clinit() ⽅法的过程。在准备阶段，类变量已经赋过⼀次系统要求的初始值，⽽在初始化阶段，根据程序员通过程序制定的主观计划去初始化类变量和其它资源。 clinit() 是由编译器⾃动收集类中所有类变量的赋值动作和静态语句块中的语句合并产⽣的，编译器收集的顺序由语句在源⽂件中出现的顺序决定。特别注意的是，静态语句块只能访问到定义在它之前的类变量，定义在它之后的类变量只能赋值，不能访问。例如以下代码： public class Test static i = 0; // 给变量赋值可以正常编译通过System.out.print(i); // 这句编译器会提示“⾮法向前引⽤”static int i = 1; 由于⽗类的 () ⽅法先执⾏，也就意味着⽗类中定义的静态语句块的执⾏要优先于⼦类。例如以下代码： static class Parent public static int A = 1;static A = 2;static class Sub extends Parent public static int B = A;public static void main(String[] args) System.out.println(Sub.B); // 2 静态代码块和赋值动作是按照代码的顺序执行的。接⼝中不可以使⽤静态语句块，但仍然有类变量初始化的赋值操作，因此接⼝与类⼀样都会⽣成 clinit() ⽅法。 但接⼝与类不同的是，执⾏接⼝的 clinit() ⽅法不需要先执⾏⽗接⼝的 clinit() ⽅法。只有当⽗接⼝中定义的变量使⽤时，⽗接⼝才会初始化。另外，接⼝的实现类在初始化时也⼀样不会执⾏接⼝的 clinit() ⽅法。虚拟机会保证⼀个类的 clinit() ⽅法在多线程环境下被正确的加锁和同步，如果多个线程同时初始化⼀个类，只会有⼀个线程执⾏这个类的 clinit() ⽅法，其它线程都会阻塞等待，直到活动线程执⾏ clinit() ⽅法完毕。 如果在⼀个类的clinit()⽅法中有耗时的操作，就可能造成多个线程阻塞，在实际过程中此种阻塞很隐蔽。 类的初始化时机1.主动引用虚拟机规范中并没有强制约束何时进⾏加载，但是规范严格规定了有且只有下列五种情况必须对类进⾏初始化（加载、验证、准备都会随之发⽣）: 遇到 new、getstatic、putstatic 或 invokestatic 这 4 条字节码指令时，如果类没有进⾏过初始化，则需要先触发其初始化。 使⽤ java.lang.reflect 包的方法对类进⾏反射调⽤的时候，如果类没有进⾏过初始化，则需要先触发其初始化。 当初始化⼀个类时，如果发现其父类还没有进⾏过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，⽤于执⾏主类（包含 main() ⽅法的那个类）的初始化。 使⽤ JDK 7 新加入的动态语言⽀持时，如果⼀个 java.lang.invoke.MethodHandle 实例最后的解析结果 REF_getStatic、REF_putStatic、REF_invokeStatic 的⽅法句柄，并且这个⽅法句柄所对应的类没有进⾏过初始化，则需要先出触发其初始化。 2.被动引用以上 5 种场景中的⾏为称为对⼀个类进⾏主动引⽤。除此之外，所有引⽤类的⽅式都不会触发初始化，称为被动引⽤。被动引⽤的常⻅例⼦包括：通过⼦类引⽤⽗类的静态字段，不会导致⼦类初始化。 System.out.println(SubClass.value); // value 字段在 SuperClass 中定义 通过数组定义来引⽤类，不会触发此类的初始化。该过程会对数组类进⾏初始化，数组类是⼀个由虚拟机⾃动⽣成的、直接继承⾃ Object 的⼦类，其中包含了数组的属性和⽅法。 SuperClass[] sca = new SuperClass[10]; 常量在编译阶段会存⼊调⽤类的常量池中，本质上并没有直接引⽤到定义常量的类，因此不会触发定义常量的类的初始化。 System.out.println(ConstClass.HELLOWORLD); 类加载器分类从 Java 虚拟机的⻆度来讲，只存在以下两种不同的类加载器： 启动类加载器（Bootstrap ClassLoader），使⽤ C++ 实现，是虚拟机⾃身的⼀部分； 所有其它类的加载器，使⽤ Java 实现，独⽴于虚拟机，继承⾃抽象类java.lang.ClassLoader。 从 Java 开发⼯程的⻆度来看，类加载器可以划分得更细致一些： 启动类加载器（Bootstrap ClassLoader）：这个类加载器负责将存放在 JAVA_HOME\\lib 目录中的，或者被 -Xbootclasspath 参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如 rt.jar，名字不符合的类库即使放在 lib 目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被 Java 程序直接引⽤，用户在编写自定义类加载器时，如果需要把加载请求委派给启动类加载器去处理，那么直接⽤ null 代替即可。 扩展类加载器（Extension ClassLoader）：这个类加载器是在类 java.lang.ClassLoader 的构造函数中被调⽤的。它负责将 libext 或者被 java.ext.dir 系统变量所指定路径中的所有类库加载到内存中，开发者可以直接使⽤扩展类加载器。 应用程序类加载器（Application ClassLoader）：这个类加载器是在类 java.lang.ClassLoader 的构造函数中被调⽤的。由于这个类加载器是 ClassLoader 中的 getSystemClassLoader() 方法的返回值，所以也被称为系统类加载器。它负责将⽤户类路径（ClassPath）上所指定的类库加载到内存中。开发者可以直接使⽤这个类加载器，如果应⽤程序中没有定义过⾃定义的类加载器，一般情况下这个就是程序中默认的类加载器。 ⼯作过程⼀个类加载器⾸先将类加载请求转发到⽗类加载器，只有当⽗类加载器⽆法完成时才尝试⾃⼰加载。 好处使得 Java 类随着它的类加载器⼀起具有⼀种带有优先级的层次关系，从⽽使得基础类得到统⼀。例如 java.lang.Object 存放在 rt.jar 中，如果编写另外⼀个 java.lang.Object 并放到 ClassPath中，程序可以编译通过。由于双亲委派模型的存在，所以在 rt.jar 中的 Object ⽐在 ClassPath 中的 Object 优先级更⾼，这是因为 rt.jar 中的 Object 使⽤的是启动类加载器，⽽ ClassPath 中的 Object 使⽤的是应⽤程序类加载器。rt.jar 中的 Object 优先级更⾼，那么程序中所有的 Object 都是这个Object。","tags":["JVM","基础"]},{"title":"2025.6.9学习日记","path":"/2025/06/09/学习日记/2025.6.9学习笔记/","content":"学习内容1. 力扣每日一题 ＋ 昨天的每日一题昨天又忘打卡力扣了,还欠了13天的,得五个月之后才能全续上了.今天的每日是字典序第K数字.昨天的也是字典序相关.做了两道字典序感觉理解了. 2. 学习JVM相关基础学习了JVM相关,并且记了一篇笔记. 3. 把KMP算法实践一下手画梳理了一下流程,然后构造了两遍之后感觉理解很多了.个人理解KMP的核心思想就是让主串索引不后退,匹配串索引通过next数组快速找到前缀相同的下标位置继续匹配.核心就是next数组的构造.这个算法理解后实现也比较复杂,有一堆的边界条件,一个比较好的思路是在主串和匹配串前面加一个空格作为哨兵,然后边界问题会少很多,只需要比较j+1和主串i位置即可. 4. 学习项目文档生活记录1. 足球训练今天七点起床,下楼练球,练颠球和逆足.10","tags":["基础","项目","日记","leetcode"]},{"title":"Java并发篇","path":"/2025/06/07/Java并发篇/","content":"使用线程三种方法 继承Thread类需要重写run方法，然后调用start方法启动线程。 实现Runnable接口需要重写run方法，然后调用start方法启动线程。 实现Callable接口需要重写call方法，然后调用start方法启动线程。有返回值，通过 FutureTask 进⾏封装。 实现接口还是继承类？实现接口更好一些，java不支持多继承，但可以实现多个接口。 基础线程机制ExecutorExecutor用来管理多个异步操作（多个任务互不干扰，不需要同步操作）。 主要有三种Executor：CachedThreadPool：⼀个任务创建⼀个线程；FixedThreadPool：所有任务只能使⽤固定⼤⼩的线程；SingleThreadExecutor：相当于⼤⼩为 1 的 FixedThreadPool。 DaemonDaemon守护线程是⼀个服务线程，⽤于为其他线程提供服务。所有非守护线程都执⾏完毕后，无论有没有守护线程，程序都会退出。线程启动前可以通过setDaemon() 方法来设置该线程是否为守护线程。 sleep()Thread.sleep() 使当前线程暂停执⾏指定的时间，暂停期间，其他线程可以继续运⾏，不会受到阻塞。sleep()可能会抛出InterruptedException异常，异常不会传回main()，所以必须在Thread类中捕获并处理。 yield()代表线程已经走完了重要的部分，可以让其他线程有机会执行。 中断线程完成会自动关闭，但是如果线程异常也会提前关闭。 InterruptedException 异常线程在 sleep() 或 wait() 时被中断，会抛出 InterruptedException 异常。 interrupted()如果一个线程处于无限循环中，并且没有执行 sleep() 或 wait()，那么可以通过 interrupted() 来判断线程是否被中断。如果线程被中断，interrupted() 会返回 true。如果线程没有被中断，interrupted() 会返回 false。 Executor的中断操作调用shutdown()方法会等待所有任务执行完毕后关闭Executor。调用shutdownNow()方法会中断所有任务，相当于调用每个任务的interrupt()方法，然后关闭Executor。 如果只想中断某一个线程，可以通过submit() 方法提交一个Callable任务，然后调用Future的cancel()方法来中断任务。 互斥同步Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第⼀个是 JVM 实现的synchronized，另⼀个是 JDK 实现的 ReentrantLock。 synchronizedsynchronized 是 Java 中的关键字，它可以修饰方法和代码块。修饰方法时，锁的是当前对象。修饰代码块时，锁的是括号中的对象。 ReentrantLockReentrantLock 是 java.util.concurrent（J.U.C）包中的锁。 比较synchronized和ReentrantLock 锁的实现synchronized 是 JVM 实现的，⽽ ReentrantLock 是 JDK 实现的。 性能新版本 Java 对 synchronized 进⾏了很多优化，例如⾃旋锁，synchronized 与ReentrantLock 的性能⼤致相同。 等待可中断当持有锁的线程⻓期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。ReentrantLock 可中断，⽽ synchronized 不⾏。 公平锁公平锁是指多个线程在等待同⼀个锁时，必须按照申请锁的时间顺序来依次获得锁。synchronized 中的锁是⾮公平的，ReentrantLock 默认情况下也是⾮公平的，但是也可以是公平的。 锁绑定多个条件⼀个 ReentrantLock 可以同时绑定多个 Condition 对象。 使用选择除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。因为synchronized 是 JVM 实现的，可以保证⾃⼰的线程安全，⽽ ReentrantLock 需要程序员手动释放锁， 线程之间的协作join()在一个线程中调用另一个线程的 join() 方法，会将当前线程挂起，直到被调用的线程执行完毕。 wait() notify() notifyAll()wait() 使当前线程等待，直到其他线程调⽤ notify() 或 notifyAll() 方法。notify() 随机唤醒⼀个等待线程，notifyAll() 唤醒所有等待线程。wait()必须在 synchronized 块中调⽤,否则会抛出IllegalMonitorStateException异常。 wait()和sleep()的区别 wait() 是 Object 的⽅法，sleep() 是 Thread 的⽅法。 wait() 会释放锁，sleep() 不会释放锁。 wait() 可以被 notify() 或 notifyAll() 唤醒，sleep() 只能被中断。 wait() 必须在 synchronized 块中调⽤，sleep() 可以在任何位置调⽤。 await() signal() signalAll()java.util.concurrent 提供的 Condition 类，可以再Condition 上调⽤ await() 使线程等待. 相比wait()，await() 可以指定时间，超过时间会⾃动唤醒。 线程状态一个线程通常只有一种状态,并且这里特指jvm线程状态,而不是操作系统线程状态.线程状态有6种: 新建(New)创建后尚未启用. 可运行(Runnable)正在Java虚拟机中执行,但是它可能正在等待操作系统分配处理器资源. 阻塞(Blocked)线程被阻塞,等待其他线程完成操作. 等待(Waiting)线程等待其他线程执行特定操作. 计时等待(Timed Waiting)线程等待指定的时间. 终止(Terminated)线程已经完成执行. 状态转换 J.U.C - AQSjava.util.concurrent （J.U.C）⼤⼤提⾼了并发性能，AQS 被认为是 J.U.C 的核⼼。AQS是AbstractQueuedSynchronizer的缩写,是Java并发包中用来实现锁的基础框架. CountDownLatchCountDownLatch用来控制一个或多个线程等待其他线程完成操作. CyclicBarrier用来控制多个线程互相等待，直到到达某个公共屏障点（common barrier point）。和CountDownLatch不同的是，CyclicBarrier的计数器可以被重置后使用，所以它被称为循环屏障。 SemaphoreSemaphore 类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。 J.U.C - 其它组件FutureTask实现了Future接口和Runnable接口,可以作为Runnable被线程执行,也可以用来获取异步执行的结果.适用于需要异步执行任务,并且需要获取结果的场景. BlockingQueue阻塞队列,可以用来实现生产者-消费者模式. java.util.concurrent.BlockingQueue 接⼝有以下阻塞队列的实现：FIFO 队列 ：LinkedBlockingQueue、ArrayBlockingQueue（固定⻓度）优先级队列 ：PriorityBlockingQueue ForkJoin和MapReduce类似,可以将⼤量的数据拆分成⼩量的数据，然后分⽴计算，最后将结果合并。 Java 内存模型Java 内存模型试图屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到⼀致的内存访问效果。 主内存和工作内存主内存是所有线程共享的内存区域，工作内存是每个线程独有的内存区域。 所有的变量都存储在主内存中，每个线程还有⾃⼰的⼯作内存，⼯作内存存储在⾼速缓存或者寄存器中，保存了该线程使⽤的变量的主内存副本拷⻉。线程只能直接读写⾃⼰的⼯作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。 内存间的交互操作 java内存模型规定了8种操作来完成主内存和工作内存之间的交互操作：read：把⼀个变量的值从主内存传输到⼯作内存中load：在 read 之后执⾏，把 read 得到的值放⼊⼯作内存的变量副本中use：把⼯作内存中⼀个变量的值传递给执⾏引擎assign：把⼀个从执⾏引擎接收到的值赋给⼯作内存的变量store：把⼯作内存的⼀个变量的值传送到主内存中write：在 store 之后执⾏，把 store 得到的值放⼊主内存的变量中lock：作⽤于主内存的变量unlock:作⽤于主内存的变量 内存模型的三大特性原子性java内存模型保证了read、load、use、assign、store、write这6个操作是具有原子性的。但是不保证这6个操作的组合是具有原子性的。AtomicInteger 是⼀个提供原子操作的 Integer 类。除了使用原子类外，还可以通过 synchronized 关键字来保证操作的原子性。 可见性可⻅性指当⼀个线程修改了共享变量的值，其它线程能够⽴即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可⻅性的。主要有三种可见性的实现方式: volatile synchronized，对⼀个变量执⾏ unlock 操作之前，必须把变量值同步回主内存。 final，被 final 关键字修饰的字段在构造⽅法中⼀旦初始化完成，并且没有发⽣ this 逃逸（其它线程通过 this 引⽤访问到初始化了⼀半的对象），那么其它线程就能看⻅ final 字段的值。 有序性有序性指的是在本线程内观察，所有操作都是有序的；如果在⼀个线程观察另⼀个线程，所有操作都是无序的。Java 内存模型是通过禁止指令重排序来保证有序性的。主要有两种有序性的实现方式: volatile synchronized，对⼀个变量执⾏ unlock 操作之前，必须把变量值同步回主内存。 先⾏发⽣原则先⾏发⽣原则是指如果在程序中两个操作的先后顺序与代码中的顺序相同，那么这两个操作就会先⾏发⽣。 1. 单⼀线程原则在单⼀线程中，在程序前⾯的操作先⾏发⽣于后⾯的操作。 2. 管程锁定规则⼀个 unlock 操作先⾏发⽣于后⾯对同⼀个锁的 lock 操作。 3. volatile 变量规则对⼀个 volatile 变量的写操作先⾏发⽣于后⾯对这个变量的读操作。 4. 线程启动规则Thread 对象的 start() ⽅法调⽤先⾏发⽣于此线程的每⼀个动作。 5. 线程加⼊规则Thread 对象的结束先⾏发⽣于 join() ⽅法返回。 6. 线程中断规则对线程interrupt()⽅法的调⽤先⾏发⽣于被中断线程的代码检测到中断事件的发⽣，可以通过 interrupted() ⽅法检测到是否有中断发⽣。 7. 对象终结规则⼀个对象的初始化完成（构造⽅法执⾏结束）先⾏发⽣于它的 finalize() ⽅法的开始。 8. 传递性如果操作 A 先⾏发⽣于操作 B，操作 B 先⾏发⽣于操作 C，那么操作 A 先⾏发⽣于操作 C。 线程安全多个线程不管以何种⽅式访问某个类，并且在主调代码中不需要任何额外的同步或协调，这个类都能表现出正确的⾏为，那么就称这个类是线程安全的。 线程安全有以下几种实现方法:不可变不可变（Immutable）的对象⼀定是线程安全的，不需要再采取任何的线程安全保障措施。只要⼀个不可变的对象被正确地构建出来，永远也不会看到它在多个线程之中处于不⼀致的状态。多线程环境下，应当尽量使对象成为不可变，来满⾜线程安全。 不可变的类型：final 关键字修饰的基本数据类型String枚举类型Number 部分⼦类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等⼤数据类型。但同为 Number 的原⼦类 AtomicInteger 和 AtomicLong 则是可变的。对于集合类型，我们可以使⽤ Collections.unmodifiableXXX() 方法来获取⼀个不可变的集合。 互斥同步synchronized 和 ReentrantLock。 ⾮阻塞同步阻塞同步是一种悲观的并发策略，即认为只要不去做正确的同步措施，那就肯定会出现问题。而非阻塞是一种基于冲突检测的乐观并发策略，即不加锁，但是如果存在冲突，就重试当前操作直到成功。 CAS硬件⽀持的原⼦性操作最典型的是：⽐较并交换（Compare-and-Swap，CAS）。CAS 指令需要有 3 个操作数，分别是内存地址 V、旧的预期值 A 和新值 B。当执⾏操作时，只有当 V的值等于 A，才将 V 的值更新为 B。 乐观锁需要操作、冲突检测这两个步骤具备原⼦性，这⾥就不能再使⽤互斥同步来保证了，只能靠硬件来完成。 AtomicIntegerJ.U.C 包⾥⾯的整数原⼦类 AtomicInteger 的⽅法调⽤了 Unsafe 类的 CAS 操作。 ABA如果⼀个变量初次读取的时候是 A 值，它的值被改成了 B，后来⼜被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。J.U.C 包提供了⼀个带有标记的原⼦引⽤类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。⼤部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改⽤传统的互斥同步可能会⽐原⼦类更⾼效。 无同步方案要保证线程安全，并不是⼀定就要进⾏同步。如果⼀个⽅法本来就不涉及共享数据，那它⾃然就⽆须任何同步措施去保证正确性。 栈封闭多个线程访问同⼀个⽅法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。 线程本地存储（Thread Local Storage）如果⼀个变量在线程的⼀个⽅法中被TLS变量存储，并被其他⽅法读取和修改，那么即使两个线程执⾏的是同⼀个代码，它们也会访问到不同的数据。 锁优化主要是针对synchronized关键字的优化。 ⾃旋锁⾃旋锁虽然能避免进⼊阻塞状态从⽽减少开销，但是它需要进⾏忙循环操作占⽤ CPU 时间，它只适⽤于共享数据的锁定状态很短的场景。 锁消除锁消除是指虚拟机即时编译器在运⾏时，对代码进⾏扫描，去除不可能存在共享数据竞争的锁，通过锁消除，可以节省毫无意义的请求锁时间。 锁粗化锁粗化是指虚拟机即时编译器在运⾏时，对代码进⾏扫描，将多个相邻的加锁操作合并为⼀个加锁操作，通过锁粗化，可以节省加锁和释放锁的时间。 轻量级锁JDK 1.6 引⼊了偏向锁和轻量级锁，从⽽让锁拥有了四个状态：⽆锁状态（unlocked）、偏向锁状态（biasble）、轻量级锁状态（lightweight locked）和重量级锁状态（inflated）。 轻量级锁相比传统的重量级锁，它使用CAS操作来避免线程阻塞和唤醒的开销，同时也避免了操作系统层面的线程调度。如果轻量级锁自旋或检测到有线程冲突，会升级为重量级锁。 偏向锁偏向锁是指在没有线程竞争的情况下，锁对象会偏向于使⽤它的线程，这样就不需要进⾏额外的加锁和解锁操作。 多线程开发良好的实践 给线程起个有意义的名字，这样可以⽅便找 Bug。 缩⼩同步范围，从⽽减少锁争⽤。例如对于 synchronized，应该尽量使⽤同步块⽽不是同步⽅法。 多⽤同步⼯具少⽤ wait()和 notify() 。⾸先，CountDownLatch, CyclicBarrier, Semaphore 和 Exchanger 这些同步类简化了编码操作，⽽⽤ wait()和 notify() 很难实现复杂控制流；其次，这些同步类是由最好的企业编写和维护，在后续的 JDK 中还会不断优化和完善。 使⽤ BlockingQueue 实现⽣产者消费者问题。 多⽤并发集合少⽤同步集合，例如应该使⽤ ConcurrentHashMap ⽽不是 Hashtable。 使⽤本地变量和不可变类来保证线程安全。 使⽤线程池⽽不是直接创建线程，这是因为创建线程代价很⾼，线程池可以有效地利⽤有限的线程来启动任务。","tags":["基础","并发","Java"]},{"title":"2025.6.7学习日记","path":"/2025/06/07/学习日记/2025.6.7学习笔记/","content":"学习内容1. 力扣每日一题https://leetcode.cn/problems/lexicographically-minimum-string-after-removing-stars?envType=daily-questionenvId=2025-06-07 先是尝试优先队列，最小堆找前面的最小元素，然后遇到*就删除，但时间复杂度为On2，特殊用例超时了。然后发现可以用栈模拟二十六个字母，栈中存储下标，遇到*出栈最小的字符。优化点：可以使用二进制掩码来表示最小的非空栈在哪里。 2. 学习完java并发篇笔记记录在java并发篇. 3. 把昨天的题用堆来完善一下维护小顶堆求前k大的元素。 4. 学习KMP算法.KMP算法是一种字符串匹配算法，它的时间复杂度为O(n+m)，其中n是文本串的长度，m是模式串的长度。贴一个模板,原理已经理解了，但是代码还需要再写一遍： class Solution // KMP 算法 // ss: 原串(string) pp: 匹配串(pattern) public int strStr(String ss, String pp) if (pp.isEmpty()) return 0; // 分别读取原串和匹配串的长度 int n = ss.length(), m = pp.length(); // 原串和匹配串前面都加空格，使其下标从 1 开始 ss = + ss; pp = + pp; char[] s = ss.toCharArray(); char[] p = pp.toCharArray(); // 构建 next 数组，数组长度为匹配串的长度（next 数组是和匹配串相关的） int[] next = new int[m + 1]; // 构造过程 i = 2，j = 0 开始，i 小于等于匹配串长度 【构造 i 从 2 开始】 for (int i = 2, j = 0; i = m; i++) // 匹配不成功的话，j = next(j) while (j 0 p[i] != p[j + 1]) j = next[j]; // 匹配成功的话，先让 j++ if (p[i] == p[j + 1]) j++; // 更新 next[i]，结束本次循环，i++ next[i] = j; // 匹配过程，i = 1，j = 0 开始，i 小于等于原串长度 【匹配 i 从 1 开始】 for (int i = 1, j = 0; i = n; i++) // 匹配不成功 j = next(j) while (j 0 s[i] != p[j + 1]) j = next[j]; // 匹配成功的话，先让 j++，结束本次循环后 i++ if (s[i] == p[j + 1]) j++; // 整一段匹配成功，直接返回下标 if (j == m) return i - m; return -1;","tags":["基础","项目","日记","leetcode"]},{"title":"java30天学习笔记","path":"/2025/06/06/java30天笔记/","content":"杂项最好不使用 clone()来进行复制,可以使用拷贝构造函数或拷贝工厂来复制对象. 抽象类提供了⼀种 IS-A 的关系接⼝更像是⼀种 LIKE-A 关系 Fail-Fast 机制Fail-Fast 机制是 Java 集合(Collection)中的⼀种错误机制。当多个线程对同一个集合的内容进⾏操作时，就可能产⽣线程安全问题。Fail-Fast 机制会⾃动检测到线程安全问题,在操作前后比较集合的结构变化次数是否相同，并抛出 ConcurrentModificationException 异常。 tips:禁⽌在foreach⾥执⾏元素的删除操作 容器的一些解析vector和arraylist的比较vector是同步的，所以开销更大vector每次扩容请求2倍，而arraylist是1.5倍 如果对线程安全有要求的话，可以选择Collections.synchronizedList() 或者使用CopyOnWriteArrayList保证线程安全。 CopyOnWriteArrayList写操作在拷贝的数组上进行，而读操作在原数组上进行。写操作需要加锁，防止并发写操作。适用于读多写少的场景。问题:内存占用约占原数组的两倍。数据一致性问题。 所以CopyOnWriteArrayList更加适合对内存不敏感以及实时性要求很高的场景。 LinkedListArrayList是基于数组实现的，而LinkedList是基于链表实现的。数组支持随机访问，而链表不支持随机访问。数组的插入和删除操作需要移动元素，而链表的插入和删除操作只需要修改指针。数组的空间利用率高，而链表的空间利用率低。LinkedList适用于需要频繁插入和删除元素的场景。 HashMap相当于分成了很多个桶，每个桶里面是一个链表，链表的每个节点是一个键值对，使用头插法插入节点。 ConcurrentHashMapConcurrentHashMap是线程安全的HashMap，它的实现方式是使用分段锁。ConcurrentHashMap将整个HashMap分成了多个段，每个段都是一个HashMap。每个段都有一个锁，当一个线程访问一个段时，其他线程也可以访问其他段。 LinkedHashMapLinkedHashMap是HashMap的子类，它的实现方式是使用双向链表。LinkedHashMap的迭代顺序是插入顺序或者访问顺序。可以通过LinkedHashMap实现LRU缓存。 WeakHashMap主要是用来实现缓存的。WeakHashMap的键是弱引用，当键不再被引用时，键值对会被自动移除。WeakHashMap的迭代器是弱引用的，所以在迭代时可能会出现空指针异常。 ConcurrentCacheConcurrentCache是一个线程安全的缓存，它的实现方式是使用ConcurrentHashMap。","tags":["java"]},{"title":"好用的快捷键和操作","path":"/2025/06/06/好用的快捷键或操作/","content":"MAC系统操作截图到剪切板mac:shift+control+command+4 最小化窗口mac:command+m 关闭窗口mac:command+w 全屏mac:command+control+f VSCODE单行上下移动mac:shift+option+up/down 多行上下移动mac:shift+option+command+up/down 删除本行mac:command+shift+k 开关左侧项目树mac:command+1 重命名文件mac:fn+shift+f6 VSCODE picgo插件上传到图床mac:option+command+u 关闭终端窗口mac:command+j 终端Warp到hexo根目录cd /Users/mac/Blog/JakicDong.github.io hexo清理并且重新上传hexo clean hexo g hexo d 本地部署hexo s Edge浏览器标签页左右移动mac:command+option+left/right 关闭标签页mac:command+w 开发者工具mac:command+option+i fn+f12","tags":["快捷键"]},{"title":"2025.6.6学习日记","path":"/2025/06/06/学习日记/2025.6.6学习笔记/","content":"学习内容1. 优化了一下个人博客的图片上传工作流由于大部分笔记在语雀中,导致图片上传后外链无法访问,所以今天通过picgo➕github搭建了一个图床.具体流程如下: 首先需要在github中创建一个仓库,用来存放图片 然后在picgo中配置github的仓库,将图片上传到github中操作如下:mac:shift+control+command+4 截图 然后在vscode中option+command+u上传到图床后会自动生成markdown的链接. 2. 优化了一下自己记笔记发博客的工作流语雀写笔记还是太麻烦了。所以准备以后还是用vscode写笔记,然后直接运行一行命令同步到仓库,而且还有补全工具。 3. 力扣两道每日一题：这题思路很清晰，贪心加一个栈的模拟题，实现有一些小细节需要注意。前K个高频元素：map记录频率，然后小顶堆维护前K个元素。（第一遍做用了单调栈，忘记用小顶堆维护了）做了关于最大最小堆的笔记。 4. 看了java容器相关的八股文记在java30天笔记里面了。 5. 项目部分看了session登录拦截器相关的部分6. 杂谈感觉需要增加基础的学习，项目可以先读一遍文档。","tags":["基础","博客","项目","日记","leetcode","picgo"]},{"title":"Hello World","path":"/2025/06/05/hello-world/","content":"hexo的基本使用和模板常用模版 ---title: 个人博客搭建tags: [博客, hexo]date: 2025-06-01--- 快捷部署: hexo clean hexo g hexo d Quick Start创建一篇文章$ hexo new My New Post 更多信息: Writing 运行服务$ hexo server 更多信息: Server 生成静态文件$ hexo generate 更多信息: Generating 部署到远程站点$ hexo deploy 更多信息: Deployment 文章模版---# 基本信息title: title date: date tags: []categories: []description: # excerpt 也可 # 封面cover: banner: poster: # 海报（可选，全图封面卡片） topic: 标题上方的小字 # 可选 headline: 大标题 # 必选 caption: 标题下方的小字 # 可选 color: 标题颜色 # 可选# 插件sticky: # 数字越大越靠前mermaid:katex: mathjax: # 可选topic: # 专栏 idauthor: references:comments: # 设置 false 禁止评论indexing: # 设置 false 避免被搜索breadcrumb: # 设置 false 隐藏面包屑导航leftbar: rightbar:h1: # 设置为 隐藏标题type: # tech/story---","tags":["欢迎页"]},{"title":"2025.6.5学习日记","path":"/2025/06/05/学习日记/2025.6.5学习日记/","content":"学习内容1. hexo轻量化框架搭建个人博客搭建了个人博客网站.简化了一下笔记的流程:直接本地写markdown笔记然后直接运行一行命令同步太仓库,比较方便.todo:后期可以考虑加一个打卡墙. 2. leetcode每日一题并查集的题,太久没做图论有点忘了 class Solution public String smallestEquivalentString(String s1, String s2, String baseStr) int[] fa = new int[26]; for (int i = 0; i 26; i++) fa[i] = i; for (int i = 0; i s1.length(); i++) merge(fa, s1.charAt(i) - a, s2.charAt(i) - a); char[] s = baseStr.toCharArray(); for (int i = 0; i s.length; i++) s[i] = (char) (find(fa, s[i] - a) + a); return new String(s); private int find(int[] fa, int x) if (fa[x] != x) fa[x] = find(fa, fa[x]); return fa[x]; private void merge(int[] fa, int x, int y) int fx = find(fa, x); int fy = find(fa, y); // 把大的代表元指向小的代表元 if (fx fy) fa[fy] = fx; else fa[fx] = fy; 3. 健身练胸日","tags":["日记","leetcode"]},{"title":"技术派项目笔记","path":"/2025/06/04/技术派项目笔记/","content":"开启新项目要考虑的事情业务模块拆解首先对业务模块进行拆解，除了业务属性纬度以外，还有一个很重要的属性就是参与者角色。 首先对功能、模块划分、概要设计，详细设计有初步的了解。 主要就是功能模块设计 + DB 的设计。 启动项目mysql 启动 redis 启动： 路径 ： D:\\workTools\\Redis-x64-3.2.100 redis-server.exe redis.windows.conf 启动成功，点击进入首页: http://127.0.0.1:8080 跑环境 font style=color:#000000;D:\\sys\\Desktop\\Workplace\\IDEA_Projects\\paicoding/font下载位置 font style=color:#000000;git clone git@github.com:itwanger/paicoding.git D:\\sys\\Desktop\\Workplace\\IDEA_Projects\\paicoding/fontgit 下载 git clone 出现报错 ， 原因：github ssh 秘钥没有配置 1 打开运行，输入services.msc，确定 找到 OpenSSH Authentication Agent 服务，需开启它. ssh-keygen -t rsa -C “你的邮箱地址” 我用的是Administrator用户，执行完后，可以在 C:\\Users\\Administrator.ssh 目录下生成 id_rsa 和 id_rsa.pub 这两个文件。如果你没有用Administrator用户，也是在类似的目录下 项目结构该项目主要有五个模块，各模块功能如下： paicoding-api： 用于定义一些通用的枚举、实体类，包含 DO（数据对象）、DTO（数据传输对象）、VO（视图对象）等，为不同层之间的数据交互提供统一的格式和规范。 paicoding-core： 核心工具和组件相关的模块，像工具包 util 以及通用的组件都放在这里。按照包路径对模块功能进行拆分，例如搜索、缓存、推荐等功能组件。 paicoding-service： 服务模块，负责业务相关的主要逻辑，数据库（DB）的操作都在这个模块中进行。 paicoding-ui： 存放 HTML 前端资源，包括 JavaScript、CSS、Thymeleaf 等，主要用于构建用户界面。 paicoding-web： Web 模块，是 HTTP 请求的入口，也是项目启动的入口，同时包含权限身份校验、全局异常处理等功能。 web 模块：admin：admin 目录存放和管理后台相关的代码，主要处理管理员对系统的管理操作。 common：common 一般用来存放项目通用的代码，提高代码的复用性和可维护性。 comoinent：TemplateEngineHelper Thymeleaf模版渲染引擎，通过末班引擎进行服务端渲染（SSR），在初次渲染速度方面有显著优势。 configForumDataSourceInitializer 用来进行数据库表的初始化，首次启动时候执行： DbChangeSetLoader 杂项笔记请求参数解析如果一个请求不会引起服务器上任何资源的状态变化，那就可以使用 GET 请求 AOP技术派中的 AOP 记录接口访问日志是放在 paicoding-core 模块下的 mdc 包下。 三层架构 为什么要使用微服务而不是单体项目呢？用不用微服务取决于业务量，能用单体的绝对不用微服务，毕竟单体的好处显而易见，当业务简单的时候，部署非常简单，技术架构也简单，不用考虑微服务间的调用什么的，但是随着业务的复杂，单体的缺点也就暴露出来了，例如修改一个模块上线，就要整个服务下线，这在某些业务中是不被允许的，其次单体复杂度高了，部署就缓慢了，出现问题排查也很困难，这些的前提就是业务复杂度提高了。 所以微服务的出现在我看来最初就是为了解决业务复杂单体所出现的问题的，将业务拆分到不同的模块，不同的模块单独部署开发，提高了开发效率，节省了维护时间成本，问题排查也方便了很多，微服务也并不是没有缺点，只不过是维护一个平衡，例如需要引入注册中心，为了方便配置的修改，还需要引入配置中心，不可能修改一个配置重新打包发布，服务间的调用组件，很多都是为了使用微服务而引入的。 所以没有哪种技术更好，只有哪种技术更符合当下的业务，抛开业务谈技术，在我看来并不是那么可靠。 工厂模式创建型设计模式，定义一个创建对象的接口，但让实现这个接口的类决定实例化哪个类。 工厂方法把类的实例化延迟到子类中进行。 @Bean 就是一个工厂方法 各种注解@Slf4j@Slf4j：借助 Lombok 自动添加 SLF4J 日志记录器，简化日志记录代码。 @Value@Configuration@Configuration：把类标记为 Spring 配置类，允许在类里使用 @Bean 注解定义 Spring Bean。 在 Spring 应用启动时，Spring 会扫描带有 @Configuration 注解的类，将其作为配置类来处理，把类里使用 @Bean 注解定义的方法返回的对象注册到 Spring 容器中。 @Component@Component：通用的组件注解，用于标记一个类为 Spring 组件，Spring 会自动扫描并将其注册到容器中。 @Service@Service：@Component 的特殊化注解，通常用于标记服务层类。 @Repository@Repository：@Component 的特殊化注解，通常用于标记数据访问层类。 @Controller@Controller：@Component 的特殊化注解，通常用于标记 Web 控制器类。 @Bean@Bean注册一个实体类 @册一个实体类 实体对象 用 GET 还是 POSTGET - 从指定的资源请求数据。POST - 向指定的资源提交要被处理的数据。 GET 请求是 HTTP 协议中的一种请求方法，通常用于请求访问指定的资源。如果一个请求不会导致服务器上任何资源的状态变化，那你就可以使用 GET 请求。 Filter过滤器 首先进入 filter，执行相关业务逻辑 若判定通行，则进入 Servlet 逻辑，Servlet 执行完毕之后，又返回 Filter，最后在返回给请求方 判定失败，直接返回，不需要将请求发给 Servlet 过滤器的使用如果要使用过滤器，实现 Filter 接口，需要重写 doFilter 方法，在方法中编写过滤逻辑。init: 初始化时执行destory: 销毁时执行doFilter: 重点关注这个，filter 规则命中的请求，都会走进来三个参数，注意第三个 FilterChain，这里是经典的责任链设计模式执行 filterChain.doFilter(servletRequest, servletResponse) 表示会继续将请求执行下去；若不执行这一句，表示这一次的 http 请求到此为止了，后面的走不下去了 过滤器在项目中的应用 身份识别,并保存身份到ReqInfoContext上下文中 记录请求记录 添加跨域支持 跨域问题:跨域问题（CORS）的本质是浏览器的安全限制，而代理服务器是解决该问题的关键方案之一。以下通过​​场景化解析​​帮你彻底理解代理机制. 假如说:前端​​：运行在 http://localhost:5700​​后端​​：运行在 http://localhost:8080​​问题​​：前端直接请求后端接口时，浏览器会拦截并报错： 代理与服务器间的通信属于服务器之间的通信,不受浏览器同源规则的约束. ServletServlet的使用姿势，以及注册自定义的Servelt的四种姿势 ● @WebServlet 注解:在自定义的servlet上添加Servlet3+的注解@WebServlet，来声明这个类是一个Servlet和Fitler的注册方式一样，使用这个注解，需要配合Spring Boot的@ServletComponentScan，否则单纯的添加上面的注解并不会生效 /** * 使用注解的方式来定义并注册一个自定义Servlet */@WebServlet(urlPatterns = /annotation)public class AnnotationServlet extends HttpServlet @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException String name = req.getParameter(name); PrintWriter writer = resp.getWriter(); writer.write([AnnotationServlet] welcome + name); writer.flush(); writer.close(); 还需要配置启动类 @ServletComponentScan@SpringBootApplicationpublic class Application public static void main(String[] args) SpringApplication.run(Application.class); ● ServletRegistrationBean bean定义在Filter的注册中，我们知道有一种方式是定义一个Spring的BeanFilterRegistrationBean来包装我们的自定义Filter，从而让Spring容器来管理我们的过滤器；同样的在Servlet中，也有类似的包装bean: ServletRegistrationBean自定义的bean如下，注意类上没有任何注解: public class RegisterBeanServlet extends HttpServlet @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException String name = req.getParameter(name); PrintWriter writer = resp.getWriter(); writer.write([RegisterBeanServlet] welcome + name); writer.flush(); writer.close(); 接下来我们需要定义一个ServletRegistrationBean，让它持有RegisterBeanServlet的实例 @Beanpublic ServletRegistrationBean servletBean() ServletRegistrationBean registrationBean = new ServletRegistrationBean(); registrationBean.addUrlMappings(/register); registrationBean.setServlet(new RegisterBeanServlet()); return registrationBean; ● ServletContext 动态添加这种姿势，在实际的Servlet注册中，其实用得并不太多，主要思路是在ServletContext初始化后，借助javax.servlet.ServletContext#addServlet(java.lang.String, java.lang.Class? extends javax.servlet.Servlet)方法来主动添加一个Servlet 所以我们需要找一个合适的时机，获取ServletContext实例，并注册Servlet，在SpringBoot生态下，可以借助ServletContextInitializer public class ContextServlet extends HttpServlet @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException String name = req.getParameter(name); PrintWriter writer = resp.getWriter(); writer.write([ContextServlet] welcome + name); writer.flush(); writer.close(); @Componentpublic class SelfServletConfig implements ServletContextInitializer @Override public void onStartup(ServletContext servletContext) throws ServletException ServletRegistration initServlet = servletContext.addServlet(contextServlet, ContextServlet.class); initServlet.addMapping(/context); ● 普通的spring bean模式","tags":["项目","技术派"]},{"title":"个人博客搭建","path":"/2025/06/02/个人博客搭建/","content":"环境配置: node -v #查看node版本npm -v #查看npm版本 可以使用nvm来管理node版本 安装 hexo: npm install hexo-cli -g 出现权限问题 ,修改: sudo chown -R $(whoami) $(npm config get prefix)/lib/node_modules,bin,share #修改权限范围 初始化个人博客文件夹: hexo init /Users/mac/Blog/JakicDong.github.io # 博客初始化，这里是创建的本地博客文件夹，执行后会自动创建，我这里图简洁，直接用了我网站的地址 hihulu.github.io 为文件名cd /Users/mac/Blog/JakicDong.github.io # 进入本地的博客文件夹hexo server # 打开本地服务器预览 UsersmacJakicDong.github.io 4.Github部署为了部署到Github上，需要安装hexo-deployer-git插件，命令如下： sudo npm install hexo-deployer-git --save 然后找到自己的本地博客文件夹，修改博客根目录下的_config.yml文件中的deploy，修改成： deploy: type: git repo: git@github.com:JakicDong/JakicDong.github.io.git #这个地址是从github仓库复制过来的ssh branch: main （⚠️注意，这里有一个很容易犯错的点，我们在创建“hihulu.github.io”这个仓库的时候，一定要创建和你github用户名相同的仓库，后面加.http://github.io，只有这样，将来要部署到GitHub page的时候，才会被识别，也就是http://xxxx.github.io，其中xxx就是你注册GitHub的用户名。所以上图我的仓库显示的是“hihuluhihulu.github.io”，如果仓库名和用户名不一致，后面是根本打不开这个网站的～） 然后就可以通过以下命令行上传github了 hexo g #hexo generate的简写，即把刚刚做的改动生成更新一下hexo d #hexo deploy，上传到github网站 还有一些常用的命令行： hexo clean #清空一下缓存，有时候博客页面显示不正常也可以试试这个命令行hexo server # 在本地服务器运行，网址默认https://localhost:4000 5.更改主题很多前端大牛博主设计了很多好看的主题，网址https://hexo.io/themes/ ，可以预览并选择你喜爱的主题进行应用。 这里浅以一个蛮火的主题butterfly主题来走一个安装主题的步骤～ 执行以下代码： git clone -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/butterfly 运行成功之后，在项目文件夹根目录中可以查看到新的主题themes文件夹：butterfly 在博客的项目文件夹下，修改_config.yml配置文件如下: # theme: landscape 默认主题theme: butterfly 此时主题还不能正常配置使用，需要安装pug 以及stylus 的渲染器： npm install hexo-renderer-pug hexo-renderer-stylus --save 最后推送到github # 清除缓存b.json 和已生成的静态文件 publichexo clean# 生成静态页面到默认设置的 public 文件夹hexo g# 部署到设定的仓库或上传部署至服务端hexo d 至此主题安装end，可访问https://hihulu.github.io/ 查看～ https://JakicDong.github.io/ # 7.4 常用命令hexo new name # 新建文章hexo new page name # 新建页面hexo g # 生成页面hexo d # 部署hexo g -d # 生成页面并部署hexo s # 本地预览hexo clean # 清除缓存和已生成的静态文件hexo help # 帮助","tags":["博客","hexo"]},{"title":"算法学习笔记","path":"/2025/06/01/算法笔记/算法题刷题笔记/","content":"常用操作一些好的逻辑思路1. 反问题如果一个问题正问题很复杂,可以尝试想一下反问题,比如求有恰好k个相邻数的数组个数,正问题很复杂,但是反问题只需要找到n-k-1个分割线,把数组分割成n-k块.3405. 统计恰好有 K 个相等相邻元素的数组数目 ACM 格式import java.util.*;import java.io.*;public class Main public static void main(String[] args) throws IOException BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); String line; while ((line = br.readLine()) != null) // 逐行读取 int n = Integer.parseInt(line.trim()); int[] nums = new int[n]; String[] parts = br.readLine().split( ); for (int i = 0; i n; i++) nums[i] = Integer.parseInt(parts[i]); // 处理逻辑 // 输出结果 System.out.println(result); public static void main(String[] args) Scanner scanner = new Scanner(System.in); String s = scanner.next(); System.out.println(replaceNumber(s)); scanner.close(); 第二种: import java.util.*;import java.io.*;public static void main(String[] args) Scanner scanner = new Scanner(System.in); String s = scanner.next(); System.out.println(replaceNumber(s)); scanner.close(); 杂项操作绝对值:Math.abs();Int最大值:Integer.MAX_VALUE取随机值： import java.util.Random;import java.util.concurrent.ThreadLocalRandom;public class RandomDemo public static void main(String[] args) int n = 10; //0~9 // 方法1: Math.random() int random1 = (int) (Math.random() * n); System.out.println(Math.random(): + random1); // 方法2: Random类 Random rand = new Random(); int random2 = rand.nextInt(n); System.out.println(Random: + random2); // 方法3: ThreadLocalRandom（多线程安全） int random3 = ThreadLocalRandom.current().nextInt(n); System.out.println(ThreadLocalRandom: + random3); Array 常用操作// ========== 数组声明与初始化 ==========int[] arr = new int[5]; // 创建空数组 [0,0,0,0,0]int[] nums = 3,1,4,5,2; // 直接初始化String[] strArr = A, B, C; // 字符串数组int[][] matrix = 1,2, 3,4,5; // 二维数组// ========== 基本操作 ==========// 访问元素int first = nums[0]; // 获取第一个元素 → 3nums[2] = 9; // 修改元素 → [3,1,9,5,2]// 获取长度int len = nums.length; // 一维数组长度 → 5int cols = matrix[1].length; // 二维数组第二维长度 → 3// ========== 遍历操作 ==========// 普通for循环for(int i=0; inums.length; i++) System.out.print(nums[i] + ); // 3 1 9 5 2// 增强for循环for(int num : nums) System.out.print(num + );// 二维数组遍历for(int[] row : matrix) for(int n : row) System.out.print(n + ); // 1 2 / 3 4 5 // ========== 数组工具操作 ==========// 排序Arrays.sort(nums); // 排序后 → [1,2,3,5,9]// 复制int[] copy1 = Arrays.copyOf(nums, 3); // 复制前3元素 → [1,2,3]int[] copy2 = Arrays.copyOfRange(nums, 1, 4); // 复制1-3索引 → [2,3,5]// 比较boolean isEqual = Arrays.equals(nums, copy1); // false// 填充Arrays.fill(nums, 0); // 全部填充0 → [0,0,0,0,0]Arrays.fill(nums, 1, 3, 5); // 索引1-2填充5 → [0,5,5,0,0]// ========== 类型转换 ==========// 数组转List（固定大小）ListInteger list = Arrays.asList(1,2,3); // 数组转StreamIntStream stream = Arrays.stream(nums);// ========== 其他操作 ==========// 二分查找（需先排序）int index = Arrays.binarySearch(nums, 5); // 返回元素索引// 多维数组操作int[][] matrixCopy = Arrays.copyOf(matrix, matrix.length); // 浅拷贝String deepStr = Arrays.deepToString(matrix); // [[1, 2], [3, 4, 5]]// 反转数组for(int i=0; inums.length/2; i++) int temp = nums[i]; nums[i] = nums[nums.length-1-i]; nums[nums.length-1-i] = temp; Array 排序： 升序排序：Arrays.sort(array); 降序排序：Arrays.sort(Collections.reverseOrder()); 和 int 数组相互转换： Integer[] arr = 1,2,3;ArrayListInteger list = new ArrayList(Arrays.asList(arr));ArrayListInteger list = new ArrayList();Integer[] arr = list.toArray(new Integer[0]);//但是如何转成int[]数组呢//方法1 arr = list.stream().mapToInt(Integer::valueOf).toArray(); List 常用操作// ====================== 1. 初始化 List ======================ListString arrayList = new ArrayList(); // 可修改列表ListInteger linkedList = new LinkedList(); ListString immutableList = List.of(A, B, C); // Java9+ 不可变列表// ====================== 2. 添加元素 ======================arrayList.add(Apple); // 末尾添加arrayList.add(0, Banana); // 索引0插入arrayList.addAll(List.of(Orange, Grape)); // 批量添加// ====================== 3. 访问元素 ======================String firstElement = arrayList.get(0); // Bananaboolean containsApple = arrayList.contains(Apple); // trueint indexOfOrange = arrayList.indexOf(Orange); // 2// ====================== 4. 删除元素 ======================arrayList.remove(Banana); // 按值删除arrayList.remove(0); // 按索引删除arrayList.clear(); // 清空列表// ====================== 5. 修改元素 ======================arrayList.add(Mango);arrayList.set(0, Pineapple); // 修改索引0的元素// ====================== 6. 遍历 List ======================// 方式1: 普通for循环for (int i = 0; i arrayList.size(); i++) System.out.println(arrayList.get(i));// 方式2: 增强for循环for (String fruit : arrayList) System.out.println(fruit);// 方式3: 迭代器IteratorString it = arrayList.iterator();while (it.hasNext()) System.out.println(it.next());// 方式4: forEach + LambdaarrayList.forEach(System.out::println);// ====================== 7. 其他操作 ======================int size = arrayList.size(); // 列表长度boolean isEmpty = arrayList.isEmpty(); // 是否为空ListString subList = arrayList.subList(0, 2); // 截取子列表Object[] array = arrayList.toArray(); // 转为数组// ====================== 8. 注意事项 ======================/*1. ArrayList初始容量10，扩容1.5倍 2. LinkedList用节点链接实现3. 线程不安全，多线程环境使用：ListString syncList = Collections.synchronizedList(new ArrayList());4. 快速失败机制(fast-fail)：遍历时修改会抛出ConcurrentModificationException*/ 二维List例子:import java.util.ArrayList;import java.util.Arrays;import java.util.List;public class TwoDListExample public static void main(String[] args) // ====================== // 1. 创建二维List // ====================== ListInteger[] ls = new ArrayList[26]; Arrays.setAll(ls,i-new ArrayList()); // 方法1: 使用Arrays.asList()初始化 ListListInteger matrix1 = new ArrayList(); matrix1.add(Arrays.asList(1, 2, 3)); matrix1.add(Arrays.asList(4, 5, 6)); matrix1.add(Arrays.asList(7, 8, 9)); // 方法2: 动态创建空二维List ListListString matrix2 = new ArrayList(); // 方法3: 使用嵌套循环初始化 ListListCharacter matrix3 = new ArrayList(); for (int i = 0; i 3; i++) ListCharacter row = new ArrayList(); for (int j = 0; j 4; j++) row.add((char) (A + i + j)); matrix3.add(row); // ====================== // 2. 添加元素 // ====================== // 添加新行 matrix2.add(new ArrayList(Arrays.asList(Java, Python))); matrix2.add(new ArrayList(Arrays.asList(C++, JavaScript))); // 在指定行添加元素 matrix2.get(0).add(Ruby); // 第一行添加元素 matrix2.get(1).add(0, Go); // 第二行开头插入元素 // 添加新行（空行） matrix2.add(new ArrayList()); matrix2.get(2).add(Swift); // 给新行添加元素 // ====================== // 3. 访问元素 // ====================== // 访问单个元素 int element = matrix1.get(1).get(2); // 获取第二行第三列元素 → 6 String lang = matrix2.get(0).get(1); // 获取第一行第二列元素 → Python // 获取行数 int rows = matrix1.size(); // 获取列数（特定行） int colsRow0 = matrix1.get(0).size(); int colsRow2 = matrix2.get(2).size(); // ====================== // 4. 修改元素 // ====================== matrix1.get(0).set(0, 100); // 修改第一行第一列: 1 → 100 matrix2.get(1).set(2, TypeScript); // 修改第二行第三列 // ====================== // 5. 删除元素 // ====================== // 删除指定位置的元素 matrix1.get(2).remove(1); // 删除第三行第二列元素(8) // 删除整行 matrix2.remove(2); // 删除第三行 // ====================== // 6. 遍历二维List // ====================== System.out.println( 遍历matrix1:); // 方法1: 索引遍历 for (int i = 0; i matrix1.size(); i++) for (int j = 0; j matrix1.get(i).size(); j++) System.out.print(matrix1.get(i).get(j) + ); System.out.println(); System.out.println( 遍历matrix2:); // 方法2: 增强for循环 for (ListString row : matrix2) for (String item : row) System.out.print(item + ); System.out.println(); System.out.println( 遍历matrix3:); // 方法3: 使用forEach + lambda matrix3.forEach(row - row.forEach(item - System.out.print(item + )); System.out.println(); ); // ====================== // 7. 其他常用操作 // ====================== // 检查是否为空 boolean isEmpty = matrix2.isEmpty(); // 检查是否包含元素 boolean containsPython = matrix2.get(0).contains(Python); // 查找元素位置 int rowIndex = -1, colIndex = -1; for (int i = 0; i matrix1.size(); i++) int index = matrix1.get(i).indexOf(5); if (index != -1) rowIndex = i; colIndex = index; break; // 转换为二维数组 String[][] array2D = new String[matrix2.size()][]; for (int i = 0; i matrix2.size(); i++) ListString row = matrix2.get(i); array2D[i] = row.toArray(new String[0]); ////翻转行 //方法1 使用工具类 ListListInteger matrix = new ArrayList(); // 假设 matrix 已经填充数据 // 翻转行（首行变末行，次行变次末行，依此类推） Collections.reverse(matrix); //方法2 ListListInteger matrix = new ArrayList(); // 假设 matrix 已经填充数据 int left = 0; int right = matrix.size() - 1; while (left right) // 使用临时行 temp 交换左右两行 ListInteger temp = matrix.get(left); matrix.set(left, matrix.get(right)); matrix.set(right, temp); left++; right--; //方法3 Stream ListListInteger matrix = new ArrayList(); // 假设 matrix 已经填充数据 // 翻转行顺序 ListListInteger reversed = IntStream.range(0, matrix.size()) .mapToObj(i - matrix.get(matrix.size() - 1 - i)) .collect(Collectors.toList()); matrix = reversed; // 如果需要原地翻转，需重新赋值 // 打印结果 System.out.println( matrix1: + matrix1); System.out.println(matrix2: + matrix2); System.out.println(matrix3: + matrix3); System.out.println(找到数字5的位置: [ + rowIndex + ][ + colIndex + ]); HashSet 常用操作// =================== HashSet 基础操作 ===================import java.util.Collections;import java.util.HashSet;import java.util.Iterator;import java.util.Set;// 创建对象SetString set = new HashSet(); // 空集合（默认初始容量16，负载因子0.75）SetInteger initSet = new HashSet(32); // 指定初始容量SetString prefilled = new HashSet(Arrays.asList(A, B, C)); // 通过集合初始化// 元素操作boolean added = set.add(Apple); // 添加元素 → true（首次添加）boolean dupAdd = set.add(Apple); // 添加重复元素 → falseboolean hasBanana = set.contains(Apple); // 检查存在 → trueboolean removed = set.remove(Apple); // 删除元素 → true（存在时）set.clear(); // 清空集合// 批量操作SetString fruits = new HashSet(Arrays.asList(Orange, Mango));boolean addedAll = set.addAll(fruits); // 合并集合 → true（集合改变时）boolean retainAll = set.retainAll(Arrays.asList(Mango)); // 保留交集 → true（集合改变时）boolean removeAll = set.removeAll(fruits); // 删除所有匹配元素 → true（集合改变时）// 遍历操作set.add(Apple);set.add(Banana);for (String item : set) // 增强for循环（无序） System.out.print(item + ); // 输出顺序不确定（如 Banana Apple）IteratorString it = set.iterator(); // 迭代器遍历while (it.hasNext()) System.out.print(it.next() + );set.forEach(item - System.out.print(item)); // Java8+ Lambda遍历// 集合信息int size = set.size(); // 元素数量（如 2）boolean isEmpty = set.isEmpty(); // 是否空集合 → falseObject[] array = set.toArray(); // 转Object数组String[] strArray = set.toArray(new String[0]); // 转指定类型数组// 特殊操作SetString cloneSet = (HashSetString) ((HashSetString) set).clone(); // 浅拷贝SetString syncSet = Collections.synchronizedSet(set); // 线程安全包装// 集合运算示例SetString set1 = new HashSet(Arrays.asList(A, B));SetString set2 = new HashSet(Arrays.asList(B, C));SetString union = new HashSet(set1); // 并集 → [A, B, C]union.addAll(set2);SetString intersection = new HashSet(set1); // 交集 → [B]intersection.retainAll(set2);SetString difference = new HashSet(set1); // 差集 → [A]difference.removeAll(set2);/* 核心特性：1. 唯一性：基于 hashCode() 和 equals() 判断重复2. 无序性：遍历顺序不保证与插入顺序一致3. 允许 null 元素（但只能有一个 null）4. 基础操作时间复杂度：add/remove/contains → 平均 O(1)5. 非线程安全：需通过 Collections.synchronizedSet 包装实现线程安全*/ HashMap 常用操作// =================== HashMap 基础操作 ===================import java.util.Collections;import java.util.HashMap;import java.util.Map;import java.util.Set;// 创建对象MapString, Integer map = new HashMap(); // 默认容量16，负载因子0.75MapString, String initMap = new HashMap(32); // 指定初始容量MapString, Integer prefilled = new HashMap(Map.of(A, 1, B, 2)); // Java9+快速初始化// 增删改操作map.put(Apple, 10); // 添加键值对 → Apple=10map.put(Banana, 20); // → Apple=10, Banana=20map.putIfAbsent(Apple, 50); // 仅当键不存在时添加 → 原值10保持不变map.replace(Apple, 15); // 替换已有键的值 → Apple=15, Banana=20map.remove(Banana); // 删除键 → Apple=15map.replace(Apple, 15, 20); // 键值匹配时替换 → Apple=20map.clear(); // 清空映射// 查询操作int count = map.get(Apple); // 获取值（需确保键存在）Integer countSafe = map.get(Orange); // 键不存在时返回nullboolean existsKey = map.containsKey(Apple); // 检查键是否存在 → trueboolean existsValue = map.containsValue(20); // 检查值是否存在 → trueint size = map.size(); // 键值对数量boolean isEmpty = map.isEmpty(); // 是否为空映射// 遍历操作（4种方式）// 1. Entry遍历（推荐）for (Map.EntryString, Integer entry : map.entrySet()) System.out.println(entry.getKey() + : + entry.getValue());// 2. Key遍历for (String key : map.keySet()) System.out.println(key + - + map.get(key));// 3. Value遍历for (Integer value : map.values()) System.out.println(Value: + value);// 4. Java8+ Lambda遍历map.forEach((k, v) - System.out.println(k + = + v));// 批量操作MapString, Integer newItems = Map.of(Cherry, 5, Durian, 8);map.putAll(newItems); // 合并映射 → Apple=20, Cherry=5, Durian=8// 特殊值处理map.put(null, 0); // 允许null键 → null=0map.put(Mango, null); // 允许null值 → null=0, Mango=null// 高级操作（Java8+）map.computeIfAbsent(Orange, k - 3); // 不存在时计算 → 添加 Orange=3map.computeIfPresent(Apple, (k, v) - v + 5); // 存在时更新 → Apple=25map.merge(Apple, 10, (oldVal, newVal) - oldVal + newVal); // 合并值 → Apple=35// 线程安全包装MapString, Integer syncMap = Collections.synchronizedMap(map);// 不可变映射（Java9+）MapString, Integer immutableMap = Map.ofEntries( Map.entry(A, 1), Map.entry(B, 2));/* 核心特性：1. 键唯一性：基于 hashCode() 和 equals() 判断重复2. 无序存储：迭代顺序不保证与插入顺序一致3. 允许一个null键和多个null值4. 基础操作时间复杂度：get/put → 平均 O(1)5. 扩容机制：当元素数量超过（容量*负载因子）时自动翻倍扩容6. 树化优化：当链表长度超过8时转红黑树（Java8+）*/ HashMapCharacter, Integer hm_s = new HashMap();//遍历字符串的所有字符（更清晰的逻辑）for (char c : s.toCharArray()) hm_s.merge(c, 1, Integer::sum);// 使用getOrDefault避免NullPointerExceptionint countS = hm_s.getOrDefault(c, 0); 一个 Key 只能对应一个值，所以如果要实现类似 Multimap 的结构需要如下方式： //初始化HashMapString, ListInteger multiValueMap = new HashMap();/////添加元素if (!multiValueMap.containsKey(scores)) multiValueMap.put(scores, new ArrayList());multiValueMap.get(scores).add(90);// 若键不存在，自动创建空列表multiValueMap.computeIfAbsent(scores, k - new ArrayList()).add(90);multiValueMap.computeIfAbsent(scores, k - new ArrayList()).add(85);////访问元素//获取某个键的所有值ListInteger scores = multiValueMap.get(scores);if (scores != null) for (int num : scores) System.out.println(num); //输出 90, 85 //避免 NullPointerException的情况ListInteger scores = multiValueMap.getOrDefault(scores, new ArrayList());for (int num : scores) System.out.println(num);////删除元素//删除整个键值对multiValueMap.remove(scores);// 删除某个键的特定值ListInteger scores = multiValueMap.get(scores);if (scores != null) scores.remove(Integer.valueOf(90)); // 删除值为 90 的元素 // 如果列表为空，可选删除键 if (scores.isEmpty()) multiValueMap.remove(scores); ////遍历哈希表// 遍历所有键值对for (Map.EntryString, ListInteger entry : multiValueMap.entrySet()) String key = entry.getKey(); ListInteger values = entry.getValue(); System.out.println(key + : + values);//遍历所有键for (String key : multiValueMap.keySet()) System.out.println(Key: + key);//遍历所有值for (ListInteger values : multiValueMap.values()) System.out.println(Values: + values); String的常用操作// =================== String 常用操作 ===================// 创建对象String str1 = Hello; // 直接量创建（字符串常量池）String str2 = new String(World); // 堆内存新对象char[] chars = J,a,v,a;String str3 = new String(chars); // 通过字符数组创建 → Java// 基本操作int len = str1.length(); // 获取长度 → 5char c = str1.charAt(1); // 获取索引1字符 → eString substr1 = str1.substring(2); // 从索引2截取 → lloString substr2 = str1.substring(1,4); // 截取1-3索引 → ellString concatStr = str1.concat( World);// 拼接 → Hello WorldString upper = str1.toUpperCase(); // 转大写 → HELLOString lower = HELLO.toLowerCase(); // 转小写 → helloString trimStr = text .trim(); // 去首尾空格 → textString replaced = str1.replace(l, L);// 替换字符 → HeLLoString replacedAll = a1b2c3.replaceAll(\\\\d, #); // 正则替换 → a#b#c#// 转换与比较char[] arr = str1.toCharArray(); // 转字符数组 → [H,e,l,l,o]byte[] bytes = str1.getBytes(); // 按默认编码转字节数组boolean eq1 = str1.equals(Hello); // 值比较 → trueboolean eq2 = str1.equalsIgnoreCase(hElLo); // 忽略大小写 → trueint cmp = str1.compareTo(Hella); // 字典序比较 → 正数（o a）// 正则处理boolean matches = 123.matches(\\\\d+); // 正则匹配 → trueString[] parts = a,b,c.split(,); // 分割字符串 → [a,b,c]String[] regexParts = a1b2c3.split(\\\\d); // 按数字分割 → [a,b,c]// 格式化处理String format1 = String.format(%s-%d, ID, 100); // → ID-100String format2 = String.join(|, A, B, C); // → A|B|C// 特殊判断boolean isEmpty = .isEmpty(); // 空字符串 → trueboolean isBlank = .isBlank(); // 全空白字符（Java 11+） → trueboolean starts = str1.startsWith(He); // 开头判断 → trueboolean ends = str1.endsWith(lo); // 结尾判断 → true/* 核心特性：1. 不可变性：所有操作返回新字符串，原对象不变2. 字符串常量池复用机制：直接量赋值优先使用常量池3. 支持正则表达式操作（split/matches/replaceAll等）4. 包含丰富的格式化方法（format/join等）*/ int转StringString s = String.valueOf(i);String s = Integer.toString(i);String 转 intString str = 123;int num = Integer.parseInt(str); StringBuffer 和 StringBuilderStringBuilder 类在 Java 5 中被提出，它和 StringBuffer 之间的最大不同在于 StringBuilder 的方法不是线程安全的（不能同步访问）。由于 StringBuilder 相较于 StringBuffer 有速度优势，所以多数情况下建议使用 StringBuilder 类。 // =================== StringBuilder ===================// 创建对象StringBuilder sb = new StringBuilder(); // 默认容量16StringBuilder sb2 = new StringBuilder(Hello); // 指定初始内容// 基本操作sb.append( World); // 追加内容 → Hello Worldsb.insert(5, Java); // 指定位置插入 → Hello Java Worldsb.delete(5, 10); // 删除5-9位置 → Hello Worldsb.replace(6, 11, Earth); // 替换指定区间 → Hello Earthsb.reverse(); // 反转 → htraE olleH sb.setLength(5); // 截断保留前5字符 → htraEchar c = sb.charAt(2); // 获取索引2的字符 → rsb.setCharAt(0, H); // 修改索引0字符 → HtraEint len = sb.length(); // 获取当前长度 → 5String s = sb.toString(); // 转换为String// 正向遍历for (int i = 0; i sb.length(); i++) char c = sb.charAt(i); System.out.println(c);// 链式调用StringBuilder sb3 = new StringBuilder() .append(123) // 支持多类型 .append(3.14) .append(true);// =================== StringBuffer ===================// 创建对象（操作方法与StringBuilder完全一致）StringBuffer sbf = new StringBuffer(); sbf.append(100); // 追加数值sbf.insert(3, new char[]A,B); // 插入字符数组sbf.deleteCharAt(4); // 删除单个字符sbf.setLength(0); // 清空缓冲区（复用对象）// 线程安全示例sbf.append(ThreadSafe); // 所有方法都有synchronized修饰符/* 共性特征：1. 初始容量16，自动扩容（每次扩容2n+2）2. append() 支持所有基础类型/Object类型3. 修改后对象地址不变（与String的不可变性对比）4. 主要方法：append/insert/delete/replace/reverse*/String s1 = buffer.toString(); // StringBuffer → StringString s2 = builder.toString(); // StringBuilder → String PriorityQueue的常用操作最大堆（降序优先队列） PriorityQueue pq new PriorityQueue((a, b) - b - a); 自定义比较器： (a, b) - b - a 是一个 Lambda 表达式，用作自定义比较器。它通过计算 b - a 来确定元素的优先级： 当结果为正数时，说明 a 应排在 b 之后，即 b 的优先级更高。 当结果为负数或零时，a 的优先级不低于 b。 与默认行为的对比： 默认情况下，优先队列使用自然顺序（最小堆），即 a - b，队首元素是最小值。 此处通过 b - a 反转顺序，使队首元素变为最大值，形成最大堆。 java优先队列,(a,b)-a-b 意思相当于 a代表父节点,b代表子节点,a-b小于0代表a优先级更高,a-b小于0相当于a小于b,所以这个是小顶堆. 小顶堆（默认，前 K 大，升序）// 创建小顶堆（默认）PriorityQueueInteger minHeap = new PriorityQueue();// 添加元素minHeap.offer(5);minHeap.add(3); // offer和add功能相同// 查看堆顶元素（不删除）int min = minHeap.peek();// 取出堆顶元素（删除）int removedMin = minHeap.poll();// 获取堆大小int size = minHeap.size();// 检查是否为空boolean isEmpty = minHeap.isEmpty();// 删除指定元素（非堆顶）minHeap.remove(2);// 清空堆minHeap.clear(); 大顶堆（前 K 小，降序）// 创建大顶堆（使用自定义比较器）PriorityQueueInteger maxHeap = new PriorityQueue((a, b) - b - a);// 或 PriorityQueue(Comparator.reverseOrder());// 添加元素maxHeap.offer(8);maxHeap.add(4);// 查看堆顶元素（不删除）int max = maxHeap.peek();// 取出堆顶元素（删除）int removedMax = maxHeap.poll();// 检查元素是否存在boolean contains = maxHeap.contains(5);// 遍历并输出元素for (Integer num : minHeap) System.out.println(num);// 构造按照字典序排列的优先队列PriorityQueueInteger pq = new PriorityQueue((a, b) - // 将 int 转换为 String 后比较字典序 String strA = String.valueOf(a); String strB = String.valueOf(b); return strA.compareTo(strB);); 自定义对象堆// 自定义类class Student String name; int score; // 构造方法等...// 按分数的小顶堆PriorityQueueStudent studentMinHeap = new PriorityQueue( (s1, s2) - s1.score - s2.score);// 按分数的大顶堆 PriorityQueueStudent studentMaxHeap = new PriorityQueue( (s1, s2) - s2.score - s1.score);// 添加自定义对象studentMinHeap.offer(new Student(Alice, 85)); 堆序性质堆类型\t比较条件\t数学表达\tJava比较器实现小顶堆\t父 ≤ 子\ta ≤ b\ta - b 或 a.compareTo(b)大顶堆\t父 ≥ 子\ta ≥ b\tb - a 或 b.compareTo(a) 比较器的本质a在堆里代表父节点 b是子节点 a-b 要小于0 a优先级才高 ab 所以是最小堆 比较器定义的是”优先级”关系： 返回负数：第一个参数（a）应该排在前面（更高优先级） 返回正数：第二个参数（b）应该排在前面 返回零：两者优先级相同 使用场景:前 K 大的元素：使用最小堆，因为堆顶是存储的最小的元素，如果新增元素比堆顶大，那只需要替换掉堆顶即可。 前 K 小的元素：使用最大堆，因为堆顶是存储的最大的元素，如果新增元素比堆顶小，那只需要替换掉堆顶即可。 默认小顶堆：升序排序。 默认大顶堆：降序排序。 Deque 的常用操作import java.util.Deque;import java.util.ArrayDeque;import java.util.Iterator;// 初始化 Deque（以 ArrayDeque 为例）DequeString deque = new ArrayDeque(); //不能插入null元素DequeString deque = new LinkedList();// ================== 插入操作 ==================// 队头插入deque.addFirst(A); // 插入元素到队头（容量满时抛出 IllegalStateException）deque.offerFirst(B); // 插入元素到队头（容量满时返回 false）// 队尾插入deque.addLast(C); // 插入元素到队尾（容量满时抛出 IllegalStateException）deque.offerLast(D); // 插入元素到队尾（容量满时返回 false）// 批量插入（从 Collection 继承）deque.addAll(List.of(E, F)); // 依次插入队尾// ================== 删除操作 ==================// 队头删除String first1 = deque.removeFirst(); // 删除并返回队头元素（空队列抛 NoSuchElementException）String first2 = deque.pollFirst(); // 删除并返回队头元素（空队列返回 null）// 队尾删除String last1 = deque.removeLast(); // 删除并返回队尾元素（空队列抛异常）String last2 = deque.pollLast(); // 删除并返回队尾元素（空队列返回 null）// 删除指定元素（从队头开始搜索）boolean removed1 = deque.remove(E); // 删除第一个出现的 Eboolean removed2 = deque.removeFirstOccurrence(F); // 删除队头方向第一个 Fboolean removed3 = deque.removeLastOccurrence(G); // 删除队尾方向第一个 G// ================== 查看元素 ==================// 查看队头String head1 = deque.getFirst(); // 返回队头元素（空队列抛异常）String head2 = deque.peekFirst(); // 返回队头元素（空队列返回 null）// 查看队尾String tail1 = deque.getLast(); // 返回队尾元素（空队列抛异常）String tail2 = deque.peekLast(); // 返回队尾元素（空队列返回 null）// ================== 队列状态 ==================boolean isEmpty = deque.isEmpty(); // 判断队列是否为空int size = deque.size(); // 返回元素数量boolean exists = deque.contains(A); // 判断是否包含元素 A// ================== 其他操作 ==================// 清空队列deque.clear();// 转换为数组Object[] array1 = deque.toArray(); // 返回 Object[]String[] array2 = deque.toArray(new String[0]); // 指定类型数组// 迭代器（正向：队头 → 队尾）IteratorString iterator = deque.iterator();while (iterator.hasNext()) String element = iterator.next();// 反向迭代器（队尾 → 队头）IteratorString descendingIterator = deque.descendingIterator();while (descendingIterator.hasNext()) String element = descendingIterator.next();// ================== 栈操作（Deque 兼容的额外方法）==================deque.push(X); // 等效于 addFirst()String popped = deque.pop(); // 等效于 removeFirst()// ================== 容量限制队列（如 LinkedBlockingDeque）==================// 阻塞操作示例（需使用线程安全 Deque，此处仅展示方法）/*deque.offerFirst(W, 1, TimeUnit.SECONDS); // 等待1秒尝试插入队头deque.offerLast(Z, 1, TimeUnit.SECONDS); // 等待1秒尝试插入队尾String item = deque.pollFirst(1, TimeUnit.SECONDS); // 等待1秒尝试取出队头*/ 模运算的世界（模运算恒等式费马小定理组合数）灵神的模运算帖子.respect.https://leetcode.cn/discuss/post/3584387/fen-xiang-gun-mo-yun-suan-de-shi-jie-dan-7xgu/ 前言某些题目，由于要计算的答案非常大（超出 64 位整数的范围），会要求把答案对 10e9+7 取模。如果没有处理得当的话，会 WA（错误）或者 TLE（超时）。例如计算一堆数字的乘积，如果没有及时取模，乘法会溢出（例如计算结果超出 C++ 中 long long 的最大值），从而得到和预期不符的答案。对于 Python 来说，虽然没有溢出的问题，但大整数（big integer）之间的运算并不是 O(1) 的，可能会导致 TLE。 如何正确的取模呢? 加法和乘法的取模如果让你计算 1234×6789 的个位数，你会如何计算？ 由于只有个位数会影响到乘积的个位数，那么 4×936 的个位数 6 就是答案。 对于 1234+6789 的个位数，同理，4+913 的个位数 3 就是答案。 你能把这个结论抽象成数学等式吗？ 一般涉及到取模的题目，会用到如下两个恒等式，其中 mod 表示取模运算（modulo），即编程语言中的 %。上面计算的是 m10 的情况。 根据这两个恒等式，我们可以在计算过程中（例如循环），对加法和乘法的结果取模，而不是在循环结束后再取模。注：如果涉及到幂运算，指数是不能随意取模的。如果指数在 64 位整数的范围内，可以用快速幂计算，原理见一张图秒懂快速幂；如果指数超出 64 位整数的范围，见欧拉降幂。 如果计算过程中有减法，可能会产生负数，处理不当也会导致 WA。如何正确处理这种情况呢？ 同余 同余式的移项同余式中的加减法可以移项 负数和减法的取模 除法的取模证明: 求模运算总结代码实现时，上面的加减乘除通常是这样写的： MOD = 1_000_000_007// 加(a + b) % MOD// 减，b 在 [0,MOD-1] 中(a - b + MOD) % MOD// 把任意整数 a 取模到 [0,MOD-1] 中，无论 a 是正是负(a % MOD + MOD) % MOD// 乘（注意使用 64 位整数）a * b % MOD// 多个数相乘，要步步取模，防止溢出a * b % MOD * c % MOD// 除（MOD 是质数且 b 不是 MOD 的倍数）a * qpow(b, MOD - 2, MOD) % MOD 其中 qpow 为快速幂. 总之，如果发现解答错误，可以检查下代码，看看是不是哪里漏掉取模了。 附:组合数计算模板代码如下: class Solution private static final int MOD = 1_000_000_007; private static final int MX = 100_001; // 根据题目数据范围修改 private static final long[] F = new long[MX]; // F[i] = i! private static final long[] INV_F = new long[MX]; // INV_F[i] = i!^-1 = pow(i!, MOD-2) static F[0] = 1; for (int i = 1; i MX; i++) F[i] = F[i - 1] * i % MOD; INV_F[MX - 1] = pow(F[MX - 1], MOD - 2); for (int i = MX - 1; i 0; i--) INV_F[i - 1] = INV_F[i] * i % MOD; private static long pow(long x, int n) long res = 1; for (; n 0; n /= 2) if (n % 2 0) res = res * x % MOD; x = x * x % MOD; return res; // 从 n 个数中选 m 个数的方案数 private long comb(int n, int m) return m 0 || m n ? 0 : F[n] * INV_F[m] % MOD * INV_F[n - m] % MOD; public int solve(int[] nums) // 预处理的逻辑写在 static 块中，这样只会初始化一次 快速幂一图流(灵神): 代码实现时，注意 n−2^31的情况，取反后 n2^31超出 int 最大值。可以转成 64 位 int 解决。模版: class Solution public double myPow(double x, int N) double ans = 1; long n = N; if (n 0) // x^-n = (1/x)^n n = -n; x = 1 / x; while (n != 0) // 从低到高枚举 n 的每个比特位 if ((n 1) == 1) // 这个比特位是 1 ans *= x; // 把 x 乘到 ans 中 x *= x; // x 自身平方 n = 1; // 继续枚举下一个比特位 return ans; 数组 二分查找https://leetcode.cn/problems/binary-search/通用模板： class Solution public int search(int[] nums, int target) int i = lowerBound(nums, target); // 选择其中一种写法即可 return i nums.length nums[i] == target ? i : -1; // 【下面列了三种写法，选一种自己喜欢的就行】 // lowerBound 返回最小的满足 nums[i] = target 的 i // 如果数组为空，或者所有数都 target，则返回 nums.length // 要求 nums 是非递减的，即 nums[i] = nums[i + 1] // 闭区间写法 private int lowerBound(int[] nums, int target) int left = 0, right = nums.length - 1; // 闭区间 [left, right] while (left = right) // 区间不为空 // 循环不变量： // nums[left-1] target // nums[right+1] = target int mid = left + (right - left) / 2; if (nums[mid] target) left = mid + 1; // 范围缩小到 [mid+1, right] else right = mid - 1; // 范围缩小到 [left, mid-1] return left; // 或者 right+1 // 左闭右开区间写法 private int lowerBound2(int[] nums, int target) int left = 0, right = nums.length; // 左闭右开区间 [left, right) while (left right) // 区间不为空 // 循环不变量： // nums[left-1] target // nums[right] = target int mid = left + (right - left) / 2; if (nums[mid] target) left = mid + 1; // 范围缩小到 [mid+1, right) else right = mid; // 范围缩小到 [left, mid) return left; // 或者 right // 开区间写法 private int lowerBound3(int[] nums, int target) int left = -1, right = nums.length; // 开区间 (left, right) while (left + 1 right) // 区间不为空 // 循环不变量： // nums[left] target // nums[right] = target int mid = left + (right - left) / 2; if (nums[mid] target) left = mid; // 范围缩小到 (mid, right) else right = mid; // 范围缩小到 (left, mid) return right; // 或者 left+1 题目移除元素https://leetcode.cn/problems/remove-element/ 双指针 有序数组的平方https://leetcode.cn/problems/squares-of-a-sorted-array/ 双指针 长度最小的子数组https://leetcode.cn/problems/minimum-size-subarray-sum/ 螺旋矩阵IIhttps://leetcode.cn/problems/spiral-matrix-ii/ 模拟 区间和https://kamacoder.com/problempage.php?pid=1070 ACM输入输出模式（笔试面试必备） import java.util.Scanner;public class Main public static void main(String[] args) Scanner scanner = new Scanner(System.in); int n = scanner.nextInt(); int [] pre = new int [n]; int [] nums = new int [n]; for(int i = 0;in;++i) nums[i] = scanner.nextInt(); int sum = 0; for(int i = 0;in;++i) sum += nums[i]; pre[i] = sum; while(scanner.hasNextInt()) int a = scanner.nextInt(); int b = scanner.nextInt(); if(a == 0) System.out.println(pre[b]); else System.out.println(pre[b]-pre[a-1]); scanner.close(); 开发商购买土地题目链接 总结数组理论基础数组是非常基础的数据结构，在面试中，考察数组的题目一般在思维上都不难，主要是考察对代码的掌控能力 也就是说，想法很简单，但实现起来 可能就不是那么回事了。 首先要知道数组在内存中的存储方式，这样才能真正理解数组相关的面试题 数组是存放在连续内存空间上的相同类型数据的集合。 数组可以方便的通过下标索引的方式获取到下标对应的数据。 需要两点注意的是 数组下标都是从0开始的。 数组内存空间的地址是连续的 正是因为数组在内存空间的地址是连续的，所以我们在删除或者增添元素的时候，就难免要移动其他元素的地址。 例如删除下标为3的元素，需要对下标为3的元素后面的所有元素都要做移动操作 数组的元素是不能删的，只能覆盖。 那么二维数组在内存的空间地址是连续的么？ 我们来举一个Java的例子，例如： int[][] rating = new int[3][4]; ， 这个二维数组在内存空间可不是一个 3*4 的连续地址空间 所以Java的二维数组在内存中不是 3*4 的连续地址空间，而是四条连续的地址空间组成！ 数组的经典题目在面试中，数组是必考的基础数据结构。 其实数组的题目在思想上一般比较简单的，但是如果想高效，并不容易。 我们之前一共讲解了四道经典数组题目，每一道题目都代表一个类型，一种思想。 二分法数组：每次遇到二分法，都是一看就会，一写就废 这道题目呢，考察数组的基本操作，思路很简单，但是通过率在简单题里并不高，不要轻敌。 可以使用暴力解法，通过这道题目，如果追求更优的算法，建议试一试用二分法，来解决这道题目 暴力解法时间复杂度：O(n) 二分法时间复杂度：O(logn) 在这道题目中我们讲到了循环不变量原则，只有在循环中坚持对区间的定义，才能清楚的把握循环中的各种细节。 二分法是算法面试中的常考题，建议通过这道题目，锻炼自己手撕二分的能力。 双指针法 数组：就移除个元素很难么？(opens new window) 双指针法（快慢指针法）：通过一个快指针和慢指针在一个for循环下完成两个for循环的工作。 暴力解法时间复杂度：O(n^2) 双指针时间复杂度：O(n) 这道题目迷惑了不少同学，纠结于数组中的元素为什么不能删除，主要是因为以下两点： 数组在内存中是连续的地址空间，不能释放单一元素，如果要释放，就是全释放（程序运行结束，回收内存栈空间）。 C++中vector和array的区别一定要弄清楚，vector的底层实现是array，封装后使用更友好。 双指针法（快慢指针法）在数组和链表的操作中是非常常见的，很多考察数组和链表操作的面试题，都使用双指针法。 滑动窗口 数组：滑动窗口拯救了你(opens new window) 本题介绍了数组操作中的另一个重要思想：滑动窗口。 暴力解法时间复杂度：O(n^2) 滑动窗口时间复杂度：O(n) 本题中，主要要理解滑动窗口如何移动 窗口起始位置，达到动态更新窗口大小的，从而得出长度最小的符合条件的长度。 滑动窗口的精妙之处在于根据当前子序列和大小的情况，不断调节子序列的起始位置。从而将O(n^2)的暴力解法降为O(n)。 如果没有接触过这一类的方法，很难想到类似的解题思路，滑动窗口方法还是很巧妙的。 模拟行为 数组：这个循环可以转懵很多人！(opens new window) 模拟类的题目在数组中很常见，不涉及到什么算法，就是单纯的模拟，十分考察大家对代码的掌控能力。 在这道题目中，我们再一次介绍到了循环不变量原则，其实这也是写程序中的重要原则。 相信大家有遇到过这种情况： 感觉题目的边界调节超多，一波接着一波的判断，找边界，拆了东墙补西墙，好不容易运行通过了，代码写的十分冗余，毫无章法，其实真正解决题目的代码都是简洁的，或者有原则性的，大家可以在这道题目中体会到这一点. 前缀和 数组：求取区间和(opens new window) 前缀和的思路其实很简单，但非常实用，如果没接触过的录友，也很难想到这个解法维度，所以 这是开阔思路 而难度又不高的好题。 总结数组是非常基础的数据结构，在面试中，考察数组的题目一般在思维上都不难，主要是考察对代码的掌控能力。数组的题目，在解题之前一定要明确数组的含义，不要凭感觉来写代码。 链表 链表理论基础什么是链表，链表是一种通过指针串联在一起的线性结构，每一个节点由两部分组成，一个是数据域一个是指针域（存放指向下一个节点的指针），最后一个节点的指针域指向null（空指针的意思）。 链表的入口节点称为链表的头结点也就是head。 链表的类型接下来说一下链表的几种类型: 单链表刚刚说的就是单链表。 双链表单链表中的指针域只能指向节点的下一个节点。 双链表：每一个节点有两个指针域，一个指向下一个节点，一个指向上一个节点。 双链表 既可以向前查询也可以向后查询。 循环链表循环链表，顾名思义，就是链表首尾相连。 循环链表可以用来解决约瑟夫环问题。 链表的存储方式了解完链表的类型，再来说一说链表在内存中的存储方式。 数组是在内存中是连续分布的，但是链表在内存中可不是连续分布的。 链表是通过指针域的指针链接在内存中各个节点。 所以链表中的节点在内存中不是连续分布的 ，而是散乱分布在内存中的某地址上，分配机制取决于操作系统的内存管理。 这个链表起始节点为2， 终止节点为7， 各个节点分布在内存的不同地址空间上，通过指针串联在一起。 链表的定义接下来说一说链表的定义。 链表节点的定义，很多同学在面试的时候都写不好。 这是因为平时在刷leetcode的时候，链表的节点都默认定义好了，直接用就行了，所以同学们都没有注意到链表的节点是如何定义的。 而在面试的时候，一旦要自己手写链表，就写的错漏百出。 这里我给出CC++的定义链表节点方式，如下所示： // 单链表struct ListNode int val; // 节点上存储的元素 ListNode *next; // 指向下一个节点的指针 ListNode(int x) : val(x), next(NULL) // 节点的构造函数;/** JAVA * Definition for singly-linked list. * public class ListNode * int val; * ListNode next; * ListNode() * ListNode(int val) this.val = val; * ListNode(int val, ListNode next) this.val = val; this.next = next; * */ 有同学说了，我不定义构造函数行不行，答案是可以的，C++默认生成一个构造函数。 但是这个构造函数不会初始化任何成员变量，下面我来举两个例子： 通过自己定义构造函数初始化节点： ListNode* head = new ListNode(5); 使用默认构造函数初始化节点： ListNode* head = new ListNode();head-val = 5; 所以如果不定义构造函数使用默认构造函数的话，在初始化的时候就不能直接给变量赋值！ 链表的操作删除节点只要将C节点的next指针 指向E节点就可以了。 那有同学说了，D节点不是依然存留在内存里么？只不过是没有在这个链表里而已。 是这样的，所以在C++里最好是再手动释放这个D节点，释放这块内存。 其他语言例如Java、Python，就有自己的内存回收机制，就不用自己手动释放了。 添加节点可以看出链表的增添和删除都是O(1)操作，也不会影响到其他节点。 但是要注意，要是删除第五个节点，需要从头节点查找到第四个节点通过next指针进行删除操作，查找的时间复杂度是O(n)。 性能分析再把链表的特性和数组的特性进行一个对比:链表更加灵活，但是查找的时间复杂度是O(n)，而数组查找的时间复杂度是O(1)。数组的静态分配内存和动态分配内存，都在栈上进行，而链表的动态分配内存在堆上进行。 数组在定义的时候，长度就是固定的，如果想改动数组的长度，就需要重新定义一个新的数组。 链表的长度可以是不固定的，并且可以动态增删， 适合数据量不固定，频繁增删，较少查询的场景。 相信大家已经对链表足够的了解，后面我会讲解关于链表的高频面试题目，我们下期见！ JAVA版本public class ListNode // 结点的值 int val; // 下一个结点 ListNode next; // 节点的构造函数(无参) public ListNode() // 节点的构造函数(有一个参数) public ListNode(int val) this.val = val; // 节点的构造函数(有两个参数) public ListNode(int val, ListNode next) this.val = val; this.next = next; 链表题目移除链表元素力扣题目链接设计链表力扣题目链接反转链表力扣题目链接原地反转，只需要把每个节点间的指向反转就可以尝试递归调用两两交换链表中的节点力扣题目链接删除链表的倒数第N个节点力扣题目链接面试题 02.07. 链表相交力扣题目链接 142.环形链表II力扣题目链接环形链表快慢指针一同走 相遇后差一圈 结论a c从起点和相遇点同时走 就是入口点相似题: https://leetcode.cn/problems/find-the-duplicate-number这个是数组模拟环形链表 class Solution public int findDuplicate(int[] nums) int slow = 0; int fast = 0; slow = nums[slow]; fast = nums[nums[fast]]; while(slow != fast) slow = nums[slow]; fast = nums[nums[fast]]; int pre1 = 0; int pre2 = slow; while(pre1 != pre2) pre1 = nums[pre1]; pre2 = nums[pre2]; return pre1; 哈希表题目242.有效的字母异位词力扣题目链接349.两个数组的交集力扣题目链接第202题. 快乐数力扣题目链接两数之和力扣题目链接第454题.四数相加II力扣题目链接赎金信力扣题目链接第15题. 三数之和力扣题目链接第18题. 四数之和力扣题目链接 字符串KMP算法介绍:KMP 算法是一个快速查找匹配串的算法，它的作用其实就是本题问题：如何快速在「原字符串」中找到「匹配字符串」。 上述的朴素解法，不考虑剪枝的话复杂度是 O(m∗n) 的，而 KMP 算法的复杂度为 O(m+n)。 KMP 之所以能够在 O(m+n) 复杂度内完成查找，是因为其能在「非完全匹配」的过程中提取到有效信息进行复用，以减少「重复匹配」的消耗。个人理解:通过构造一个next数组,使的前缀一样的部分能够快速跳转,前缀一样,但是后面的一个不一样,那就可以直接通过next数组跳转到上一个前缀一样的位置的下标,然后继续匹配.所以这个算法的关键就是构造next数组.看到的一个比较好的实现方式就是在主串和匹配串前面都加上一个空格,这样就可以保证next数组的下标从1开始,这样就可以避免很多边界问题. 先贴一个实现: class Solution // KMP 算法 // ss: 原串(string) pp: 匹配串(pattern) public int strStr(String ss, String pp) if (pp.isEmpty()) return 0; // 分别读取原串和匹配串的长度 int n = ss.length(), m = pp.length(); // 原串和匹配串前面都加空格，使其下标从 1 开始 ss = + ss; pp = + pp; char[] s = ss.toCharArray(); char[] p = pp.toCharArray(); // 构建 next 数组，数组长度为匹配串的长度（next 数组是和匹配串相关的） int[] next = new int[m + 1]; // 构造过程 i = 2，j = 0 开始，i 小于等于匹配串长度 【构造 i 从 2 开始】 for (int i = 2, j = 0; i = m; i++) // 匹配不成功的话，j = next(j) while (j 0 p[i] != p[j + 1]) j = next[j]; // 匹配成功的话，先让 j++ if (p[i] == p[j + 1]) j++; // 更新 next[i]，结束本次循环，i++ next[i] = j; // 匹配过程，i = 1，j = 0 开始，i 小于等于原串长度 【匹配 i 从 1 开始】 for (int i = 1, j = 0; i = n; i++) // 匹配不成功 j = next(j) while (j 0 s[i] != p[j + 1]) j = next[j]; // 匹配成功的话，先让 j++，结束本次循环后 i++ if (s[i] == p[j + 1]) j++; // 整一段匹配成功，直接返回下标 if (j == m) return i - m; return -1; next数组构造: 匹配过程: 题目344.反转字符串力扣题目链接 aa^b: 先把a和b中，不相同的位保存到a，现在a中置1的位，代表原始的a和b不相同的位，而0，就是a和b相同的位。 ba^b: 不相同的位是1和原始b异或，就得到原始a的那个位的值；相同的位是0和原始b异或就是原始a或者原始b的值（本来就相同）。现在得到的就是原始a的值，现在存在b中。 aa^b：和上面相同。 a，b已经交换。 1.反转字符串II力扣题目链接 二叉树二叉树的种类 满二叉树:如果一棵二叉树只有度为0的结点和度为2的结点，并且度为0的结点在同一层上，则这棵二叉树为满二叉树。 完全二叉树:在完全二叉树中，除了最底层节点可能没填满外，其余每层节点数都达到最大值，并且最下面一层的节点都集中在该层最左边的若干位置。若最底层为第 h 层（h从1开始），则该层包含 1~ 2^(h-1) 个节点。也就是只有最后一层右侧不满,前面都是满的. 二叉搜索树:二叉搜索树是一个有序树 若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 它的左、右子树也分别为二叉排序树 平衡二叉搜索树:平衡二叉搜索树：又被称为AVL（Adelson-Velsky and Landis）树，且具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 二叉树的存储方式二叉树可以链式存储，也可以顺序存储。 二叉树遍历顺序前序遍历：中左右中序遍历：左中右后序遍历：左右中 public class TreeNode int val; TreeNode left; TreeNode right; TreeNode() TreeNode(int val) this.val = val; TreeNode(int val, TreeNode left, TreeNode right) this.val = val; this.left = left; this.right = right; 二叉树递归遍历递归的三要素:1.确定递归函数的参数和返回值： 确定哪些参数是递归的过程中需要处理的，那么就在递归函数里加上这个参数， 并且还要明确每次递归的返回值是什么进而确定递归函数的返回类型。 2.确定终止条件： 写完了递归算法, 运行的时候，经常会遇到栈溢出的错误，就是没写终止条件或者终止条件写的不对，操作系统也是用一个栈的结构来保存每一层递归的信息，如果递归没有终止，操作系统的内存栈必然就会溢出。 3.确定单层递归的逻辑： 确定每一层递归需要处理的信息。在这里也就会重复调用自己来实现递归的过程。 // 前序遍历·递归·LC144_二叉树的前序遍历class Solution public ListInteger preorderTraversal(TreeNode root) ListInteger result = new ArrayListInteger(); preorder(root, result); return result; public void preorder(TreeNode root, ListInteger result) if (root == null) return; result.add(root.val); preorder(root.left, result); preorder(root.right, result); // 中序遍历·递归·LC94_二叉树的中序遍历class Solution public ListInteger inorderTraversal(TreeNode root) ListInteger res = new ArrayList(); inorder(root, res); return res; void inorder(TreeNode root, ListInteger list) if (root == null) return; inorder(root.left, list); list.add(root.val); // 注意这一句 inorder(root.right, list); // 后序遍历·递归·LC145_二叉树的后序遍历class Solution public ListInteger postorderTraversal(TreeNode root) ListInteger res = new ArrayList(); postorder(root, res); return res; void postorder(TreeNode root, ListInteger list) if (root == null) return; postorder(root.left, list); postorder(root.right, list); list.add(root.val); // 注意这一句 二叉树迭代遍历144.二叉树的前序遍历https://leetcode.cn/problems/binary-tree-preorder-traversal/94.二叉树的中序遍历https://leetcode.cn/problems/binary-tree-inorder-traversal/145.二叉树的后序遍历https://leetcode.cn/problems/binary-tree-postorder-traversal/ 统一写法!!!!!!!!思路:将访问的节点放入栈中，把要处理的节点也放入栈中但是要做标记。实现方式: 方法一：就是要处理的节点放入栈之后，紧接着放入一个空指针作为标记。 这种方法可以叫做空指针标记法。 方法二：加一个 boolean 值跟随每个节点，false (默认值) 表示需要为该节点和它的左右儿子安排在栈中的位次，true 表示该节点的位次之前已经安排过了，可以收割节点了。 这种方法可以叫做boolean 标记法。 这种方法更容易理解，在面试中更容易写出来。前序遍历代码:public ListInteger preorderTraversal(TreeNode root) ListInteger result = new LinkedList(); DequeTreeNode st = new LinkedList(); if (root != null) st.push(root); while (!st.isEmpty()) TreeNode node = st.peek(); if (node != null) st.pop(); // 将该节点弹出，避免重复操作，下面再将右左中节点添加到栈中（前序遍历-中左右，入栈顺序右左中） if (node.right!=null) st.push(node.right); // 添加右节点（空节点不入栈） if (node.left!=null) st.push(node.left); // 添加左节点（空节点不入栈） st.push(node); // 添加中节点 st.push(null); // 中节点访问过，但是还没有处理，加入空节点做为标记。 else // 只有遇到空节点的时候，才将下一个节点放进结果集 st.pop(); // 将空节点弹出 node = st.peek(); // 重新取出栈中元素 st.pop(); result.add(node.val); // 加入到结果集 return result; 中序遍历代码:public ListInteger inorderTraversal(TreeNode root) ListInteger result = new LinkedList(); DequeTreeNode st = new LinkedList(); if (root != null) st.push(root); while (!st.isEmpty()) TreeNode node = st.peek(); if (node != null) st.pop(); // 将该节点弹出，避免重复操作，下面再将右中左节点添加到栈中（中序遍历-左中右，入栈顺序右中左） if (node.right!=null) st.push(node.right); // 添加右节点（空节点不入栈） st.push(node); // 添加中节点 st.push(null); // 中节点访问过，但是还没有处理，加入空节点做为标记。 if (node.left!=null) st.push(node.left); // 添加左节点（空节点不入栈） else // 只有遇到空节点的时候，才将下一个节点放进结果集 st.pop(); // 将空节点弹出 node = st.peek(); // 重新取出栈中元素 st.pop(); result.add(node.val); // 加入到结果集 return result; 后序遍历代码:public ListInteger postorderTraversal(TreeNode root) ListInteger result = new LinkedList(); DequeTreeNode st = new LinkedList(); if (root != null) st.push(root); while (!st.isEmpty()) TreeNode node = st.peek(); if (node != null) st.pop(); // 将该节点弹出，避免重复操作，下面再将中右左节点添加到栈中（后序遍历-左右中，入栈顺序中右左） st.push(node); // 添加中节点 st.push(null); // 中节点访问过，但是还没有处理，加入空节点做为标记。 if (node.right!=null) st.push(node.right); // 添加右节点（空节点不入栈） if (node.left!=null) st.push(node.left); // 添加左节点（空节点不入栈） else // 只有遇到空节点的时候，才将下一个节点放进结果集 st.pop(); // 将空节点弹出 node = st.peek(); // 重新取出栈中元素 st.pop(); result.add(node.val); // 加入到结果集 return result; 直接用栈模拟的写法:前序 中序 后序的写法不一样. // 前序遍历顺序：中-左-右，入栈顺序：中-右-左class Solution public ListInteger preorderTraversal(TreeNode root) ListInteger result = new ArrayList(); if (root == null) return result; StackTreeNode stack = new Stack(); stack.push(root); while (!stack.isEmpty()) TreeNode node = stack.pop(); result.add(node.val); if (node.right != null) stack.push(node.right); if (node.left != null) stack.push(node.left); return result; // 中序遍历顺序: 左-中-右 入栈顺序： 左-右class Solution public ListInteger inorderTraversal(TreeNode root) ListInteger result = new ArrayList(); if (root == null) return result; StackTreeNode stack = new Stack(); TreeNode cur = root; while (cur != null || !stack.isEmpty()) if (cur != null) stack.push(cur); cur = cur.left; else cur = stack.pop(); result.add(cur.val); cur = cur.right; return result; // 后序遍历顺序 左-右-中 入栈顺序：中-左-右 出栈顺序：中-右-左， 最后翻转结果class Solution public ListInteger postorderTraversal(TreeNode root) ListInteger result = new ArrayList(); if (root == null) return result; StackTreeNode stack = new Stack(); stack.push(root); while (!stack.isEmpty()) TreeNode node = stack.pop(); result.add(node.val); if (node.left != null) stack.push(node.left); if (node.right != null) stack.push(node.right); Collections.reverse(result); return result; 二叉树的层序遍历(BFS)// 102.二叉树的层序遍历class Solution public ListListInteger resList = new ArrayListListInteger(); public ListListInteger levelOrder(TreeNode root) //checkFun01(root,0); checkFun02(root); return resList; //BFS--递归方式 public void checkFun01(TreeNode node, Integer deep) if (node == null) return; deep++; if (resList.size() deep) //当层级增加时，list的Item也增加，利用list的索引值进行层级界定 ListInteger item = new ArrayListInteger(); resList.add(item); resList.get(deep - 1).add(node.val); checkFun01(node.left, deep); checkFun01(node.right, deep); //BFS--迭代方式--借助队列 public void checkFun02(TreeNode node) if (node == null) return; QueueTreeNode que = new LinkedListTreeNode(); que.offer(node); while (!que.isEmpty()) ListInteger itemList = new ArrayListInteger(); int len = que.size(); while (len 0) TreeNode tmpNode = que.poll(); itemList.add(tmpNode.val); if (tmpNode.left != null) que.offer(tmpNode.left); if (tmpNode.right != null) que.offer(tmpNode.right); len--; resList.add(itemList); 翻转二叉树https://leetcode.cn/problems/invert-binary-tree/dfs或者bfs都可做 //DFS递归class Solution /** * 前后序遍历都可以 * 中序不行，因为先左孩子交换孩子，再根交换孩子（做完后，右孩子已经变成了原来的左孩子），再右孩子交换孩子（此时其实是对原来的左孩子做交换） */ public TreeNode invertTree(TreeNode root) if (root == null) return null; invertTree(root.left); invertTree(root.right); swapChildren(root); return root; private void swapChildren(TreeNode root) TreeNode tmp = root.left; root.left = root.right; root.right = tmp; //BFSclass Solution public TreeNode invertTree(TreeNode root) if (root == null) return null; ArrayDequeTreeNode deque = new ArrayDeque(); deque.offer(root); while (!deque.isEmpty()) int size = deque.size(); while (size-- 0) TreeNode node = deque.poll(); swap(node); if (node.left != null) deque.offer(node.left); if (node.right != null) deque.offer(node.right); return root; public void swap(TreeNode root) TreeNode temp = root.left; root.left = root.right; root.right = temp; 对称二叉树这道题递归调用很简单,迭代调用用一个队列就可以,退出条件可以注意一下. /** * 递归法 */public boolean isSymmetric1(TreeNode root) return compare(root.left, root.right);private boolean compare(TreeNode left, TreeNode right) if (left == null right != null) return false; if (left != null right == null) return false; if (left == null right == null) return true; if (left.val != right.val) return false; // 比较外侧 boolean compareOutside = compare(left.left, right.right); // 比较内侧 boolean compareInside = compare(left.right, right.left); return compareOutside compareInside;/** * 迭代法 * 使用双端队列，相当于两个栈 */public boolean isSymmetric2(TreeNode root) DequeTreeNode deque = new LinkedList(); deque.offerFirst(root.left); deque.offerLast(root.right); while (!deque.isEmpty()) TreeNode leftNode = deque.pollFirst(); TreeNode rightNode = deque.pollLast(); if (leftNode == null rightNode == null) continue; // if (leftNode == null rightNode != null) // return false;// // if (leftNode != null rightNode == null) // return false;// // if (leftNode.val != rightNode.val) // return false;// // 以上三个判断条件合并 if (leftNode == null || rightNode == null || leftNode.val != rightNode.val) return false; deque.offerFirst(leftNode.left); deque.offerFirst(leftNode.right); deque.offerLast(rightNode.right); deque.offerLast(rightNode.left); return true;/** * 迭代法 * 使用普通队列 */public boolean isSymmetric3(TreeNode root) QueueTreeNode deque = new LinkedList(); deque.offer(root.left); deque.offer(root.right); while (!deque.isEmpty()) TreeNode leftNode = deque.poll(); TreeNode rightNode = deque.poll(); if (leftNode == null rightNode == null) continue; // if (leftNode == null rightNode != null) // return false;// // if (leftNode != null rightNode == null) // return false;// // if (leftNode.val != rightNode.val) // return false;// // 以上三个判断条件合并 if (leftNode == null || rightNode == null || leftNode.val != rightNode.val) return false; // 这里顺序与使用Deque不同 deque.offer(leftNode.left); deque.offer(rightNode.right); deque.offer(leftNode.right); deque.offer(rightNode.left); return true; 二叉树最大深度104.二叉树的最大深度 class Solution /** * 递归法 */ public int maxDepth(TreeNode root) if (root == null) return 0; int leftDepth = maxDepth(root.left); int rightDepth = maxDepth(root.right); return Math.max(leftDepth, rightDepth) + 1; class Solution /** * 递归法(求深度法) */ //定义最大深度 int maxnum = 0; public int maxDepth(TreeNode root) ans(root,0); return maxnum; //递归求解最大深度 void ans(TreeNode tr,int tmp) if(tr==null) return; tmp++; maxnum = maxnumtmp?tmp:maxnum; ans(tr.left,tmp); ans(tr.right,tmp); tmp--; class Solution /** * 迭代法，使用层序遍历 */ public int maxDepth(TreeNode root) if(root == null) return 0; DequeTreeNode deque = new LinkedList(); deque.offer(root); int depth = 0; while (!deque.isEmpty()) int size = deque.size(); depth++; for (int i = 0; i size; i++) TreeNode node = deque.poll(); if (node.left != null) deque.offer(node.left); if (node.right != null) deque.offer(node.right); return depth; 二叉树的所有路径https://leetcode.cn/problems/binary-tree-paths/递归和回溯.PS:递归和回溯永远要放在一起!!! //解法一//方式一class Solution /** * 递归法 */ public ListString binaryTreePaths(TreeNode root) ListString res = new ArrayList();// 存最终的结果 if (root == null) return res; ListInteger paths = new ArrayList();// 作为结果中的路径 traversal(root, paths, res); return res; private void traversal(TreeNode root, ListInteger paths, ListString res) paths.add(root.val);// 前序遍历，中 // 遇到叶子结点 if (root.left == null root.right == null) // 输出 StringBuilder sb = new StringBuilder();// StringBuilder用来拼接字符串，速度更快 for (int i = 0; i paths.size() - 1; i++) sb.append(paths.get(i)).append(-); sb.append(paths.get(paths.size() - 1));// 记录最后一个节点 res.add(sb.toString());// 收集一个路径 return; // 递归和回溯是同时进行，所以要放在同一个花括号里 if (root.left != null) // 左 traversal(root.left, paths, res); paths.remove(paths.size() - 1);// 回溯 if (root.right != null) // 右 traversal(root.right, paths, res); paths.remove(paths.size() - 1);// 回溯 //方式二class Solution ListString result = new ArrayList(); public ListString binaryTreePaths(TreeNode root) deal(root, ); return result; public void deal(TreeNode node, String s) if (node == null) return; if (node.left == null node.right == null) result.add(new StringBuilder(s).append(node.val).toString()); return; String tmp = new StringBuilder(s).append(node.val).append(-).toString(); deal(node.left, tmp); deal(node.right, tmp); 迭代法: // 解法二class Solution /** * 迭代法 */ public ListString binaryTreePaths(TreeNode root) ListString result = new ArrayList(); if (root == null) return result; StackObject stack = new Stack(); // 节点和路径同时入栈 stack.push(root); stack.push(root.val + ); while (!stack.isEmpty()) // 节点和路径同时出栈 String path = (String) stack.pop(); TreeNode node = (TreeNode) stack.pop(); // 若找到叶子节点 if (node.left == null node.right == null) result.add(path); //右子节点不为空 if (node.right != null) stack.push(node.right); stack.push(path + - + node.right.val); //左子节点不为空 if (node.left != null) stack.push(node.left); stack.push(path + - + node.left.val); return result; 动态规划数位DP字典序字典序字典树:我觉得比较关键的点是: 字典树左子树字典序一定比右子树小. 字典树想要到右侧兄弟节点,直接num++就可以. 关键就是要找到以当前数字为根的十叉树的元素总个数.看着这个图就比较好理解了: 这张图也很好: class Solution /** * 以当前数字为根的十叉树的元素总个数 (包括当前数字) * * @param num 当前数字 (需要先 cast 成 long, 因为 num*10 可能导致 int 溢出) * @param n 数字的最大值 * @return */ private int count(long num, int n) int cnt = 0; // 元素总个数 int width = 1; // 当前层数的宽度, 第一层只有 num 一个元素, 所以第一层宽度为 1 while (true) if (num + width - 1 = n) // n 的值大于等于当前层的最大值, 说明当前层数的个数可以全部添加 cnt += width; num *= 10; width *= 10; else // n 的值小于当前层的最大值则只能添加部分个数或者不添加, 并跳出循环 if (n - num = 0) cnt += n - num + 1; break; return cnt; public int findKthNumber(int n, int k) int cnt = 0; // 已经经过的元素个数, 开始一个元素都没有经过, 所以个数为 0 int num = 1; // 第一个元素 (经过 i 个元素, 当前 num 是第 i + 1 元素) // 要找到第 k 个元素, 需要经过 k - 1 个元素 while (true) if (cnt == k - 1) // 经过了 k - 1 个元素找到了第 k 个元素 break; int temp = count((long) num, n); // 以 num 为根, 以 n 为最大值的十叉树的元素总个数 if (cnt + temp = k) // 以 num 为根的十叉树内有第 k 个元素 num *= 10; cnt++; else if (cnt + temp k) // 以 num 为根的十叉树内没有第 k 个元素 num++; cnt += temp; return num;","tags":["基础","leetcode","算法"]}]